{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d753a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "### Стоян Михов\n",
    "### Зимен семестър 2021/2022\n",
    "#############################################################################\n",
    "###\n",
    "### Домашно задание 2  -- програма за извикване на обучението\n",
    "###\n",
    "#############################################################################\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import grads\n",
    "import utils\n",
    "import w2v_sgd\n",
    "import sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912640e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n",
      "[                                                  --------------------------------------------------]\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "#######   Зареждане на корпуса\n",
    "#############################################################\n",
    "startToken = '<START>'\n",
    "endToken = '<END>'\n",
    "\n",
    "corpus_root = '../../practice/JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "\n",
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]\n",
    "\n",
    "windowSize = 3\n",
    "negativesCount = 5\n",
    "embDim = 50\n",
    "\n",
    "words, word2ind, freqs = utils.extractDictionary(corpus, limit=20000)\n",
    "data = utils.extractWordContextPairs(corpus, windowSize, word2ind)\n",
    "\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2e288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 0 / 53735682 Loss: 4.158825869450769\n",
      "Epoch: 0 Sample: 10000 / 53735682 Loss: 4.146111564211253\n",
      "Epoch: 0 Sample: 20000 / 53735682 Loss: 3.8211443192717454\n",
      "Epoch: 0 Sample: 30000 / 53735682 Loss: 3.2813517163432806\n",
      "Epoch: 0 Sample: 40000 / 53735682 Loss: 2.9900938297872797\n",
      "Epoch: 0 Sample: 50000 / 53735682 Loss: 2.7950921036328156\n",
      "Epoch: 0 Sample: 60000 / 53735682 Loss: 2.684280124323597\n",
      "Epoch: 0 Sample: 70000 / 53735682 Loss: 2.587923352246589\n",
      "Epoch: 0 Sample: 80000 / 53735682 Loss: 2.521000487644519\n",
      "Epoch: 0 Sample: 90000 / 53735682 Loss: 2.307184314064564\n",
      "Epoch: 0 Sample: 100000 / 53735682 Loss: 2.283052527080101\n",
      "Epoch: 0 Sample: 110000 / 53735682 Loss: 2.22440160737137\n",
      "Epoch: 0 Sample: 120000 / 53735682 Loss: 2.124703141726674\n",
      "Epoch: 0 Sample: 130000 / 53735682 Loss: 2.2029613247164366\n",
      "Epoch: 0 Sample: 140000 / 53735682 Loss: 2.0877677602083162\n",
      "Epoch: 0 Sample: 150000 / 53735682 Loss: 1.9601475742426895\n",
      "Epoch: 0 Sample: 160000 / 53735682 Loss: 2.2415120305184537\n",
      "Epoch: 0 Sample: 170000 / 53735682 Loss: 2.06384264263719\n",
      "Epoch: 0 Sample: 180000 / 53735682 Loss: 2.2523401033992974\n",
      "Epoch: 0 Sample: 190000 / 53735682 Loss: 2.166758521104071\n",
      "Epoch: 0 Sample: 200000 / 53735682 Loss: 1.8663221297270658\n",
      "Epoch: 0 Sample: 210000 / 53735682 Loss: 1.9438085016059303\n",
      "Epoch: 0 Sample: 220000 / 53735682 Loss: 2.0045381053146833\n",
      "Epoch: 0 Sample: 230000 / 53735682 Loss: 2.0168233377502496\n",
      "Epoch: 0 Sample: 240000 / 53735682 Loss: 1.9453930976220404\n",
      "Epoch: 0 Sample: 250000 / 53735682 Loss: 2.0651380585210135\n",
      "Epoch: 0 Sample: 260000 / 53735682 Loss: 2.1281327509089105\n",
      "Epoch: 0 Sample: 270000 / 53735682 Loss: 1.9327297927770004\n",
      "Epoch: 0 Sample: 280000 / 53735682 Loss: 2.1051488959300495\n",
      "Epoch: 0 Sample: 290000 / 53735682 Loss: 2.076172083125174\n",
      "Epoch: 0 Sample: 300000 / 53735682 Loss: 2.01598848598556\n",
      "Epoch: 0 Sample: 310000 / 53735682 Loss: 1.9669076041308715\n",
      "Epoch: 0 Sample: 320000 / 53735682 Loss: 2.0478393943399675\n",
      "Epoch: 0 Sample: 330000 / 53735682 Loss: 2.094572520158979\n",
      "Epoch: 0 Sample: 340000 / 53735682 Loss: 2.060709892016809\n",
      "Epoch: 0 Sample: 350000 / 53735682 Loss: 2.1281227134942986\n",
      "Epoch: 0 Sample: 360000 / 53735682 Loss: 2.0464020957449867\n",
      "Epoch: 0 Sample: 370000 / 53735682 Loss: 2.1287430698392713\n",
      "Epoch: 0 Sample: 380000 / 53735682 Loss: 2.0502574577930566\n",
      "Epoch: 0 Sample: 390000 / 53735682 Loss: 1.9989323488705106\n",
      "Epoch: 0 Sample: 400000 / 53735682 Loss: 2.1468513132056355\n",
      "Epoch: 0 Sample: 410000 / 53735682 Loss: 1.7323525659746972\n",
      "Epoch: 0 Sample: 420000 / 53735682 Loss: 1.9068435387996243\n",
      "Epoch: 0 Sample: 430000 / 53735682 Loss: 2.050106397664771\n",
      "Epoch: 0 Sample: 440000 / 53735682 Loss: 1.9766044615170928\n",
      "Epoch: 0 Sample: 450000 / 53735682 Loss: 1.9716856294887752\n",
      "Epoch: 0 Sample: 460000 / 53735682 Loss: 1.9082753216278276\n",
      "Epoch: 0 Sample: 470000 / 53735682 Loss: 2.093015012627772\n",
      "Epoch: 0 Sample: 480000 / 53735682 Loss: 1.8928640887321668\n",
      "Epoch: 0 Sample: 490000 / 53735682 Loss: 1.8323110745051525\n",
      "Epoch: 0 Sample: 500000 / 53735682 Loss: 1.9556278420772992\n",
      "Epoch: 0 Sample: 510000 / 53735682 Loss: 1.7356089364173797\n",
      "Epoch: 0 Sample: 520000 / 53735682 Loss: 1.9728800217755844\n",
      "Epoch: 0 Sample: 530000 / 53735682 Loss: 2.051474326265252\n",
      "Epoch: 0 Sample: 540000 / 53735682 Loss: 1.8817395688177856\n",
      "Epoch: 0 Sample: 550000 / 53735682 Loss: 1.9190655792766729\n",
      "Epoch: 0 Sample: 560000 / 53735682 Loss: 1.9334377075742006\n",
      "Epoch: 0 Sample: 570000 / 53735682 Loss: 1.8563640834069486\n",
      "Epoch: 0 Sample: 580000 / 53735682 Loss: 1.9068091647414271\n",
      "Epoch: 0 Sample: 590000 / 53735682 Loss: 1.8999902194639957\n",
      "Epoch: 0 Sample: 600000 / 53735682 Loss: 1.816836322170563\n",
      "Epoch: 0 Sample: 610000 / 53735682 Loss: 1.8493493216943595\n",
      "Epoch: 0 Sample: 620000 / 53735682 Loss: 1.9481653283090505\n",
      "Epoch: 0 Sample: 630000 / 53735682 Loss: 2.051381213022206\n",
      "Epoch: 0 Sample: 640000 / 53735682 Loss: 1.7439940181387104\n",
      "Epoch: 0 Sample: 650000 / 53735682 Loss: 1.7978806335190545\n",
      "Epoch: 0 Sample: 660000 / 53735682 Loss: 1.880401129542426\n",
      "Epoch: 0 Sample: 670000 / 53735682 Loss: 1.7639988421941402\n",
      "Epoch: 0 Sample: 680000 / 53735682 Loss: 1.8310272471588955\n",
      "Epoch: 0 Sample: 690000 / 53735682 Loss: 1.8830831493133129\n",
      "Epoch: 0 Sample: 700000 / 53735682 Loss: 1.7162127261423237\n",
      "Epoch: 0 Sample: 710000 / 53735682 Loss: 1.7235671599415652\n",
      "Epoch: 0 Sample: 720000 / 53735682 Loss: 1.7882067782442108\n",
      "Epoch: 0 Sample: 730000 / 53735682 Loss: 1.8353862360795894\n",
      "Epoch: 0 Sample: 740000 / 53735682 Loss: 1.853850956788538\n",
      "Epoch: 0 Sample: 750000 / 53735682 Loss: 1.8365045888550895\n",
      "Epoch: 0 Sample: 760000 / 53735682 Loss: 1.6998763567561852\n",
      "Epoch: 0 Sample: 770000 / 53735682 Loss: 1.8619017385677488\n",
      "Epoch: 0 Sample: 780000 / 53735682 Loss: 1.7993914811359677\n",
      "Epoch: 0 Sample: 790000 / 53735682 Loss: 1.8204039137887957\n",
      "Epoch: 0 Sample: 800000 / 53735682 Loss: 1.8707865085556286\n",
      "Epoch: 0 Sample: 810000 / 53735682 Loss: 1.7553953831731568\n",
      "Epoch: 0 Sample: 820000 / 53735682 Loss: 1.8197802558832659\n",
      "Epoch: 0 Sample: 830000 / 53735682 Loss: 1.769950222739725\n",
      "Epoch: 0 Sample: 840000 / 53735682 Loss: 1.6797299966312345\n",
      "Epoch: 0 Sample: 850000 / 53735682 Loss: 1.9052674652277004\n",
      "Epoch: 0 Sample: 860000 / 53735682 Loss: 1.9174886486942904\n",
      "Epoch: 0 Sample: 870000 / 53735682 Loss: 1.8374395954307714\n",
      "Epoch: 0 Sample: 880000 / 53735682 Loss: 1.7401852473683566\n",
      "Epoch: 0 Sample: 890000 / 53735682 Loss: 1.6848224012868147\n",
      "Epoch: 0 Sample: 900000 / 53735682 Loss: 1.821586186866834\n",
      "Epoch: 0 Sample: 910000 / 53735682 Loss: 1.868125658283266\n",
      "Epoch: 0 Sample: 920000 / 53735682 Loss: 1.7122816679069777\n",
      "Epoch: 0 Sample: 930000 / 53735682 Loss: 1.8705520432045675\n",
      "Epoch: 0 Sample: 940000 / 53735682 Loss: 1.712830362536914\n",
      "Epoch: 0 Sample: 950000 / 53735682 Loss: 1.7522749222666703\n",
      "Epoch: 0 Sample: 960000 / 53735682 Loss: 1.6950926597388112\n",
      "Epoch: 0 Sample: 970000 / 53735682 Loss: 1.7958972422317228\n",
      "Epoch: 0 Sample: 980000 / 53735682 Loss: 1.7788839398066125\n",
      "Epoch: 0 Sample: 990000 / 53735682 Loss: 1.8114109386997979\n",
      "Epoch: 0 Sample: 1000000 / 53735682 Loss: 1.8632479522118413\n",
      "Epoch: 0 Sample: 1010000 / 53735682 Loss: 1.8411653566299768\n",
      "Epoch: 0 Sample: 1020000 / 53735682 Loss: 1.8090756266455015\n",
      "Epoch: 0 Sample: 1030000 / 53735682 Loss: 1.7074869989915569\n",
      "Epoch: 0 Sample: 1040000 / 53735682 Loss: 1.6932014960560062\n",
      "Epoch: 0 Sample: 1050000 / 53735682 Loss: 1.7591497213154959\n",
      "Epoch: 0 Sample: 1060000 / 53735682 Loss: 1.8309604112728752\n",
      "Epoch: 0 Sample: 1070000 / 53735682 Loss: 1.8440154534363815\n",
      "Epoch: 0 Sample: 1080000 / 53735682 Loss: 1.7952931439602722\n",
      "Epoch: 0 Sample: 1090000 / 53735682 Loss: 1.7629357242320265\n",
      "Epoch: 0 Sample: 1100000 / 53735682 Loss: 1.7638491894395254\n",
      "Epoch: 0 Sample: 1110000 / 53735682 Loss: 1.6707284229559478\n",
      "Epoch: 0 Sample: 1120000 / 53735682 Loss: 1.7137452489188094\n",
      "Epoch: 0 Sample: 1130000 / 53735682 Loss: 1.7233463529175717\n",
      "Epoch: 0 Sample: 1140000 / 53735682 Loss: 1.693799802594462\n",
      "Epoch: 0 Sample: 1150000 / 53735682 Loss: 1.7597304547600845\n",
      "Epoch: 0 Sample: 1160000 / 53735682 Loss: 1.7936246823557138\n",
      "Epoch: 0 Sample: 1170000 / 53735682 Loss: 1.893468905518936\n",
      "Epoch: 0 Sample: 1180000 / 53735682 Loss: 1.7213956965239408\n",
      "Epoch: 0 Sample: 1190000 / 53735682 Loss: 1.6676401904691769\n",
      "Epoch: 0 Sample: 1200000 / 53735682 Loss: 1.8186194753033045\n",
      "Epoch: 0 Sample: 1210000 / 53735682 Loss: 1.8269738259464152\n",
      "Epoch: 0 Sample: 1220000 / 53735682 Loss: 1.6479920938560744\n",
      "Epoch: 0 Sample: 1230000 / 53735682 Loss: 1.7654364793975295\n",
      "Epoch: 0 Sample: 1240000 / 53735682 Loss: 1.6578457625707594\n",
      "Epoch: 0 Sample: 1250000 / 53735682 Loss: 1.793059555259894\n",
      "Epoch: 0 Sample: 1260000 / 53735682 Loss: 1.8833553831091654\n",
      "Epoch: 0 Sample: 1270000 / 53735682 Loss: 1.8499861321517144\n",
      "Epoch: 0 Sample: 1280000 / 53735682 Loss: 1.7589271720269308\n",
      "Epoch: 0 Sample: 1290000 / 53735682 Loss: 1.8193466096968725\n",
      "Epoch: 0 Sample: 1300000 / 53735682 Loss: 1.727946657086307\n",
      "Epoch: 0 Sample: 1310000 / 53735682 Loss: 1.6884038458720891\n",
      "Epoch: 0 Sample: 1320000 / 53735682 Loss: 1.7634183721221697\n",
      "Epoch: 0 Sample: 1330000 / 53735682 Loss: 1.7466115523665349\n",
      "Epoch: 0 Sample: 1340000 / 53735682 Loss: 1.8629415694338936\n",
      "Epoch: 0 Sample: 1350000 / 53735682 Loss: 1.6734481762344775\n",
      "Epoch: 0 Sample: 1360000 / 53735682 Loss: 1.7591786520069697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 1370000 / 53735682 Loss: 1.7249871452121504\n",
      "Epoch: 0 Sample: 1380000 / 53735682 Loss: 1.654232446042238\n",
      "Epoch: 0 Sample: 1390000 / 53735682 Loss: 1.7404626681960451\n",
      "Epoch: 0 Sample: 1400000 / 53735682 Loss: 1.7154165105778905\n",
      "Epoch: 0 Sample: 1410000 / 53735682 Loss: 1.7303343538511922\n",
      "Epoch: 0 Sample: 1420000 / 53735682 Loss: 1.6824820921341637\n",
      "Epoch: 0 Sample: 1430000 / 53735682 Loss: 1.7002664495875708\n",
      "Epoch: 0 Sample: 1440000 / 53735682 Loss: 1.6577784448917225\n",
      "Epoch: 0 Sample: 1450000 / 53735682 Loss: 1.7475141021563232\n",
      "Epoch: 0 Sample: 1460000 / 53735682 Loss: 1.7681497936777393\n",
      "Epoch: 0 Sample: 1470000 / 53735682 Loss: 1.7093678191830162\n",
      "Epoch: 0 Sample: 1480000 / 53735682 Loss: 1.7934658975638884\n",
      "Epoch: 0 Sample: 1490000 / 53735682 Loss: 1.7063329784204866\n",
      "Epoch: 0 Sample: 1500000 / 53735682 Loss: 1.6813396145003052\n",
      "Epoch: 0 Sample: 1510000 / 53735682 Loss: 1.6926801783722631\n",
      "Epoch: 0 Sample: 1520000 / 53735682 Loss: 1.6252122994227847\n",
      "Epoch: 0 Sample: 1530000 / 53735682 Loss: 1.7949475998702962\n",
      "Epoch: 0 Sample: 1540000 / 53735682 Loss: 1.6670354948035673\n",
      "Epoch: 0 Sample: 1550000 / 53735682 Loss: 1.7851802943931925\n",
      "Epoch: 0 Sample: 1560000 / 53735682 Loss: 1.6439893007668525\n",
      "Epoch: 0 Sample: 1570000 / 53735682 Loss: 1.7261541010350485\n",
      "Epoch: 0 Sample: 1580000 / 53735682 Loss: 1.7715284698243812\n",
      "Epoch: 0 Sample: 1590000 / 53735682 Loss: 1.7169119006919136\n",
      "Epoch: 0 Sample: 1600000 / 53735682 Loss: 1.6721886885298745\n",
      "Epoch: 0 Sample: 1610000 / 53735682 Loss: 1.7443898271194749\n",
      "Epoch: 0 Sample: 1620000 / 53735682 Loss: 1.7091180595252582\n",
      "Epoch: 0 Sample: 1630000 / 53735682 Loss: 1.636314683451694\n",
      "Epoch: 0 Sample: 1640000 / 53735682 Loss: 1.749905654377571\n",
      "Epoch: 0 Sample: 1650000 / 53735682 Loss: 1.7015427042624562\n",
      "Epoch: 0 Sample: 1660000 / 53735682 Loss: 1.7586223790303248\n",
      "Epoch: 0 Sample: 1670000 / 53735682 Loss: 1.748848032129696\n",
      "Epoch: 0 Sample: 1680000 / 53735682 Loss: 1.6770925393392957\n",
      "Epoch: 0 Sample: 1690000 / 53735682 Loss: 1.7202089314556062\n",
      "Epoch: 0 Sample: 1700000 / 53735682 Loss: 1.788444168336267\n",
      "Epoch: 0 Sample: 1710000 / 53735682 Loss: 1.6896851787677276\n",
      "Epoch: 0 Sample: 1720000 / 53735682 Loss: 1.7029001746956753\n",
      "Epoch: 0 Sample: 1730000 / 53735682 Loss: 1.6926429555996643\n",
      "Epoch: 0 Sample: 1740000 / 53735682 Loss: 1.7414449165445292\n",
      "Epoch: 0 Sample: 1750000 / 53735682 Loss: 1.6856576032944401\n",
      "Epoch: 0 Sample: 1760000 / 53735682 Loss: 1.7116879744608497\n",
      "Epoch: 0 Sample: 1770000 / 53735682 Loss: 1.6114962870024057\n",
      "Epoch: 0 Sample: 1780000 / 53735682 Loss: 1.6867358800054366\n",
      "Epoch: 0 Sample: 1790000 / 53735682 Loss: 1.715077687126314\n",
      "Epoch: 0 Sample: 1800000 / 53735682 Loss: 1.7837646923195252\n",
      "Epoch: 0 Sample: 1810000 / 53735682 Loss: 1.7018662142585794\n",
      "Epoch: 0 Sample: 1820000 / 53735682 Loss: 1.6934309588569385\n",
      "Epoch: 0 Sample: 1830000 / 53735682 Loss: 1.7870413769486342\n",
      "Epoch: 0 Sample: 1840000 / 53735682 Loss: 1.6734786883336272\n",
      "Epoch: 0 Sample: 1850000 / 53735682 Loss: 1.6962529306255059\n",
      "Epoch: 0 Sample: 1860000 / 53735682 Loss: 1.6094051412906913\n",
      "Epoch: 0 Sample: 1870000 / 53735682 Loss: 1.7139165785052448\n",
      "Epoch: 0 Sample: 1880000 / 53735682 Loss: 1.7205512901596804\n",
      "Epoch: 0 Sample: 1890000 / 53735682 Loss: 1.6998264962544796\n",
      "Epoch: 0 Sample: 1900000 / 53735682 Loss: 1.6226190545053916\n",
      "Epoch: 0 Sample: 1910000 / 53735682 Loss: 1.729820400741317\n",
      "Epoch: 0 Sample: 1920000 / 53735682 Loss: 1.8013038851698833\n",
      "Epoch: 0 Sample: 1930000 / 53735682 Loss: 1.7038197454895712\n",
      "Epoch: 0 Sample: 1940000 / 53735682 Loss: 1.6721904456424541\n",
      "Epoch: 0 Sample: 1950000 / 53735682 Loss: 1.625139867632537\n",
      "Epoch: 0 Sample: 1960000 / 53735682 Loss: 1.6518541901764698\n",
      "Epoch: 0 Sample: 1970000 / 53735682 Loss: 1.6773094513704832\n",
      "Epoch: 0 Sample: 1980000 / 53735682 Loss: 1.6754730599248995\n",
      "Epoch: 0 Sample: 1990000 / 53735682 Loss: 1.613847864165267\n",
      "Epoch: 0 Sample: 2000000 / 53735682 Loss: 1.688107025431308\n",
      "Epoch: 0 Sample: 2010000 / 53735682 Loss: 1.6893856442309212\n",
      "Epoch: 0 Sample: 2020000 / 53735682 Loss: 1.6369404193925516\n",
      "Epoch: 0 Sample: 2030000 / 53735682 Loss: 1.6233514702923801\n",
      "Epoch: 0 Sample: 2040000 / 53735682 Loss: 1.7486263325596116\n",
      "Epoch: 0 Sample: 2050000 / 53735682 Loss: 1.6285578323246463\n",
      "Epoch: 0 Sample: 2060000 / 53735682 Loss: 1.6717208882571666\n",
      "Epoch: 0 Sample: 2070000 / 53735682 Loss: 1.5905426988079858\n",
      "Epoch: 0 Sample: 2080000 / 53735682 Loss: 1.7551612847357687\n",
      "Epoch: 0 Sample: 2090000 / 53735682 Loss: 1.6530033799924722\n",
      "Epoch: 0 Sample: 2100000 / 53735682 Loss: 1.7347965893925679\n",
      "Epoch: 0 Sample: 2110000 / 53735682 Loss: 1.7064429260388196\n",
      "Epoch: 0 Sample: 2120000 / 53735682 Loss: 1.5669889987201027\n",
      "Epoch: 0 Sample: 2130000 / 53735682 Loss: 1.6180898345923176\n",
      "Epoch: 0 Sample: 2140000 / 53735682 Loss: 1.6201294744152512\n",
      "Epoch: 0 Sample: 2150000 / 53735682 Loss: 1.6369844310308852\n",
      "Epoch: 0 Sample: 2160000 / 53735682 Loss: 1.6712941629847806\n",
      "Epoch: 0 Sample: 2170000 / 53735682 Loss: 1.7185205680126936\n",
      "Epoch: 0 Sample: 2180000 / 53735682 Loss: 1.6651597983674353\n",
      "Epoch: 0 Sample: 2190000 / 53735682 Loss: 1.6369573168184588\n",
      "Epoch: 0 Sample: 2200000 / 53735682 Loss: 1.6149529641276879\n",
      "Epoch: 0 Sample: 2210000 / 53735682 Loss: 1.6476390602195248\n",
      "Epoch: 0 Sample: 2220000 / 53735682 Loss: 1.6489515597689706\n",
      "Epoch: 0 Sample: 2230000 / 53735682 Loss: 1.6255266558530488\n",
      "Epoch: 0 Sample: 2240000 / 53735682 Loss: 1.6876506416041637\n",
      "Epoch: 0 Sample: 2250000 / 53735682 Loss: 1.6852073257077913\n",
      "Epoch: 0 Sample: 2260000 / 53735682 Loss: 1.5925580539333324\n",
      "Epoch: 0 Sample: 2270000 / 53735682 Loss: 1.6956718963368262\n",
      "Epoch: 0 Sample: 2280000 / 53735682 Loss: 1.6968049249334864\n",
      "Epoch: 0 Sample: 2290000 / 53735682 Loss: 1.6446270056981995\n",
      "Epoch: 0 Sample: 2300000 / 53735682 Loss: 1.6756424916809316\n",
      "Epoch: 0 Sample: 2310000 / 53735682 Loss: 1.7397366943220258\n",
      "Epoch: 0 Sample: 2320000 / 53735682 Loss: 1.6676383530962444\n",
      "Epoch: 0 Sample: 2330000 / 53735682 Loss: 1.6776676026072948\n",
      "Epoch: 0 Sample: 2340000 / 53735682 Loss: 1.6102079643322789\n",
      "Epoch: 0 Sample: 2350000 / 53735682 Loss: 1.6555040638770366\n",
      "Epoch: 0 Sample: 2360000 / 53735682 Loss: 1.6764475676217403\n",
      "Epoch: 0 Sample: 2370000 / 53735682 Loss: 1.6801122115826548\n",
      "Epoch: 0 Sample: 2380000 / 53735682 Loss: 1.714765801377892\n",
      "Epoch: 0 Sample: 2390000 / 53735682 Loss: 1.697548902890318\n",
      "Epoch: 0 Sample: 2400000 / 53735682 Loss: 1.6985450358609724\n",
      "Epoch: 0 Sample: 2410000 / 53735682 Loss: 1.6327719967792151\n",
      "Epoch: 0 Sample: 2420000 / 53735682 Loss: 1.7283656100252185\n",
      "Epoch: 0 Sample: 2430000 / 53735682 Loss: 1.661963008641771\n",
      "Epoch: 0 Sample: 2440000 / 53735682 Loss: 1.6792861285870484\n",
      "Epoch: 0 Sample: 2450000 / 53735682 Loss: 1.5887442884143974\n",
      "Epoch: 0 Sample: 2460000 / 53735682 Loss: 1.5893146714167334\n",
      "Epoch: 0 Sample: 2470000 / 53735682 Loss: 1.6269221740228166\n",
      "Epoch: 0 Sample: 2480000 / 53735682 Loss: 1.66333174170905\n",
      "Epoch: 0 Sample: 2490000 / 53735682 Loss: 1.671584345242262\n",
      "Epoch: 0 Sample: 2500000 / 53735682 Loss: 1.7193181950584588\n",
      "Epoch: 0 Sample: 2510000 / 53735682 Loss: 1.6247824981970145\n",
      "Epoch: 0 Sample: 2520000 / 53735682 Loss: 1.6886777410141007\n",
      "Epoch: 0 Sample: 2530000 / 53735682 Loss: 1.6473625758728605\n",
      "Epoch: 0 Sample: 2540000 / 53735682 Loss: 1.5710356656913822\n",
      "Epoch: 0 Sample: 2550000 / 53735682 Loss: 1.6158168942714437\n",
      "Epoch: 0 Sample: 2560000 / 53735682 Loss: 1.6799563770388046\n",
      "Epoch: 0 Sample: 2570000 / 53735682 Loss: 1.6271167417682473\n",
      "Epoch: 0 Sample: 2580000 / 53735682 Loss: 1.6806530532236412\n",
      "Epoch: 0 Sample: 2590000 / 53735682 Loss: 1.5853225085921032\n",
      "Epoch: 0 Sample: 2600000 / 53735682 Loss: 1.7105219952410926\n",
      "Epoch: 0 Sample: 2610000 / 53735682 Loss: 1.594385722674525\n",
      "Epoch: 0 Sample: 2620000 / 53735682 Loss: 1.617678044466391\n",
      "Epoch: 0 Sample: 2630000 / 53735682 Loss: 1.5589055584619378\n",
      "Epoch: 0 Sample: 2640000 / 53735682 Loss: 1.6761431664671107\n",
      "Epoch: 0 Sample: 2650000 / 53735682 Loss: 1.6401346721613654\n",
      "Epoch: 0 Sample: 2660000 / 53735682 Loss: 1.6293078534154337\n",
      "Epoch: 0 Sample: 2670000 / 53735682 Loss: 1.675572775503344\n",
      "Epoch: 0 Sample: 2680000 / 53735682 Loss: 1.6311527799394792\n",
      "Epoch: 0 Sample: 2690000 / 53735682 Loss: 1.5580751197647926\n",
      "Epoch: 0 Sample: 2700000 / 53735682 Loss: 1.587591237117314\n",
      "Epoch: 0 Sample: 2710000 / 53735682 Loss: 1.5606118750871203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 2720000 / 53735682 Loss: 1.705770697832211\n",
      "Epoch: 0 Sample: 2730000 / 53735682 Loss: 1.5875241114990017\n",
      "Epoch: 0 Sample: 2740000 / 53735682 Loss: 1.6084950147561274\n",
      "Epoch: 0 Sample: 2750000 / 53735682 Loss: 1.6094802244695958\n",
      "Epoch: 0 Sample: 2760000 / 53735682 Loss: 1.5853403238635722\n",
      "Epoch: 0 Sample: 2770000 / 53735682 Loss: 1.651394727894308\n",
      "Epoch: 0 Sample: 2780000 / 53735682 Loss: 1.695846008255355\n",
      "Epoch: 0 Sample: 2790000 / 53735682 Loss: 1.6209787510207199\n",
      "Epoch: 0 Sample: 2800000 / 53735682 Loss: 1.6532235246448872\n",
      "Epoch: 0 Sample: 2810000 / 53735682 Loss: 1.5750131279049973\n",
      "Epoch: 0 Sample: 2820000 / 53735682 Loss: 1.6347766449883812\n",
      "Epoch: 0 Sample: 2830000 / 53735682 Loss: 1.6217586666298733\n",
      "Epoch: 0 Sample: 2840000 / 53735682 Loss: 1.6659616533787207\n",
      "Epoch: 0 Sample: 2850000 / 53735682 Loss: 1.7396528593386174\n",
      "Epoch: 0 Sample: 2860000 / 53735682 Loss: 1.6606038703857176\n",
      "Epoch: 0 Sample: 2870000 / 53735682 Loss: 1.581763644737397\n",
      "Epoch: 0 Sample: 2880000 / 53735682 Loss: 1.5563525464777093\n",
      "Epoch: 0 Sample: 2890000 / 53735682 Loss: 1.693475213424008\n",
      "Epoch: 0 Sample: 2900000 / 53735682 Loss: 1.5961859919160157\n",
      "Epoch: 0 Sample: 2910000 / 53735682 Loss: 1.6294446963548286\n",
      "Epoch: 0 Sample: 2920000 / 53735682 Loss: 1.623606948472708\n",
      "Epoch: 0 Sample: 2930000 / 53735682 Loss: 1.5818476758803484\n",
      "Epoch: 0 Sample: 2940000 / 53735682 Loss: 1.5995029190590415\n",
      "Epoch: 0 Sample: 2950000 / 53735682 Loss: 1.6381082504000117\n",
      "Epoch: 0 Sample: 2960000 / 53735682 Loss: 1.4510924481089909\n",
      "Epoch: 0 Sample: 2970000 / 53735682 Loss: 1.6201656892761058\n",
      "Epoch: 0 Sample: 2980000 / 53735682 Loss: 1.6806821682417432\n",
      "Epoch: 0 Sample: 2990000 / 53735682 Loss: 1.571862060150183\n",
      "Epoch: 0 Sample: 3000000 / 53735682 Loss: 1.5076027827216796\n",
      "Epoch: 0 Sample: 3010000 / 53735682 Loss: 1.6952221142495754\n",
      "Epoch: 0 Sample: 3020000 / 53735682 Loss: 1.6095987769283866\n",
      "Epoch: 0 Sample: 3030000 / 53735682 Loss: 1.5493416480694036\n",
      "Epoch: 0 Sample: 3040000 / 53735682 Loss: 1.6049955336974837\n",
      "Epoch: 0 Sample: 3050000 / 53735682 Loss: 1.6084298148419616\n",
      "Epoch: 0 Sample: 3060000 / 53735682 Loss: 1.623567806317703\n",
      "Epoch: 0 Sample: 3070000 / 53735682 Loss: 1.5897874709017494\n",
      "Epoch: 0 Sample: 3080000 / 53735682 Loss: 1.605366338176177\n",
      "Epoch: 0 Sample: 3090000 / 53735682 Loss: 1.6643024861176179\n",
      "Epoch: 0 Sample: 3100000 / 53735682 Loss: 1.6383784864362667\n",
      "Epoch: 0 Sample: 3110000 / 53735682 Loss: 1.5841002695510296\n",
      "Epoch: 0 Sample: 3120000 / 53735682 Loss: 1.5056159859991327\n",
      "Epoch: 0 Sample: 3130000 / 53735682 Loss: 1.5166117761131266\n",
      "Epoch: 0 Sample: 3140000 / 53735682 Loss: 1.6736932504787898\n",
      "Epoch: 0 Sample: 3150000 / 53735682 Loss: 1.5579788783361317\n",
      "Epoch: 0 Sample: 3160000 / 53735682 Loss: 1.6373030129326007\n",
      "Epoch: 0 Sample: 3170000 / 53735682 Loss: 1.5689513423439947\n",
      "Epoch: 0 Sample: 3180000 / 53735682 Loss: 1.6879000591478759\n",
      "Epoch: 0 Sample: 3190000 / 53735682 Loss: 1.671450814458157\n",
      "Epoch: 0 Sample: 3200000 / 53735682 Loss: 1.6651569507532193\n",
      "Epoch: 0 Sample: 3210000 / 53735682 Loss: 1.6057586485543318\n",
      "Epoch: 0 Sample: 3220000 / 53735682 Loss: 1.6451957153642076\n",
      "Epoch: 0 Sample: 3230000 / 53735682 Loss: 1.6687836019496654\n",
      "Epoch: 0 Sample: 3240000 / 53735682 Loss: 1.5064842590706937\n",
      "Epoch: 0 Sample: 3250000 / 53735682 Loss: 1.585354870411257\n",
      "Epoch: 0 Sample: 3260000 / 53735682 Loss: 1.587887164984588\n",
      "Epoch: 0 Sample: 3270000 / 53735682 Loss: 1.6035815309140176\n",
      "Epoch: 0 Sample: 3280000 / 53735682 Loss: 1.6295430519927385\n",
      "Epoch: 0 Sample: 3290000 / 53735682 Loss: 1.6345305414288938\n",
      "Epoch: 0 Sample: 3300000 / 53735682 Loss: 1.5568152535838915\n",
      "Epoch: 0 Sample: 3310000 / 53735682 Loss: 1.627360066808242\n",
      "Epoch: 0 Sample: 3320000 / 53735682 Loss: 1.5290762713860186\n",
      "Epoch: 0 Sample: 3330000 / 53735682 Loss: 1.4745861648909497\n",
      "Epoch: 0 Sample: 3340000 / 53735682 Loss: 1.6035727997855527\n",
      "Epoch: 0 Sample: 3350000 / 53735682 Loss: 1.59465052545175\n",
      "Epoch: 0 Sample: 3360000 / 53735682 Loss: 1.5922157466912994\n",
      "Epoch: 0 Sample: 3370000 / 53735682 Loss: 1.5692852073043209\n",
      "Epoch: 0 Sample: 3380000 / 53735682 Loss: 1.5665303638605217\n",
      "Epoch: 0 Sample: 3390000 / 53735682 Loss: 1.6038444672445902\n",
      "Epoch: 0 Sample: 3400000 / 53735682 Loss: 1.6243867472962448\n",
      "Epoch: 0 Sample: 3410000 / 53735682 Loss: 1.6191034855774775\n",
      "Epoch: 0 Sample: 3420000 / 53735682 Loss: 1.5778161778915365\n",
      "Epoch: 0 Sample: 3430000 / 53735682 Loss: 1.5090195126573243\n",
      "Epoch: 0 Sample: 3440000 / 53735682 Loss: 1.6351662294814249\n",
      "Epoch: 0 Sample: 3450000 / 53735682 Loss: 1.590558820925419\n",
      "Epoch: 0 Sample: 3460000 / 53735682 Loss: 1.679448937255796\n",
      "Epoch: 0 Sample: 3470000 / 53735682 Loss: 1.628429948382356\n",
      "Epoch: 0 Sample: 3480000 / 53735682 Loss: 1.5493920434445414\n",
      "Epoch: 0 Sample: 3490000 / 53735682 Loss: 1.633166549157231\n",
      "Epoch: 0 Sample: 3500000 / 53735682 Loss: 1.542437792640564\n",
      "Epoch: 0 Sample: 3510000 / 53735682 Loss: 1.6621675302357979\n",
      "Epoch: 0 Sample: 3520000 / 53735682 Loss: 1.5609130790144994\n",
      "Epoch: 0 Sample: 3530000 / 53735682 Loss: 1.5637041596154648\n",
      "Epoch: 0 Sample: 3540000 / 53735682 Loss: 1.6099062353589768\n",
      "Epoch: 0 Sample: 3550000 / 53735682 Loss: 1.6192043327650705\n",
      "Epoch: 0 Sample: 3560000 / 53735682 Loss: 1.5922825429586716\n",
      "Epoch: 0 Sample: 3570000 / 53735682 Loss: 1.6534369915931366\n",
      "Epoch: 0 Sample: 3580000 / 53735682 Loss: 1.5750720384537114\n",
      "Epoch: 0 Sample: 3590000 / 53735682 Loss: 1.4699380755592935\n",
      "Epoch: 0 Sample: 3600000 / 53735682 Loss: 1.5983284920413094\n",
      "Epoch: 0 Sample: 3610000 / 53735682 Loss: 1.6608809901863402\n",
      "Epoch: 0 Sample: 3620000 / 53735682 Loss: 1.6767233905850367\n",
      "Epoch: 0 Sample: 3630000 / 53735682 Loss: 1.6364806308351134\n",
      "Epoch: 0 Sample: 3640000 / 53735682 Loss: 1.6374951635815842\n",
      "Epoch: 0 Sample: 3650000 / 53735682 Loss: 1.6362356907292308\n",
      "Epoch: 0 Sample: 3660000 / 53735682 Loss: 1.5798838449312962\n",
      "Epoch: 0 Sample: 3670000 / 53735682 Loss: 1.5181725694627621\n",
      "Epoch: 0 Sample: 3680000 / 53735682 Loss: 1.636346443456837\n",
      "Epoch: 0 Sample: 3690000 / 53735682 Loss: 1.5878573920802208\n",
      "Epoch: 0 Sample: 3700000 / 53735682 Loss: 1.5406456236393213\n",
      "Epoch: 0 Sample: 3710000 / 53735682 Loss: 1.6325172366301235\n",
      "Epoch: 0 Sample: 3720000 / 53735682 Loss: 1.685084041700465\n",
      "Epoch: 0 Sample: 3730000 / 53735682 Loss: 1.54523850086091\n",
      "Epoch: 0 Sample: 3740000 / 53735682 Loss: 1.6248595179503738\n",
      "Epoch: 0 Sample: 3750000 / 53735682 Loss: 1.6453830402376242\n",
      "Epoch: 0 Sample: 3760000 / 53735682 Loss: 1.5873092523344128\n",
      "Epoch: 0 Sample: 3770000 / 53735682 Loss: 1.6602107253128244\n",
      "Epoch: 0 Sample: 3780000 / 53735682 Loss: 1.6548159167751584\n",
      "Epoch: 0 Sample: 3790000 / 53735682 Loss: 1.5938270132499348\n",
      "Epoch: 0 Sample: 3800000 / 53735682 Loss: 1.648475650258243\n",
      "Epoch: 0 Sample: 3810000 / 53735682 Loss: 1.6739866748478047\n",
      "Epoch: 0 Sample: 3820000 / 53735682 Loss: 1.5540206758721389\n",
      "Epoch: 0 Sample: 3830000 / 53735682 Loss: 1.617035115769796\n",
      "Epoch: 0 Sample: 3840000 / 53735682 Loss: 1.6102352680570757\n",
      "Epoch: 0 Sample: 3850000 / 53735682 Loss: 1.696084709547938\n",
      "Epoch: 0 Sample: 3860000 / 53735682 Loss: 1.550970448720862\n",
      "Epoch: 0 Sample: 3870000 / 53735682 Loss: 1.5818067110646834\n",
      "Epoch: 0 Sample: 3880000 / 53735682 Loss: 1.4583509504285415\n",
      "Epoch: 0 Sample: 3890000 / 53735682 Loss: 1.5067008080770026\n",
      "Epoch: 0 Sample: 3900000 / 53735682 Loss: 1.519833762039673\n",
      "Epoch: 0 Sample: 3910000 / 53735682 Loss: 1.690049020826757\n",
      "Epoch: 0 Sample: 3920000 / 53735682 Loss: 1.5906721263854413\n",
      "Epoch: 0 Sample: 3930000 / 53735682 Loss: 1.5055907495156626\n",
      "Epoch: 0 Sample: 3940000 / 53735682 Loss: 1.5549324086567342\n",
      "Epoch: 0 Sample: 3950000 / 53735682 Loss: 1.6032866432171167\n",
      "Epoch: 0 Sample: 3960000 / 53735682 Loss: 1.5324284699386026\n",
      "Epoch: 0 Sample: 3970000 / 53735682 Loss: 1.6010960421033285\n",
      "Epoch: 0 Sample: 3980000 / 53735682 Loss: 1.5341776981003212\n",
      "Epoch: 0 Sample: 3990000 / 53735682 Loss: 1.4780230665654999\n",
      "Epoch: 0 Sample: 4000000 / 53735682 Loss: 1.5670840164912563\n",
      "Epoch: 0 Sample: 4010000 / 53735682 Loss: 1.590675693962075\n",
      "Epoch: 0 Sample: 4020000 / 53735682 Loss: 1.5867052218992703\n",
      "Epoch: 0 Sample: 4030000 / 53735682 Loss: 1.6212577390015233\n",
      "Epoch: 0 Sample: 4040000 / 53735682 Loss: 1.4886631656379468\n",
      "Epoch: 0 Sample: 4050000 / 53735682 Loss: 1.5625020473666358\n",
      "Epoch: 0 Sample: 4060000 / 53735682 Loss: 1.4862615587953316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 4070000 / 53735682 Loss: 1.543395957626355\n",
      "Epoch: 0 Sample: 4080000 / 53735682 Loss: 1.533213698755787\n",
      "Epoch: 0 Sample: 4090000 / 53735682 Loss: 1.612226196869408\n",
      "Epoch: 0 Sample: 4100000 / 53735682 Loss: 1.5651176535738318\n",
      "Epoch: 0 Sample: 4110000 / 53735682 Loss: 1.5941482370334006\n",
      "Epoch: 0 Sample: 4120000 / 53735682 Loss: 1.5616701835992768\n",
      "Epoch: 0 Sample: 4130000 / 53735682 Loss: 1.4871996410252857\n",
      "Epoch: 0 Sample: 4140000 / 53735682 Loss: 1.537045124798975\n",
      "Epoch: 0 Sample: 4150000 / 53735682 Loss: 1.5928185049597818\n",
      "Epoch: 0 Sample: 4160000 / 53735682 Loss: 1.5423253199056117\n",
      "Epoch: 0 Sample: 4170000 / 53735682 Loss: 1.5970725698041914\n",
      "Epoch: 0 Sample: 4180000 / 53735682 Loss: 1.5558288206252027\n",
      "Epoch: 0 Sample: 4190000 / 53735682 Loss: 1.6770278392084257\n",
      "Epoch: 0 Sample: 4200000 / 53735682 Loss: 1.5438015154186653\n",
      "Epoch: 0 Sample: 4210000 / 53735682 Loss: 1.5082151357610232\n",
      "Epoch: 0 Sample: 4220000 / 53735682 Loss: 1.452638202433522\n",
      "Epoch: 0 Sample: 4230000 / 53735682 Loss: 1.5891326245085544\n",
      "Epoch: 0 Sample: 4240000 / 53735682 Loss: 1.528005230524181\n",
      "Epoch: 0 Sample: 4250000 / 53735682 Loss: 1.5600159409189178\n",
      "Epoch: 0 Sample: 4260000 / 53735682 Loss: 1.5294294351865139\n",
      "Epoch: 0 Sample: 4270000 / 53735682 Loss: 1.6079322143011714\n",
      "Epoch: 0 Sample: 4280000 / 53735682 Loss: 1.6838368813916256\n",
      "Epoch: 0 Sample: 4290000 / 53735682 Loss: 1.5055483869428175\n",
      "Epoch: 0 Sample: 4300000 / 53735682 Loss: 1.5139390856136108\n",
      "Epoch: 0 Sample: 4310000 / 53735682 Loss: 1.572841045186038\n",
      "Epoch: 0 Sample: 4320000 / 53735682 Loss: 1.527418458407706\n",
      "Epoch: 0 Sample: 4330000 / 53735682 Loss: 1.5959062197950629\n",
      "Epoch: 0 Sample: 4340000 / 53735682 Loss: 1.515240204138927\n",
      "Epoch: 0 Sample: 4350000 / 53735682 Loss: 1.6217247133847434\n",
      "Epoch: 0 Sample: 4360000 / 53735682 Loss: 1.5908542301802857\n",
      "Epoch: 0 Sample: 4370000 / 53735682 Loss: 1.5248374302890495\n",
      "Epoch: 0 Sample: 4380000 / 53735682 Loss: 1.446712075808186\n",
      "Epoch: 0 Sample: 4390000 / 53735682 Loss: 1.5768571495545385\n",
      "Epoch: 0 Sample: 4400000 / 53735682 Loss: 1.515049441808564\n",
      "Epoch: 0 Sample: 4410000 / 53735682 Loss: 1.5150739467458825\n",
      "Epoch: 0 Sample: 4420000 / 53735682 Loss: 1.5045010774004643\n",
      "Epoch: 0 Sample: 4430000 / 53735682 Loss: 1.5783619920876486\n",
      "Epoch: 0 Sample: 4440000 / 53735682 Loss: 1.5918864611254195\n",
      "Epoch: 0 Sample: 4450000 / 53735682 Loss: 1.5196440285874027\n",
      "Epoch: 0 Sample: 4460000 / 53735682 Loss: 1.5371336120644779\n",
      "Epoch: 0 Sample: 4470000 / 53735682 Loss: 1.5242677886593938\n",
      "Epoch: 0 Sample: 4480000 / 53735682 Loss: 1.5529089847274853\n",
      "Epoch: 0 Sample: 4490000 / 53735682 Loss: 1.588864691449978\n",
      "Epoch: 0 Sample: 4500000 / 53735682 Loss: 1.5702329188804494\n",
      "Epoch: 0 Sample: 4510000 / 53735682 Loss: 1.4932675399678774\n",
      "Epoch: 0 Sample: 4520000 / 53735682 Loss: 1.6619802927221652\n",
      "Epoch: 0 Sample: 4530000 / 53735682 Loss: 1.5276751090811227\n",
      "Epoch: 0 Sample: 4540000 / 53735682 Loss: 1.4857562709446162\n",
      "Epoch: 0 Sample: 4550000 / 53735682 Loss: 1.5383518528231268\n",
      "Epoch: 0 Sample: 4560000 / 53735682 Loss: 1.574411040935215\n",
      "Epoch: 0 Sample: 4570000 / 53735682 Loss: 1.5833845215610376\n",
      "Epoch: 0 Sample: 4580000 / 53735682 Loss: 1.563867543881146\n",
      "Epoch: 0 Sample: 4590000 / 53735682 Loss: 1.5804470388246739\n",
      "Epoch: 0 Sample: 4600000 / 53735682 Loss: 1.509292669603918\n",
      "Epoch: 0 Sample: 4610000 / 53735682 Loss: 1.6179030422467071\n",
      "Epoch: 0 Sample: 4620000 / 53735682 Loss: 1.5607583165957684\n",
      "Epoch: 0 Sample: 4630000 / 53735682 Loss: 1.6196249088269585\n",
      "Epoch: 0 Sample: 4640000 / 53735682 Loss: 1.583860832106794\n",
      "Epoch: 0 Sample: 4650000 / 53735682 Loss: 1.5708631568532705\n",
      "Epoch: 0 Sample: 4660000 / 53735682 Loss: 1.603949965440779\n",
      "Epoch: 0 Sample: 4670000 / 53735682 Loss: 1.626491452719248\n",
      "Epoch: 0 Sample: 4680000 / 53735682 Loss: 1.5539106814746853\n",
      "Epoch: 0 Sample: 4690000 / 53735682 Loss: 1.4748804895522716\n",
      "Epoch: 0 Sample: 4700000 / 53735682 Loss: 1.6012661064482314\n",
      "Epoch: 0 Sample: 4710000 / 53735682 Loss: 1.521795723464964\n",
      "Epoch: 0 Sample: 4720000 / 53735682 Loss: 1.5384119872315565\n",
      "Epoch: 0 Sample: 4730000 / 53735682 Loss: 1.620187714460729\n",
      "Epoch: 0 Sample: 4740000 / 53735682 Loss: 1.5584541825392708\n",
      "Epoch: 0 Sample: 4750000 / 53735682 Loss: 1.5799725625564534\n",
      "Epoch: 0 Sample: 4760000 / 53735682 Loss: 1.5398317248340705\n",
      "Epoch: 0 Sample: 4770000 / 53735682 Loss: 1.6012367403524448\n",
      "Epoch: 0 Sample: 4780000 / 53735682 Loss: 1.5419051864165645\n",
      "Epoch: 0 Sample: 4790000 / 53735682 Loss: 1.5974867208721286\n",
      "Epoch: 0 Sample: 4800000 / 53735682 Loss: 1.7226537707012306\n",
      "Epoch: 0 Sample: 4810000 / 53735682 Loss: 1.567893545392204\n",
      "Epoch: 0 Sample: 4820000 / 53735682 Loss: 1.5148252256079529\n",
      "Epoch: 0 Sample: 4830000 / 53735682 Loss: 1.5559743850314784\n",
      "Epoch: 0 Sample: 4840000 / 53735682 Loss: 1.5727224803529336\n",
      "Epoch: 0 Sample: 4850000 / 53735682 Loss: 1.6056647211240098\n",
      "Epoch: 0 Sample: 4860000 / 53735682 Loss: 1.5777133976593736\n",
      "Epoch: 0 Sample: 4870000 / 53735682 Loss: 1.5325647454748332\n",
      "Epoch: 0 Sample: 4880000 / 53735682 Loss: 1.4638779694917932\n",
      "Epoch: 0 Sample: 4890000 / 53735682 Loss: 1.5396275506992345\n",
      "Epoch: 0 Sample: 4900000 / 53735682 Loss: 1.506361775526142\n",
      "Epoch: 0 Sample: 4910000 / 53735682 Loss: 1.522243558903321\n",
      "Epoch: 0 Sample: 4920000 / 53735682 Loss: 1.6134801826783796\n",
      "Epoch: 0 Sample: 4930000 / 53735682 Loss: 1.5396508309280938\n",
      "Epoch: 0 Sample: 4940000 / 53735682 Loss: 1.6286452049272198\n",
      "Epoch: 0 Sample: 4950000 / 53735682 Loss: 1.6846623758048618\n",
      "Epoch: 0 Sample: 4960000 / 53735682 Loss: 1.571987487373116\n",
      "Epoch: 0 Sample: 4970000 / 53735682 Loss: 1.572827471302138\n",
      "Epoch: 0 Sample: 4980000 / 53735682 Loss: 1.5806708799551243\n",
      "Epoch: 0 Sample: 4990000 / 53735682 Loss: 1.5617393829307533\n",
      "Epoch: 0 Sample: 5000000 / 53735682 Loss: 1.6029765972408037\n",
      "Epoch: 0 Sample: 5010000 / 53735682 Loss: 1.579435974674646\n",
      "Epoch: 0 Sample: 5020000 / 53735682 Loss: 1.5863448123816746\n",
      "Epoch: 0 Sample: 5030000 / 53735682 Loss: 1.5422657624090808\n",
      "Epoch: 0 Sample: 5040000 / 53735682 Loss: 1.5106160993608293\n",
      "Epoch: 0 Sample: 5050000 / 53735682 Loss: 1.6549453288343248\n",
      "Epoch: 0 Sample: 5060000 / 53735682 Loss: 1.5697631016475693\n",
      "Epoch: 0 Sample: 5070000 / 53735682 Loss: 1.6160047668295974\n",
      "Epoch: 0 Sample: 5080000 / 53735682 Loss: 1.6271406024936932\n",
      "Epoch: 0 Sample: 5090000 / 53735682 Loss: 1.6950350593334123\n",
      "Epoch: 0 Sample: 5100000 / 53735682 Loss: 1.565651379877893\n",
      "Epoch: 0 Sample: 5110000 / 53735682 Loss: 1.5162665672248283\n",
      "Epoch: 0 Sample: 5120000 / 53735682 Loss: 1.5065222021134534\n",
      "Epoch: 0 Sample: 5130000 / 53735682 Loss: 1.5020374693321208\n",
      "Epoch: 0 Sample: 5140000 / 53735682 Loss: 1.614361374824251\n",
      "Epoch: 0 Sample: 5150000 / 53735682 Loss: 1.5352223964475813\n",
      "Epoch: 0 Sample: 5160000 / 53735682 Loss: 1.584211537883474\n",
      "Epoch: 0 Sample: 5170000 / 53735682 Loss: 1.4803173759094355\n",
      "Epoch: 0 Sample: 5180000 / 53735682 Loss: 1.5941482695397335\n",
      "Epoch: 0 Sample: 5190000 / 53735682 Loss: 1.652169858022884\n",
      "Epoch: 0 Sample: 5200000 / 53735682 Loss: 1.5523312333973234\n",
      "Epoch: 0 Sample: 5210000 / 53735682 Loss: 1.5903694900796248\n",
      "Epoch: 0 Sample: 5220000 / 53735682 Loss: 1.4949435627079493\n",
      "Epoch: 0 Sample: 5230000 / 53735682 Loss: 1.5175958488655161\n",
      "Epoch: 0 Sample: 5240000 / 53735682 Loss: 1.6531799379806853\n",
      "Epoch: 0 Sample: 5250000 / 53735682 Loss: 1.5051142413973264\n",
      "Epoch: 0 Sample: 5260000 / 53735682 Loss: 1.5755691143178612\n",
      "Epoch: 0 Sample: 5270000 / 53735682 Loss: 1.5401415601337982\n",
      "Epoch: 0 Sample: 5280000 / 53735682 Loss: 1.4566112688864696\n",
      "Epoch: 0 Sample: 5290000 / 53735682 Loss: 1.6115080662240895\n",
      "Epoch: 0 Sample: 5300000 / 53735682 Loss: 1.588750778139992\n",
      "Epoch: 0 Sample: 5310000 / 53735682 Loss: 1.4819654105093076\n",
      "Epoch: 0 Sample: 5320000 / 53735682 Loss: 1.5312567805221753\n",
      "Epoch: 0 Sample: 5330000 / 53735682 Loss: 1.4577807208575504\n",
      "Epoch: 0 Sample: 5340000 / 53735682 Loss: 1.537375037670607\n",
      "Epoch: 0 Sample: 5350000 / 53735682 Loss: 1.5110581262760374\n",
      "Epoch: 0 Sample: 5360000 / 53735682 Loss: 1.5070449579997125\n",
      "Epoch: 0 Sample: 5370000 / 53735682 Loss: 1.5486821535082946\n",
      "Epoch: 0 Sample: 5380000 / 53735682 Loss: 1.563486703410912\n",
      "Epoch: 0 Sample: 5390000 / 53735682 Loss: 1.5456779122402717\n",
      "Epoch: 0 Sample: 5400000 / 53735682 Loss: 1.617453488297428\n",
      "Epoch: 0 Sample: 5410000 / 53735682 Loss: 1.5775726912416852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 5420000 / 53735682 Loss: 1.5323301295900156\n",
      "Epoch: 0 Sample: 5430000 / 53735682 Loss: 1.5896626839101011\n",
      "Epoch: 0 Sample: 5440000 / 53735682 Loss: 1.561784065000314\n",
      "Epoch: 0 Sample: 5450000 / 53735682 Loss: 1.4861945367201814\n",
      "Epoch: 0 Sample: 5460000 / 53735682 Loss: 1.507683036010505\n",
      "Epoch: 0 Sample: 5470000 / 53735682 Loss: 1.5020599154842151\n",
      "Epoch: 0 Sample: 5480000 / 53735682 Loss: 1.576074083090575\n",
      "Epoch: 0 Sample: 5490000 / 53735682 Loss: 1.4917538965863626\n",
      "Epoch: 0 Sample: 5500000 / 53735682 Loss: 1.4990005653713543\n",
      "Epoch: 0 Sample: 5510000 / 53735682 Loss: 1.5583017034458535\n",
      "Epoch: 0 Sample: 5520000 / 53735682 Loss: 1.5095594673136352\n",
      "Epoch: 0 Sample: 5530000 / 53735682 Loss: 1.4898553399236865\n",
      "Epoch: 0 Sample: 5540000 / 53735682 Loss: 1.5061577722777442\n",
      "Epoch: 0 Sample: 5550000 / 53735682 Loss: 1.5534569940770488\n",
      "Epoch: 0 Sample: 5560000 / 53735682 Loss: 1.520783586342151\n",
      "Epoch: 0 Sample: 5570000 / 53735682 Loss: 1.6325475123988809\n",
      "Epoch: 0 Sample: 5580000 / 53735682 Loss: 1.5753108216610587\n",
      "Epoch: 0 Sample: 5590000 / 53735682 Loss: 1.6087174889130236\n",
      "Epoch: 0 Sample: 5600000 / 53735682 Loss: 1.6011416263778162\n",
      "Epoch: 0 Sample: 5610000 / 53735682 Loss: 1.5710347333688852\n",
      "Epoch: 0 Sample: 5620000 / 53735682 Loss: 1.5167225935170605\n",
      "Epoch: 0 Sample: 5630000 / 53735682 Loss: 1.4899023847616932\n",
      "Epoch: 0 Sample: 5640000 / 53735682 Loss: 1.4384062053551392\n",
      "Epoch: 0 Sample: 5650000 / 53735682 Loss: 1.4756675062021523\n",
      "Epoch: 0 Sample: 5660000 / 53735682 Loss: 1.4369939159402805\n",
      "Epoch: 0 Sample: 5670000 / 53735682 Loss: 1.5744143352747737\n",
      "Epoch: 0 Sample: 5680000 / 53735682 Loss: 1.522560331273451\n",
      "Epoch: 0 Sample: 5690000 / 53735682 Loss: 1.4577355719008764\n",
      "Epoch: 0 Sample: 5700000 / 53735682 Loss: 1.5174650256638818\n",
      "Epoch: 0 Sample: 5710000 / 53735682 Loss: 1.438611573355338\n",
      "Epoch: 0 Sample: 5720000 / 53735682 Loss: 1.54845376590358\n",
      "Epoch: 0 Sample: 5730000 / 53735682 Loss: 1.5423671550674927\n",
      "Epoch: 0 Sample: 5740000 / 53735682 Loss: 1.5136299826516262\n",
      "Epoch: 0 Sample: 5750000 / 53735682 Loss: 1.4345455361147397\n",
      "Epoch: 0 Sample: 5760000 / 53735682 Loss: 1.4975317872197673\n",
      "Epoch: 0 Sample: 5770000 / 53735682 Loss: 1.5181126034433352\n",
      "Epoch: 0 Sample: 5780000 / 53735682 Loss: 1.4766306738314094\n",
      "Epoch: 0 Sample: 5790000 / 53735682 Loss: 1.5848696954161854\n",
      "Epoch: 0 Sample: 5800000 / 53735682 Loss: 1.5292070888955134\n",
      "Epoch: 0 Sample: 5810000 / 53735682 Loss: 1.576685627286385\n",
      "Epoch: 0 Sample: 5820000 / 53735682 Loss: 1.5347757470477863\n",
      "Epoch: 0 Sample: 5830000 / 53735682 Loss: 1.4521841985451263\n",
      "Epoch: 0 Sample: 5840000 / 53735682 Loss: 1.5681479789875996\n",
      "Epoch: 0 Sample: 5850000 / 53735682 Loss: 1.493671507160584\n",
      "Epoch: 0 Sample: 5860000 / 53735682 Loss: 1.5388683816917976\n",
      "Epoch: 0 Sample: 5870000 / 53735682 Loss: 1.4935667119661042\n",
      "Epoch: 0 Sample: 5880000 / 53735682 Loss: 1.5277500073675303\n",
      "Epoch: 0 Sample: 5890000 / 53735682 Loss: 1.564222012232666\n",
      "Epoch: 0 Sample: 5900000 / 53735682 Loss: 1.4970678501920778\n",
      "Epoch: 0 Sample: 5910000 / 53735682 Loss: 1.5440989483340826\n",
      "Epoch: 0 Sample: 5920000 / 53735682 Loss: 1.4927595924978734\n",
      "Epoch: 0 Sample: 5930000 / 53735682 Loss: 1.568249175907476\n",
      "Epoch: 0 Sample: 5940000 / 53735682 Loss: 1.5437005409006952\n",
      "Epoch: 0 Sample: 5950000 / 53735682 Loss: 1.4848727523933791\n",
      "Epoch: 0 Sample: 5960000 / 53735682 Loss: 1.5021048320706039\n",
      "Epoch: 0 Sample: 5970000 / 53735682 Loss: 1.5939550015288653\n",
      "Epoch: 0 Sample: 5980000 / 53735682 Loss: 1.5413044254285255\n",
      "Epoch: 0 Sample: 5990000 / 53735682 Loss: 1.5097624256679416\n",
      "Epoch: 0 Sample: 6000000 / 53735682 Loss: 1.5234135099037864\n",
      "Epoch: 0 Sample: 6010000 / 53735682 Loss: 1.5219573938983002\n",
      "Epoch: 0 Sample: 6020000 / 53735682 Loss: 1.4976063897212981\n",
      "Epoch: 0 Sample: 6030000 / 53735682 Loss: 1.5351856132917527\n",
      "Epoch: 0 Sample: 6040000 / 53735682 Loss: 1.4462786156406584\n",
      "Epoch: 0 Sample: 6050000 / 53735682 Loss: 1.5593880173516301\n",
      "Epoch: 0 Sample: 6060000 / 53735682 Loss: 1.46246176182337\n",
      "Epoch: 0 Sample: 6070000 / 53735682 Loss: 1.5522627491449674\n",
      "Epoch: 0 Sample: 6080000 / 53735682 Loss: 1.5688298803236154\n",
      "Epoch: 0 Sample: 6090000 / 53735682 Loss: 1.5843872907713168\n",
      "Epoch: 0 Sample: 6100000 / 53735682 Loss: 1.6695878330575629\n",
      "Epoch: 0 Sample: 6110000 / 53735682 Loss: 1.5011745708376905\n",
      "Epoch: 0 Sample: 6120000 / 53735682 Loss: 1.512679536828418\n",
      "Epoch: 0 Sample: 6130000 / 53735682 Loss: 1.4979604771778727\n",
      "Epoch: 0 Sample: 6140000 / 53735682 Loss: 1.5173229937299686\n",
      "Epoch: 0 Sample: 6150000 / 53735682 Loss: 1.4335249521304547\n",
      "Epoch: 0 Sample: 6160000 / 53735682 Loss: 1.4964116865511132\n",
      "Epoch: 0 Sample: 6170000 / 53735682 Loss: 1.454207941841187\n",
      "Epoch: 0 Sample: 6180000 / 53735682 Loss: 1.4532577248321537\n",
      "Epoch: 0 Sample: 6190000 / 53735682 Loss: 1.4349503647296795\n",
      "Epoch: 0 Sample: 6200000 / 53735682 Loss: 1.4760104539973147\n",
      "Epoch: 0 Sample: 6210000 / 53735682 Loss: 1.4619133971220963\n",
      "Epoch: 0 Sample: 6220000 / 53735682 Loss: 1.6540193544474122\n",
      "Epoch: 0 Sample: 6230000 / 53735682 Loss: 1.532026990734897\n",
      "Epoch: 0 Sample: 6240000 / 53735682 Loss: 1.5064263871171228\n",
      "Epoch: 0 Sample: 6250000 / 53735682 Loss: 1.4482810402942023\n",
      "Epoch: 0 Sample: 6260000 / 53735682 Loss: 1.5090257076102527\n",
      "Epoch: 0 Sample: 6270000 / 53735682 Loss: 1.5114604203175286\n",
      "Epoch: 0 Sample: 6280000 / 53735682 Loss: 1.420300082721217\n",
      "Epoch: 0 Sample: 6290000 / 53735682 Loss: 1.4588392145051094\n",
      "Epoch: 0 Sample: 6300000 / 53735682 Loss: 1.5208493459288512\n",
      "Epoch: 0 Sample: 6310000 / 53735682 Loss: 1.4952778757257528\n",
      "Epoch: 0 Sample: 6320000 / 53735682 Loss: 1.5554776728023676\n",
      "Epoch: 0 Sample: 6330000 / 53735682 Loss: 1.5511206359720866\n",
      "Epoch: 0 Sample: 6340000 / 53735682 Loss: 1.5494326385546637\n",
      "Epoch: 0 Sample: 6350000 / 53735682 Loss: 1.4301344896590313\n",
      "Epoch: 0 Sample: 6360000 / 53735682 Loss: 1.4684005720670732\n",
      "Epoch: 0 Sample: 6370000 / 53735682 Loss: 1.60437907388772\n",
      "Epoch: 0 Sample: 6380000 / 53735682 Loss: 1.469545299287898\n",
      "Epoch: 0 Sample: 6390000 / 53735682 Loss: 1.533400166675742\n",
      "Epoch: 0 Sample: 6400000 / 53735682 Loss: 1.4924294455204996\n",
      "Epoch: 0 Sample: 6410000 / 53735682 Loss: 1.4194961115970033\n",
      "Epoch: 0 Sample: 6420000 / 53735682 Loss: 1.5064611936071746\n",
      "Epoch: 0 Sample: 6430000 / 53735682 Loss: 1.518750642713051\n",
      "Epoch: 0 Sample: 6440000 / 53735682 Loss: 1.505474786648903\n",
      "Epoch: 0 Sample: 6450000 / 53735682 Loss: 1.4736276958518777\n",
      "Epoch: 0 Sample: 6460000 / 53735682 Loss: 1.5229322453260061\n",
      "Epoch: 0 Sample: 6470000 / 53735682 Loss: 1.485216231492164\n",
      "Epoch: 0 Sample: 6480000 / 53735682 Loss: 1.4282670373063524\n",
      "Epoch: 0 Sample: 6490000 / 53735682 Loss: 1.4931782897325574\n",
      "Epoch: 0 Sample: 6500000 / 53735682 Loss: 1.4669871074107266\n",
      "Epoch: 0 Sample: 6510000 / 53735682 Loss: 1.5573025170037502\n",
      "Epoch: 0 Sample: 6520000 / 53735682 Loss: 1.4105338284882216\n",
      "Epoch: 0 Sample: 6530000 / 53735682 Loss: 1.5282201013248802\n",
      "Epoch: 0 Sample: 6540000 / 53735682 Loss: 1.464743700588961\n",
      "Epoch: 0 Sample: 6550000 / 53735682 Loss: 1.5756466243542566\n",
      "Epoch: 0 Sample: 6560000 / 53735682 Loss: 1.522635455175886\n",
      "Epoch: 0 Sample: 6570000 / 53735682 Loss: 1.5009755062225278\n",
      "Epoch: 0 Sample: 6580000 / 53735682 Loss: 1.5560853294923866\n",
      "Epoch: 0 Sample: 6590000 / 53735682 Loss: 1.4816462439021114\n",
      "Epoch: 0 Sample: 6600000 / 53735682 Loss: 1.4909238602525812\n",
      "Epoch: 0 Sample: 6610000 / 53735682 Loss: 1.56080534912056\n",
      "Epoch: 0 Sample: 6620000 / 53735682 Loss: 1.537657164578207\n",
      "Epoch: 0 Sample: 6630000 / 53735682 Loss: 1.4799002393379725\n",
      "Epoch: 0 Sample: 6640000 / 53735682 Loss: 1.450930459457612\n",
      "Epoch: 0 Sample: 6650000 / 53735682 Loss: 1.5444540160437124\n",
      "Epoch: 0 Sample: 6660000 / 53735682 Loss: 1.4891374916440254\n",
      "Epoch: 0 Sample: 6670000 / 53735682 Loss: 1.540316071039326\n",
      "Epoch: 0 Sample: 6680000 / 53735682 Loss: 1.4994924817299964\n",
      "Epoch: 0 Sample: 6690000 / 53735682 Loss: 1.4996199025368615\n",
      "Epoch: 0 Sample: 6700000 / 53735682 Loss: 1.5004523091506021\n",
      "Epoch: 0 Sample: 6710000 / 53735682 Loss: 1.614460310919244\n",
      "Epoch: 0 Sample: 6720000 / 53735682 Loss: 1.4612852543809018\n",
      "Epoch: 0 Sample: 6730000 / 53735682 Loss: 1.5096803512483663\n",
      "Epoch: 0 Sample: 6740000 / 53735682 Loss: 1.4109818652815502\n",
      "Epoch: 0 Sample: 6750000 / 53735682 Loss: 1.511393584479821\n",
      "Epoch: 0 Sample: 6760000 / 53735682 Loss: 1.4242099771739387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 6770000 / 53735682 Loss: 1.4434295855520385\n",
      "Epoch: 0 Sample: 6780000 / 53735682 Loss: 1.5711079464059117\n",
      "Epoch: 0 Sample: 6790000 / 53735682 Loss: 1.559490452490696\n",
      "Epoch: 0 Sample: 6800000 / 53735682 Loss: 1.376239351812631\n",
      "Epoch: 0 Sample: 6810000 / 53735682 Loss: 1.4699988923886589\n",
      "Epoch: 0 Sample: 6820000 / 53735682 Loss: 1.4711835156657451\n",
      "Epoch: 0 Sample: 6830000 / 53735682 Loss: 1.4568270881621328\n",
      "Epoch: 0 Sample: 6840000 / 53735682 Loss: 1.4977121486020732\n",
      "Epoch: 0 Sample: 6850000 / 53735682 Loss: 1.5098113786598935\n",
      "Epoch: 0 Sample: 6860000 / 53735682 Loss: 1.5415651130857926\n",
      "Epoch: 0 Sample: 6870000 / 53735682 Loss: 1.4560621146791224\n",
      "Epoch: 0 Sample: 6880000 / 53735682 Loss: 1.4221046136675883\n",
      "Epoch: 0 Sample: 6890000 / 53735682 Loss: 1.5243775504588717\n",
      "Epoch: 0 Sample: 6900000 / 53735682 Loss: 1.436400209925375\n",
      "Epoch: 0 Sample: 6910000 / 53735682 Loss: 1.5109924160698411\n",
      "Epoch: 0 Sample: 6920000 / 53735682 Loss: 1.57691970378664\n",
      "Epoch: 0 Sample: 6930000 / 53735682 Loss: 1.4893594850870588\n",
      "Epoch: 0 Sample: 6940000 / 53735682 Loss: 1.53209568406708\n",
      "Epoch: 0 Sample: 6950000 / 53735682 Loss: 1.5029402268488719\n",
      "Epoch: 0 Sample: 6960000 / 53735682 Loss: 1.4598456054767617\n",
      "Epoch: 0 Sample: 6970000 / 53735682 Loss: 1.4616662005910566\n",
      "Epoch: 0 Sample: 6980000 / 53735682 Loss: 1.4789986749505155\n",
      "Epoch: 0 Sample: 6990000 / 53735682 Loss: 1.5138832682493923\n",
      "Epoch: 0 Sample: 7000000 / 53735682 Loss: 1.4657513146860357\n",
      "Epoch: 0 Sample: 7010000 / 53735682 Loss: 1.484165022403219\n",
      "Epoch: 0 Sample: 7020000 / 53735682 Loss: 1.4998747832109374\n",
      "Epoch: 0 Sample: 7030000 / 53735682 Loss: 1.373830519180905\n",
      "Epoch: 0 Sample: 7040000 / 53735682 Loss: 1.4906430400165962\n",
      "Epoch: 0 Sample: 7050000 / 53735682 Loss: 1.4917057898587067\n",
      "Epoch: 0 Sample: 7060000 / 53735682 Loss: 1.4568278570901705\n",
      "Epoch: 0 Sample: 7070000 / 53735682 Loss: 1.5586380106392714\n",
      "Epoch: 0 Sample: 7080000 / 53735682 Loss: 1.4913488417955802\n",
      "Epoch: 0 Sample: 7090000 / 53735682 Loss: 1.5240720491652457\n",
      "Epoch: 0 Sample: 7100000 / 53735682 Loss: 1.5075479260061946\n",
      "Epoch: 0 Sample: 7110000 / 53735682 Loss: 1.5091888532381592\n",
      "Epoch: 0 Sample: 7120000 / 53735682 Loss: 1.5602926583409236\n",
      "Epoch: 0 Sample: 7130000 / 53735682 Loss: 1.550969947364208\n",
      "Epoch: 0 Sample: 7140000 / 53735682 Loss: 1.5044422486979692\n",
      "Epoch: 0 Sample: 7150000 / 53735682 Loss: 1.4824926079580714\n",
      "Epoch: 0 Sample: 7160000 / 53735682 Loss: 1.544238713833795\n",
      "Epoch: 0 Sample: 7170000 / 53735682 Loss: 1.4037351966910163\n",
      "Epoch: 0 Sample: 7180000 / 53735682 Loss: 1.568341756859469\n",
      "Epoch: 0 Sample: 7190000 / 53735682 Loss: 1.5364208242879214\n",
      "Epoch: 0 Sample: 7200000 / 53735682 Loss: 1.4978840633070938\n",
      "Epoch: 0 Sample: 7210000 / 53735682 Loss: 1.5336777125391827\n",
      "Epoch: 0 Sample: 7220000 / 53735682 Loss: 1.5507948353655419\n",
      "Epoch: 0 Sample: 7230000 / 53735682 Loss: 1.5255015682321478\n",
      "Epoch: 0 Sample: 7240000 / 53735682 Loss: 1.4924616190422388\n",
      "Epoch: 0 Sample: 7250000 / 53735682 Loss: 1.4888242182726446\n",
      "Epoch: 0 Sample: 7260000 / 53735682 Loss: 1.554212976063989\n",
      "Epoch: 0 Sample: 7270000 / 53735682 Loss: 1.5036253179054866\n",
      "Epoch: 0 Sample: 7280000 / 53735682 Loss: 1.5527333999697528\n",
      "Epoch: 0 Sample: 7290000 / 53735682 Loss: 1.422789874971912\n",
      "Epoch: 0 Sample: 7300000 / 53735682 Loss: 1.4467448631045232\n",
      "Epoch: 0 Sample: 7310000 / 53735682 Loss: 1.6091309613863882\n",
      "Epoch: 0 Sample: 7320000 / 53735682 Loss: 1.5029508427937253\n",
      "Epoch: 0 Sample: 7330000 / 53735682 Loss: 1.504021062507594\n",
      "Epoch: 0 Sample: 7340000 / 53735682 Loss: 1.4038084900504064\n",
      "Epoch: 0 Sample: 7350000 / 53735682 Loss: 1.5926485770927994\n",
      "Epoch: 0 Sample: 7360000 / 53735682 Loss: 1.5447772442244592\n",
      "Epoch: 0 Sample: 7370000 / 53735682 Loss: 1.5069594698804183\n",
      "Epoch: 0 Sample: 7380000 / 53735682 Loss: 1.4582003560127565\n",
      "Epoch: 0 Sample: 7390000 / 53735682 Loss: 1.4961218250231143\n",
      "Epoch: 0 Sample: 7400000 / 53735682 Loss: 1.5670551433811868\n",
      "Epoch: 0 Sample: 7410000 / 53735682 Loss: 1.48441516143131\n",
      "Epoch: 0 Sample: 7420000 / 53735682 Loss: 1.4786346772667884\n",
      "Epoch: 0 Sample: 7430000 / 53735682 Loss: 1.5738110535817278\n",
      "Epoch: 0 Sample: 7440000 / 53735682 Loss: 1.5346403095618033\n",
      "Epoch: 0 Sample: 7450000 / 53735682 Loss: 1.4418941434467678\n",
      "Epoch: 0 Sample: 7460000 / 53735682 Loss: 1.433804655690551\n",
      "Epoch: 0 Sample: 7470000 / 53735682 Loss: 1.4769920492984314\n",
      "Epoch: 0 Sample: 7480000 / 53735682 Loss: 1.563842178145288\n",
      "Epoch: 0 Sample: 7490000 / 53735682 Loss: 1.5796653129458247\n",
      "Epoch: 0 Sample: 7500000 / 53735682 Loss: 1.5497419493412679\n",
      "Epoch: 0 Sample: 7510000 / 53735682 Loss: 1.5511331542824855\n",
      "Epoch: 0 Sample: 7520000 / 53735682 Loss: 1.534098707848382\n",
      "Epoch: 0 Sample: 7530000 / 53735682 Loss: 1.5921292530968412\n",
      "Epoch: 0 Sample: 7540000 / 53735682 Loss: 1.6303451602352625\n",
      "Epoch: 0 Sample: 7550000 / 53735682 Loss: 1.545373244623951\n",
      "Epoch: 0 Sample: 7560000 / 53735682 Loss: 1.542473142531199\n",
      "Epoch: 0 Sample: 7570000 / 53735682 Loss: 1.4788177556381645\n",
      "Epoch: 0 Sample: 7580000 / 53735682 Loss: 1.462839005934734\n",
      "Epoch: 0 Sample: 7590000 / 53735682 Loss: 1.522046405238263\n",
      "Epoch: 0 Sample: 7600000 / 53735682 Loss: 1.4952047332597518\n",
      "Epoch: 0 Sample: 7610000 / 53735682 Loss: 1.5022367293862926\n",
      "Epoch: 0 Sample: 7620000 / 53735682 Loss: 1.4498284408452071\n",
      "Epoch: 0 Sample: 7630000 / 53735682 Loss: 1.506307182033396\n",
      "Epoch: 0 Sample: 7640000 / 53735682 Loss: 1.5357808873493821\n",
      "Epoch: 0 Sample: 7650000 / 53735682 Loss: 1.5688599200511348\n",
      "Epoch: 0 Sample: 7660000 / 53735682 Loss: 1.4453813540875475\n",
      "Epoch: 0 Sample: 7670000 / 53735682 Loss: 1.5513259223453675\n",
      "Epoch: 0 Sample: 7680000 / 53735682 Loss: 1.4498918249961572\n",
      "Epoch: 0 Sample: 7690000 / 53735682 Loss: 1.531418173218522\n",
      "Epoch: 0 Sample: 7700000 / 53735682 Loss: 1.5494120979587689\n",
      "Epoch: 0 Sample: 7710000 / 53735682 Loss: 1.5387824200987112\n",
      "Epoch: 0 Sample: 7720000 / 53735682 Loss: 1.5200037471240075\n",
      "Epoch: 0 Sample: 7730000 / 53735682 Loss: 1.5437773874947434\n",
      "Epoch: 0 Sample: 7740000 / 53735682 Loss: 1.5121206446159796\n",
      "Epoch: 0 Sample: 7750000 / 53735682 Loss: 1.569193830267692\n",
      "Epoch: 0 Sample: 7760000 / 53735682 Loss: 1.4647551559381822\n",
      "Epoch: 0 Sample: 7770000 / 53735682 Loss: 1.4590137540782493\n",
      "Epoch: 0 Sample: 7780000 / 53735682 Loss: 1.5134790732523806\n",
      "Epoch: 0 Sample: 7790000 / 53735682 Loss: 1.548770416694948\n",
      "Epoch: 0 Sample: 7800000 / 53735682 Loss: 1.5211586962161558\n",
      "Epoch: 0 Sample: 7810000 / 53735682 Loss: 1.5602449136274543\n",
      "Epoch: 0 Sample: 7820000 / 53735682 Loss: 1.4940273557169619\n",
      "Epoch: 0 Sample: 7830000 / 53735682 Loss: 1.5391804647853067\n",
      "Epoch: 0 Sample: 7840000 / 53735682 Loss: 1.4425550826050988\n",
      "Epoch: 0 Sample: 7850000 / 53735682 Loss: 1.543588162885197\n",
      "Epoch: 0 Sample: 7860000 / 53735682 Loss: 1.5055275974651927\n",
      "Epoch: 0 Sample: 7870000 / 53735682 Loss: 1.5081026419005705\n",
      "Epoch: 0 Sample: 7880000 / 53735682 Loss: 1.5001352653303157\n",
      "Epoch: 0 Sample: 7890000 / 53735682 Loss: 1.5144307482748507\n",
      "Epoch: 0 Sample: 7900000 / 53735682 Loss: 1.6373591217300716\n",
      "Epoch: 0 Sample: 7910000 / 53735682 Loss: 1.5026007274077786\n",
      "Epoch: 0 Sample: 7920000 / 53735682 Loss: 1.5500931505125533\n",
      "Epoch: 0 Sample: 7930000 / 53735682 Loss: 1.4654782182040402\n",
      "Epoch: 0 Sample: 7940000 / 53735682 Loss: 1.5456630311721176\n",
      "Epoch: 0 Sample: 7950000 / 53735682 Loss: 1.4660970753983378\n",
      "Epoch: 0 Sample: 7960000 / 53735682 Loss: 1.5173016781067752\n",
      "Epoch: 0 Sample: 7970000 / 53735682 Loss: 1.497382950826612\n",
      "Epoch: 0 Sample: 7980000 / 53735682 Loss: 1.5603860051965297\n",
      "Epoch: 0 Sample: 7990000 / 53735682 Loss: 1.601796241282694\n",
      "Epoch: 0 Sample: 8000000 / 53735682 Loss: 1.523698589209072\n",
      "Epoch: 0 Sample: 8010000 / 53735682 Loss: 1.556974414066847\n",
      "Epoch: 0 Sample: 8020000 / 53735682 Loss: 1.5384879293510707\n",
      "Epoch: 0 Sample: 8030000 / 53735682 Loss: 1.5425385355693124\n",
      "Epoch: 0 Sample: 8040000 / 53735682 Loss: 1.5038995173636964\n",
      "Epoch: 0 Sample: 8050000 / 53735682 Loss: 1.5107284042429163\n",
      "Epoch: 0 Sample: 8060000 / 53735682 Loss: 1.5664073938695438\n",
      "Epoch: 0 Sample: 8070000 / 53735682 Loss: 1.4742439244058805\n",
      "Epoch: 0 Sample: 8080000 / 53735682 Loss: 1.538729714267739\n",
      "Epoch: 0 Sample: 8090000 / 53735682 Loss: 1.5270838077850526\n",
      "Epoch: 0 Sample: 8100000 / 53735682 Loss: 1.4933950289549203\n",
      "Epoch: 0 Sample: 8110000 / 53735682 Loss: 1.5414936698509571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 8120000 / 53735682 Loss: 1.5767597761304795\n",
      "Epoch: 0 Sample: 8130000 / 53735682 Loss: 1.5214153184368548\n",
      "Epoch: 0 Sample: 8140000 / 53735682 Loss: 1.5281471838260963\n",
      "Epoch: 0 Sample: 8150000 / 53735682 Loss: 1.5264935744582004\n",
      "Epoch: 0 Sample: 8160000 / 53735682 Loss: 1.483266786875355\n",
      "Epoch: 0 Sample: 8170000 / 53735682 Loss: 1.5377200711848398\n",
      "Epoch: 0 Sample: 8180000 / 53735682 Loss: 1.5945952674841692\n",
      "Epoch: 0 Sample: 8190000 / 53735682 Loss: 1.493177925115155\n",
      "Epoch: 0 Sample: 8200000 / 53735682 Loss: 1.493344142644065\n",
      "Epoch: 0 Sample: 8210000 / 53735682 Loss: 1.5105007205016947\n",
      "Epoch: 0 Sample: 8220000 / 53735682 Loss: 1.5497423637931655\n",
      "Epoch: 0 Sample: 8230000 / 53735682 Loss: 1.5329435515962357\n",
      "Epoch: 0 Sample: 8240000 / 53735682 Loss: 1.5438242081198414\n",
      "Epoch: 0 Sample: 8250000 / 53735682 Loss: 1.5924917465484543\n",
      "Epoch: 0 Sample: 8260000 / 53735682 Loss: 1.5212042863101767\n",
      "Epoch: 0 Sample: 8270000 / 53735682 Loss: 1.5295195973444833\n",
      "Epoch: 0 Sample: 8280000 / 53735682 Loss: 1.5432132157361762\n",
      "Epoch: 0 Sample: 8290000 / 53735682 Loss: 1.4902763402452963\n",
      "Epoch: 0 Sample: 8300000 / 53735682 Loss: 1.5357454456437474\n",
      "Epoch: 0 Sample: 8310000 / 53735682 Loss: 1.5493566601406026\n",
      "Epoch: 0 Sample: 8320000 / 53735682 Loss: 1.4712722480472102\n",
      "Epoch: 0 Sample: 8330000 / 53735682 Loss: 1.451336573577482\n",
      "Epoch: 0 Sample: 8340000 / 53735682 Loss: 1.5130604259790363\n",
      "Epoch: 0 Sample: 8350000 / 53735682 Loss: 1.5735868182351127\n",
      "Epoch: 0 Sample: 8360000 / 53735682 Loss: 1.4888250431350225\n",
      "Epoch: 0 Sample: 8370000 / 53735682 Loss: 1.4873005517628988\n",
      "Epoch: 0 Sample: 8380000 / 53735682 Loss: 1.4940931301679319\n",
      "Epoch: 0 Sample: 8390000 / 53735682 Loss: 1.5164518000095173\n",
      "Epoch: 0 Sample: 8400000 / 53735682 Loss: 1.5452218238541175\n",
      "Epoch: 0 Sample: 8410000 / 53735682 Loss: 1.4962974978566554\n",
      "Epoch: 0 Sample: 8420000 / 53735682 Loss: 1.5822074312266672\n",
      "Epoch: 0 Sample: 8430000 / 53735682 Loss: 1.483979351711561\n",
      "Epoch: 0 Sample: 8440000 / 53735682 Loss: 1.5453187022105799\n",
      "Epoch: 0 Sample: 8450000 / 53735682 Loss: 1.52332466688291\n",
      "Epoch: 0 Sample: 8460000 / 53735682 Loss: 1.4266424113562994\n",
      "Epoch: 0 Sample: 8470000 / 53735682 Loss: 1.5090741421674272\n",
      "Epoch: 0 Sample: 8480000 / 53735682 Loss: 1.4775235212460132\n",
      "Epoch: 0 Sample: 8490000 / 53735682 Loss: 1.5219573547416057\n",
      "Epoch: 0 Sample: 8500000 / 53735682 Loss: 1.4437830059949341\n",
      "Epoch: 0 Sample: 8510000 / 53735682 Loss: 1.557822852211726\n",
      "Epoch: 0 Sample: 8520000 / 53735682 Loss: 1.5551681837163938\n",
      "Epoch: 0 Sample: 8530000 / 53735682 Loss: 1.5119382969652642\n",
      "Epoch: 0 Sample: 8540000 / 53735682 Loss: 1.5070338576626332\n",
      "Epoch: 0 Sample: 8550000 / 53735682 Loss: 1.49995303167072\n",
      "Epoch: 0 Sample: 8560000 / 53735682 Loss: 1.5539514343643315\n",
      "Epoch: 0 Sample: 8570000 / 53735682 Loss: 1.5470175525809258\n",
      "Epoch: 0 Sample: 8580000 / 53735682 Loss: 1.4958379360638698\n",
      "Epoch: 0 Sample: 8590000 / 53735682 Loss: 1.5170361944711006\n",
      "Epoch: 0 Sample: 8600000 / 53735682 Loss: 1.566550507447141\n",
      "Epoch: 0 Sample: 8610000 / 53735682 Loss: 1.5048280197391075\n",
      "Epoch: 0 Sample: 8620000 / 53735682 Loss: 1.446314922270032\n",
      "Epoch: 0 Sample: 8630000 / 53735682 Loss: 1.4209286352974408\n",
      "Epoch: 0 Sample: 8640000 / 53735682 Loss: 1.5186215518178678\n",
      "Epoch: 0 Sample: 8650000 / 53735682 Loss: 1.5667777313944575\n",
      "Epoch: 0 Sample: 8660000 / 53735682 Loss: 1.4394337898242255\n",
      "Epoch: 0 Sample: 8670000 / 53735682 Loss: 1.6201497449678701\n",
      "Epoch: 0 Sample: 8680000 / 53735682 Loss: 1.5393449313276608\n",
      "Epoch: 0 Sample: 8690000 / 53735682 Loss: 1.477626797043464\n",
      "Epoch: 0 Sample: 8700000 / 53735682 Loss: 1.5356982834935642\n",
      "Epoch: 0 Sample: 8710000 / 53735682 Loss: 1.5662899106071668\n",
      "Epoch: 0 Sample: 8720000 / 53735682 Loss: 1.5080951519825387\n",
      "Epoch: 0 Sample: 8730000 / 53735682 Loss: 1.5492912566069297\n",
      "Epoch: 0 Sample: 8740000 / 53735682 Loss: 1.5014088278742812\n",
      "Epoch: 0 Sample: 8750000 / 53735682 Loss: 1.483366041108312\n",
      "Epoch: 0 Sample: 8760000 / 53735682 Loss: 1.5479658110980767\n",
      "Epoch: 0 Sample: 8770000 / 53735682 Loss: 1.5834876206694326\n",
      "Epoch: 0 Sample: 8780000 / 53735682 Loss: 1.5508530902979185\n",
      "Epoch: 0 Sample: 8790000 / 53735682 Loss: 1.5064947390309533\n",
      "Epoch: 0 Sample: 8800000 / 53735682 Loss: 1.4978648782077475\n",
      "Epoch: 0 Sample: 8810000 / 53735682 Loss: 1.457034508796368\n",
      "Epoch: 0 Sample: 8820000 / 53735682 Loss: 1.6034853541867204\n",
      "Epoch: 0 Sample: 8830000 / 53735682 Loss: 1.4376624364884596\n",
      "Epoch: 0 Sample: 8840000 / 53735682 Loss: 1.57266659865261\n",
      "Epoch: 0 Sample: 8850000 / 53735682 Loss: 1.5315788617485373\n",
      "Epoch: 0 Sample: 8860000 / 53735682 Loss: 1.5461934991737791\n",
      "Epoch: 0 Sample: 8870000 / 53735682 Loss: 1.5098582462500378\n",
      "Epoch: 0 Sample: 8880000 / 53735682 Loss: 1.4738093517671516\n",
      "Epoch: 0 Sample: 8890000 / 53735682 Loss: 1.4934952370732715\n",
      "Epoch: 0 Sample: 8900000 / 53735682 Loss: 1.5369220089705173\n",
      "Epoch: 0 Sample: 8910000 / 53735682 Loss: 1.4179540897954754\n",
      "Epoch: 0 Sample: 8920000 / 53735682 Loss: 1.543893234940057\n",
      "Epoch: 0 Sample: 8930000 / 53735682 Loss: 1.5516015936336491\n",
      "Epoch: 0 Sample: 8940000 / 53735682 Loss: 1.5558147283039578\n",
      "Epoch: 0 Sample: 8950000 / 53735682 Loss: 1.576627535436799\n",
      "Epoch: 0 Sample: 8960000 / 53735682 Loss: 1.502816494945138\n",
      "Epoch: 0 Sample: 8970000 / 53735682 Loss: 1.5094375124430042\n",
      "Epoch: 0 Sample: 8980000 / 53735682 Loss: 1.4883939692548023\n",
      "Epoch: 0 Sample: 8990000 / 53735682 Loss: 1.5523074039615505\n",
      "Epoch: 0 Sample: 9000000 / 53735682 Loss: 1.586599077542856\n",
      "Epoch: 0 Sample: 9010000 / 53735682 Loss: 1.5441623575287255\n",
      "Epoch: 0 Sample: 9020000 / 53735682 Loss: 1.5367606080832343\n",
      "Epoch: 0 Sample: 9030000 / 53735682 Loss: 1.5545055174913267\n",
      "Epoch: 0 Sample: 9040000 / 53735682 Loss: 1.4931811774016255\n",
      "Epoch: 0 Sample: 9050000 / 53735682 Loss: 1.5292078515102543\n",
      "Epoch: 0 Sample: 9060000 / 53735682 Loss: 1.5849921642071112\n",
      "Epoch: 0 Sample: 9070000 / 53735682 Loss: 1.3910816489636209\n",
      "Epoch: 0 Sample: 9080000 / 53735682 Loss: 1.5362131381848785\n",
      "Epoch: 0 Sample: 9090000 / 53735682 Loss: 1.4779897900014562\n",
      "Epoch: 0 Sample: 9100000 / 53735682 Loss: 1.4669729788161503\n",
      "Epoch: 0 Sample: 9110000 / 53735682 Loss: 1.429284511676191\n",
      "Epoch: 0 Sample: 9120000 / 53735682 Loss: 1.582630330864899\n",
      "Epoch: 0 Sample: 9130000 / 53735682 Loss: 1.5067371083786738\n",
      "Epoch: 0 Sample: 9140000 / 53735682 Loss: 1.4675887008093231\n",
      "Epoch: 0 Sample: 9150000 / 53735682 Loss: 1.5449970600491423\n",
      "Epoch: 0 Sample: 9160000 / 53735682 Loss: 1.4945205159222525\n",
      "Epoch: 0 Sample: 9170000 / 53735682 Loss: 1.5332498707687814\n",
      "Epoch: 0 Sample: 9180000 / 53735682 Loss: 1.5323843196486358\n",
      "Epoch: 0 Sample: 9190000 / 53735682 Loss: 1.5260295914514277\n",
      "Epoch: 0 Sample: 9200000 / 53735682 Loss: 1.562220227765077\n",
      "Epoch: 0 Sample: 9210000 / 53735682 Loss: 1.5093955234063987\n",
      "Epoch: 0 Sample: 9220000 / 53735682 Loss: 1.5216505445008393\n",
      "Epoch: 0 Sample: 9230000 / 53735682 Loss: 1.5603082693745982\n",
      "Epoch: 0 Sample: 9240000 / 53735682 Loss: 1.551991245198606\n",
      "Epoch: 0 Sample: 9250000 / 53735682 Loss: 1.5353488857305462\n",
      "Epoch: 0 Sample: 9260000 / 53735682 Loss: 1.4602894481367201\n",
      "Epoch: 0 Sample: 9270000 / 53735682 Loss: 1.5239302707725895\n",
      "Epoch: 0 Sample: 9280000 / 53735682 Loss: 1.4732838058856648\n",
      "Epoch: 0 Sample: 9290000 / 53735682 Loss: 1.5375245675033122\n",
      "Epoch: 0 Sample: 9300000 / 53735682 Loss: 1.599716799699266\n",
      "Epoch: 0 Sample: 9310000 / 53735682 Loss: 1.4692495777982173\n",
      "Epoch: 0 Sample: 9320000 / 53735682 Loss: 1.6057913728265176\n",
      "Epoch: 0 Sample: 9330000 / 53735682 Loss: 1.5166086736762145\n",
      "Epoch: 0 Sample: 9340000 / 53735682 Loss: 1.5317209444923785\n",
      "Epoch: 0 Sample: 9350000 / 53735682 Loss: 1.471016874567494\n",
      "Epoch: 0 Sample: 9360000 / 53735682 Loss: 1.6420032293492806\n",
      "Epoch: 0 Sample: 9370000 / 53735682 Loss: 1.5236959119012299\n",
      "Epoch: 0 Sample: 9380000 / 53735682 Loss: 1.474983105750574\n",
      "Epoch: 0 Sample: 9390000 / 53735682 Loss: 1.528870155500638\n",
      "Epoch: 0 Sample: 9400000 / 53735682 Loss: 1.4696185381970617\n",
      "Epoch: 0 Sample: 9410000 / 53735682 Loss: 1.523742127117141\n",
      "Epoch: 0 Sample: 9420000 / 53735682 Loss: 1.4752609875349383\n",
      "Epoch: 0 Sample: 9430000 / 53735682 Loss: 1.4865371783408277\n",
      "Epoch: 0 Sample: 9440000 / 53735682 Loss: 1.4832461983392458\n",
      "Epoch: 0 Sample: 9450000 / 53735682 Loss: 1.486833722935874\n",
      "Epoch: 0 Sample: 9460000 / 53735682 Loss: 1.4993450036398706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 9470000 / 53735682 Loss: 1.5551317964381328\n",
      "Epoch: 0 Sample: 9480000 / 53735682 Loss: 1.457022900817855\n",
      "Epoch: 0 Sample: 9490000 / 53735682 Loss: 1.4596809159394348\n",
      "Epoch: 0 Sample: 9500000 / 53735682 Loss: 1.4957898940423058\n",
      "Epoch: 0 Sample: 9510000 / 53735682 Loss: 1.5663100871654931\n",
      "Epoch: 0 Sample: 9520000 / 53735682 Loss: 1.5506948602817672\n",
      "Epoch: 0 Sample: 9530000 / 53735682 Loss: 1.5325988357615654\n",
      "Epoch: 0 Sample: 9540000 / 53735682 Loss: 1.5527524482251216\n",
      "Epoch: 0 Sample: 9550000 / 53735682 Loss: 1.5730609597683087\n",
      "Epoch: 0 Sample: 9560000 / 53735682 Loss: 1.5634215599594048\n",
      "Epoch: 0 Sample: 9570000 / 53735682 Loss: 1.4622300324242496\n",
      "Epoch: 0 Sample: 9580000 / 53735682 Loss: 1.5027680749795518\n",
      "Epoch: 0 Sample: 9590000 / 53735682 Loss: 1.4940154506561627\n",
      "Epoch: 0 Sample: 9600000 / 53735682 Loss: 1.5635398704529866\n",
      "Epoch: 0 Sample: 9610000 / 53735682 Loss: 1.536891448467444\n",
      "Epoch: 0 Sample: 9620000 / 53735682 Loss: 1.6022231036139003\n",
      "Epoch: 0 Sample: 9630000 / 53735682 Loss: 1.50303243677674\n",
      "Epoch: 0 Sample: 9640000 / 53735682 Loss: 1.5175502028196444\n",
      "Epoch: 0 Sample: 9650000 / 53735682 Loss: 1.4472637544945448\n",
      "Epoch: 0 Sample: 9660000 / 53735682 Loss: 1.4547881750788951\n",
      "Epoch: 0 Sample: 9670000 / 53735682 Loss: 1.547798528749837\n",
      "Epoch: 0 Sample: 9680000 / 53735682 Loss: 1.5008255500510783\n",
      "Epoch: 0 Sample: 9690000 / 53735682 Loss: 1.4965396731520244\n",
      "Epoch: 0 Sample: 9700000 / 53735682 Loss: 1.5718589367181264\n",
      "Epoch: 0 Sample: 9710000 / 53735682 Loss: 1.5456510251071793\n",
      "Epoch: 0 Sample: 9720000 / 53735682 Loss: 1.473800535802373\n",
      "Epoch: 0 Sample: 9730000 / 53735682 Loss: 1.4925996535873716\n",
      "Epoch: 0 Sample: 9740000 / 53735682 Loss: 1.553568861189258\n",
      "Epoch: 0 Sample: 9750000 / 53735682 Loss: 1.4840901129757773\n",
      "Epoch: 0 Sample: 9760000 / 53735682 Loss: 1.5023035890897138\n",
      "Epoch: 0 Sample: 9770000 / 53735682 Loss: 1.4739424695600705\n",
      "Epoch: 0 Sample: 9780000 / 53735682 Loss: 1.4564920734124494\n",
      "Epoch: 0 Sample: 9790000 / 53735682 Loss: 1.4865951925309786\n",
      "Epoch: 0 Sample: 9800000 / 53735682 Loss: 1.454283048894094\n",
      "Epoch: 0 Sample: 9810000 / 53735682 Loss: 1.457258666449011\n",
      "Epoch: 0 Sample: 9820000 / 53735682 Loss: 1.4566298489424891\n",
      "Epoch: 0 Sample: 9830000 / 53735682 Loss: 1.5469645935665413\n",
      "Epoch: 0 Sample: 9840000 / 53735682 Loss: 1.499893256786757\n",
      "Epoch: 0 Sample: 9850000 / 53735682 Loss: 1.5012699184152347\n",
      "Epoch: 0 Sample: 9860000 / 53735682 Loss: 1.5136622451246127\n",
      "Epoch: 0 Sample: 9870000 / 53735682 Loss: 1.5355699231930164\n",
      "Epoch: 0 Sample: 9880000 / 53735682 Loss: 1.5362035893681762\n",
      "Epoch: 0 Sample: 9890000 / 53735682 Loss: 1.409183002132175\n",
      "Epoch: 0 Sample: 9900000 / 53735682 Loss: 1.5473148226926816\n",
      "Epoch: 0 Sample: 9910000 / 53735682 Loss: 1.533788321757227\n",
      "Epoch: 0 Sample: 9920000 / 53735682 Loss: 1.5072512099115873\n",
      "Epoch: 0 Sample: 9930000 / 53735682 Loss: 1.5054063289934976\n",
      "Epoch: 0 Sample: 9940000 / 53735682 Loss: 1.5705572063113293\n",
      "Epoch: 0 Sample: 9950000 / 53735682 Loss: 1.444645062046602\n",
      "Epoch: 0 Sample: 9960000 / 53735682 Loss: 1.4639583490923211\n",
      "Epoch: 0 Sample: 9970000 / 53735682 Loss: 1.4505515445414545\n",
      "Epoch: 0 Sample: 9980000 / 53735682 Loss: 1.5439263871707367\n",
      "Epoch: 0 Sample: 9990000 / 53735682 Loss: 1.465258062368257\n",
      "Epoch: 0 Sample: 10000000 / 53735682 Loss: 1.554341107717451\n",
      "Epoch: 0 Sample: 10010000 / 53735682 Loss: 1.5230177236534503\n",
      "Epoch: 0 Sample: 10020000 / 53735682 Loss: 1.550916052963905\n",
      "Epoch: 0 Sample: 10030000 / 53735682 Loss: 1.472937633136354\n",
      "Epoch: 0 Sample: 10040000 / 53735682 Loss: 1.5214309227044418\n",
      "Epoch: 0 Sample: 10050000 / 53735682 Loss: 1.415014196933104\n",
      "Epoch: 0 Sample: 10060000 / 53735682 Loss: 1.5066809345565795\n",
      "Epoch: 0 Sample: 10070000 / 53735682 Loss: 1.5757871889278732\n",
      "Epoch: 0 Sample: 10080000 / 53735682 Loss: 1.4679552801264768\n",
      "Epoch: 0 Sample: 10090000 / 53735682 Loss: 1.5024890539663152\n",
      "Epoch: 0 Sample: 10100000 / 53735682 Loss: 1.5193787905888698\n",
      "Epoch: 0 Sample: 10110000 / 53735682 Loss: 1.5567714545470013\n",
      "Epoch: 0 Sample: 10120000 / 53735682 Loss: 1.5274918100234278\n",
      "Epoch: 0 Sample: 10130000 / 53735682 Loss: 1.5317239943269325\n",
      "Epoch: 0 Sample: 10140000 / 53735682 Loss: 1.5438568908033528\n",
      "Epoch: 0 Sample: 10150000 / 53735682 Loss: 1.423870527268153\n",
      "Epoch: 0 Sample: 10160000 / 53735682 Loss: 1.4998737409719656\n",
      "Epoch: 0 Sample: 10170000 / 53735682 Loss: 1.4842613462497827\n",
      "Epoch: 0 Sample: 10180000 / 53735682 Loss: 1.551264301889225\n",
      "Epoch: 0 Sample: 10190000 / 53735682 Loss: 1.4630114077871286\n",
      "Epoch: 0 Sample: 10200000 / 53735682 Loss: 1.5072932847996872\n",
      "Epoch: 0 Sample: 10210000 / 53735682 Loss: 1.5020053187765814\n",
      "Epoch: 0 Sample: 10220000 / 53735682 Loss: 1.5583878168286054\n",
      "Epoch: 0 Sample: 10230000 / 53735682 Loss: 1.4964370940958571\n",
      "Epoch: 0 Sample: 10240000 / 53735682 Loss: 1.5300772602542416\n",
      "Epoch: 0 Sample: 10250000 / 53735682 Loss: 1.587573251536729\n",
      "Epoch: 0 Sample: 10260000 / 53735682 Loss: 1.4779235050680706\n",
      "Epoch: 0 Sample: 10270000 / 53735682 Loss: 1.5277630875564263\n",
      "Epoch: 0 Sample: 10280000 / 53735682 Loss: 1.472662076873324\n",
      "Epoch: 0 Sample: 10290000 / 53735682 Loss: 1.5583964922008282\n",
      "Epoch: 0 Sample: 10300000 / 53735682 Loss: 1.4180166413945143\n",
      "Epoch: 0 Sample: 10310000 / 53735682 Loss: 1.4705222792868924\n",
      "Epoch: 0 Sample: 10320000 / 53735682 Loss: 1.5256278005962722\n",
      "Epoch: 0 Sample: 10330000 / 53735682 Loss: 1.4618928183944562\n",
      "Epoch: 0 Sample: 10340000 / 53735682 Loss: 1.4867479926040899\n",
      "Epoch: 0 Sample: 10350000 / 53735682 Loss: 1.5262842400139938\n",
      "Epoch: 0 Sample: 10360000 / 53735682 Loss: 1.6246258250808838\n",
      "Epoch: 0 Sample: 10370000 / 53735682 Loss: 1.5366222620221808\n",
      "Epoch: 0 Sample: 10380000 / 53735682 Loss: 1.4570882919193189\n",
      "Epoch: 0 Sample: 10390000 / 53735682 Loss: 1.488242057436516\n",
      "Epoch: 0 Sample: 10400000 / 53735682 Loss: 1.466450013340116\n",
      "Epoch: 0 Sample: 10410000 / 53735682 Loss: 1.4844005632365151\n",
      "Epoch: 0 Sample: 10420000 / 53735682 Loss: 1.4927714868549944\n",
      "Epoch: 0 Sample: 10430000 / 53735682 Loss: 1.5231732702005885\n",
      "Epoch: 0 Sample: 10440000 / 53735682 Loss: 1.3988586791056261\n",
      "Epoch: 0 Sample: 10450000 / 53735682 Loss: 1.4608520017943447\n",
      "Epoch: 0 Sample: 10460000 / 53735682 Loss: 1.4993310190856863\n",
      "Epoch: 0 Sample: 10470000 / 53735682 Loss: 1.556738700880822\n",
      "Epoch: 0 Sample: 10480000 / 53735682 Loss: 1.5200181789194982\n",
      "Epoch: 0 Sample: 10490000 / 53735682 Loss: 1.5071107957783196\n",
      "Epoch: 0 Sample: 10500000 / 53735682 Loss: 1.5122047190758847\n",
      "Epoch: 0 Sample: 10510000 / 53735682 Loss: 1.5014557848277583\n",
      "Epoch: 0 Sample: 10520000 / 53735682 Loss: 1.5202743008935289\n",
      "Epoch: 0 Sample: 10530000 / 53735682 Loss: 1.459437911013942\n",
      "Epoch: 0 Sample: 10540000 / 53735682 Loss: 1.5809338067190666\n",
      "Epoch: 0 Sample: 10550000 / 53735682 Loss: 1.5692711449311447\n",
      "Epoch: 0 Sample: 10560000 / 53735682 Loss: 1.5361122265220182\n",
      "Epoch: 0 Sample: 10570000 / 53735682 Loss: 1.489074294260258\n",
      "Epoch: 0 Sample: 10580000 / 53735682 Loss: 1.532282375711926\n",
      "Epoch: 0 Sample: 10590000 / 53735682 Loss: 1.598355980941681\n",
      "Epoch: 0 Sample: 10600000 / 53735682 Loss: 1.5538733422561128\n",
      "Epoch: 0 Sample: 10610000 / 53735682 Loss: 1.4313044105293695\n",
      "Epoch: 0 Sample: 10620000 / 53735682 Loss: 1.475083047186526\n",
      "Epoch: 0 Sample: 10630000 / 53735682 Loss: 1.5274162345131357\n",
      "Epoch: 0 Sample: 10640000 / 53735682 Loss: 1.5380488780464232\n",
      "Epoch: 0 Sample: 10650000 / 53735682 Loss: 1.5191310379587075\n",
      "Epoch: 0 Sample: 10660000 / 53735682 Loss: 1.5129418135378336\n",
      "Epoch: 0 Sample: 10670000 / 53735682 Loss: 1.5229383847144766\n",
      "Epoch: 0 Sample: 10680000 / 53735682 Loss: 1.4908023905069707\n",
      "Epoch: 0 Sample: 10690000 / 53735682 Loss: 1.5083912476315569\n",
      "Epoch: 0 Sample: 10700000 / 53735682 Loss: 1.4320333848313673\n",
      "Epoch: 0 Sample: 10710000 / 53735682 Loss: 1.4906949309363347\n",
      "Epoch: 0 Sample: 10720000 / 53735682 Loss: 1.4867450046344404\n",
      "Epoch: 0 Sample: 10730000 / 53735682 Loss: 1.6063165959968269\n",
      "Epoch: 0 Sample: 10740000 / 53735682 Loss: 1.5321300955284638\n",
      "Epoch: 0 Sample: 10750000 / 53735682 Loss: 1.511626066753168\n",
      "Epoch: 0 Sample: 10760000 / 53735682 Loss: 1.549673816984774\n",
      "Epoch: 0 Sample: 10770000 / 53735682 Loss: 1.5376694012289702\n",
      "Epoch: 0 Sample: 10780000 / 53735682 Loss: 1.4768407486395199\n",
      "Epoch: 0 Sample: 10790000 / 53735682 Loss: 1.5097700919664119\n",
      "Epoch: 0 Sample: 10800000 / 53735682 Loss: 1.570026303318238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 10810000 / 53735682 Loss: 1.5660261665886603\n",
      "Epoch: 0 Sample: 10820000 / 53735682 Loss: 1.4976337886113278\n",
      "Epoch: 0 Sample: 10830000 / 53735682 Loss: 1.5488910371908826\n",
      "Epoch: 0 Sample: 10840000 / 53735682 Loss: 1.5454104707606549\n",
      "Epoch: 0 Sample: 10850000 / 53735682 Loss: 1.5817291256764339\n",
      "Epoch: 0 Sample: 10860000 / 53735682 Loss: 1.490144909896865\n",
      "Epoch: 0 Sample: 10870000 / 53735682 Loss: 1.4810224981645033\n",
      "Epoch: 0 Sample: 10880000 / 53735682 Loss: 1.500753510534914\n",
      "Epoch: 0 Sample: 10890000 / 53735682 Loss: 1.4817857336601765\n",
      "Epoch: 0 Sample: 10900000 / 53735682 Loss: 1.5500048061559135\n",
      "Epoch: 0 Sample: 10910000 / 53735682 Loss: 1.5085120112787527\n",
      "Epoch: 0 Sample: 10920000 / 53735682 Loss: 1.4825004867405793\n",
      "Epoch: 0 Sample: 10930000 / 53735682 Loss: 1.4752532200405797\n",
      "Epoch: 0 Sample: 10940000 / 53735682 Loss: 1.473067368367145\n",
      "Epoch: 0 Sample: 10950000 / 53735682 Loss: 1.4672683430169968\n",
      "Epoch: 0 Sample: 10960000 / 53735682 Loss: 1.5107592067496096\n",
      "Epoch: 0 Sample: 10970000 / 53735682 Loss: 1.4972829886247352\n",
      "Epoch: 0 Sample: 10980000 / 53735682 Loss: 1.5292614757799379\n",
      "Epoch: 0 Sample: 10990000 / 53735682 Loss: 1.560577738398976\n",
      "Epoch: 0 Sample: 11000000 / 53735682 Loss: 1.4375686021388767\n",
      "Epoch: 0 Sample: 11010000 / 53735682 Loss: 1.5235593996725938\n",
      "Epoch: 0 Sample: 11020000 / 53735682 Loss: 1.5420219500180852\n",
      "Epoch: 0 Sample: 11030000 / 53735682 Loss: 1.4527829621380657\n",
      "Epoch: 0 Sample: 11040000 / 53735682 Loss: 1.4787118997879842\n",
      "Epoch: 0 Sample: 11050000 / 53735682 Loss: 1.6175091567412179\n",
      "Epoch: 0 Sample: 11060000 / 53735682 Loss: 1.6462566985442244\n",
      "Epoch: 0 Sample: 11070000 / 53735682 Loss: 1.5730979190646726\n",
      "Epoch: 0 Sample: 11080000 / 53735682 Loss: 1.5279887160371306\n",
      "Epoch: 0 Sample: 11090000 / 53735682 Loss: 1.4345413209120597\n",
      "Epoch: 0 Sample: 11100000 / 53735682 Loss: 1.4715974371559266\n",
      "Epoch: 0 Sample: 11110000 / 53735682 Loss: 1.5402644208459795\n",
      "Epoch: 0 Sample: 11120000 / 53735682 Loss: 1.5046074122594448\n",
      "Epoch: 0 Sample: 11130000 / 53735682 Loss: 1.5188203608269493\n",
      "Epoch: 0 Sample: 11140000 / 53735682 Loss: 1.5259084085837944\n",
      "Epoch: 0 Sample: 11150000 / 53735682 Loss: 1.5203582665096396\n",
      "Epoch: 0 Sample: 11160000 / 53735682 Loss: 1.579058711915874\n",
      "Epoch: 0 Sample: 11170000 / 53735682 Loss: 1.474060591334303\n",
      "Epoch: 0 Sample: 11180000 / 53735682 Loss: 1.4977320497241973\n",
      "Epoch: 0 Sample: 11190000 / 53735682 Loss: 1.4325577591796437\n",
      "Epoch: 0 Sample: 11200000 / 53735682 Loss: 1.514722522162729\n",
      "Epoch: 0 Sample: 11210000 / 53735682 Loss: 1.4652301743890144\n",
      "Epoch: 0 Sample: 11220000 / 53735682 Loss: 1.4501666198462497\n",
      "Epoch: 0 Sample: 11230000 / 53735682 Loss: 1.6020788878625654\n",
      "Epoch: 0 Sample: 11240000 / 53735682 Loss: 1.5606926242976753\n",
      "Epoch: 0 Sample: 11250000 / 53735682 Loss: 1.5672466227724076\n",
      "Epoch: 0 Sample: 11260000 / 53735682 Loss: 1.4729821075959437\n",
      "Epoch: 0 Sample: 11270000 / 53735682 Loss: 1.5262216481517816\n",
      "Epoch: 0 Sample: 11280000 / 53735682 Loss: 1.5226896908592076\n",
      "Epoch: 0 Sample: 11290000 / 53735682 Loss: 1.5038113664625588\n",
      "Epoch: 0 Sample: 11300000 / 53735682 Loss: 1.4836424911222537\n",
      "Epoch: 0 Sample: 11310000 / 53735682 Loss: 1.416591009169836\n",
      "Epoch: 0 Sample: 11320000 / 53735682 Loss: 1.4788063711109543\n",
      "Epoch: 0 Sample: 11330000 / 53735682 Loss: 1.431079925355376\n",
      "Epoch: 0 Sample: 11340000 / 53735682 Loss: 1.5187489311957694\n",
      "Epoch: 0 Sample: 11350000 / 53735682 Loss: 1.475980442860648\n",
      "Epoch: 0 Sample: 11360000 / 53735682 Loss: 1.557153020621568\n",
      "Epoch: 0 Sample: 11370000 / 53735682 Loss: 1.5362326402956408\n",
      "Epoch: 0 Sample: 11380000 / 53735682 Loss: 1.4384874814275568\n",
      "Epoch: 0 Sample: 11390000 / 53735682 Loss: 1.4225994376296711\n",
      "Epoch: 0 Sample: 11400000 / 53735682 Loss: 1.4542706442730322\n",
      "Epoch: 0 Sample: 11410000 / 53735682 Loss: 1.5268837060402745\n",
      "Epoch: 0 Sample: 11420000 / 53735682 Loss: 1.4737625732275923\n",
      "Epoch: 0 Sample: 11430000 / 53735682 Loss: 1.487821912864236\n",
      "Epoch: 0 Sample: 11440000 / 53735682 Loss: 1.490084122984915\n",
      "Epoch: 0 Sample: 11450000 / 53735682 Loss: 1.4023534590929865\n",
      "Epoch: 0 Sample: 11460000 / 53735682 Loss: 1.4598811254544288\n",
      "Epoch: 0 Sample: 11470000 / 53735682 Loss: 1.5000202323885485\n",
      "Epoch: 0 Sample: 11480000 / 53735682 Loss: 1.4796354676096053\n",
      "Epoch: 0 Sample: 11490000 / 53735682 Loss: 1.5594383144188007\n",
      "Epoch: 0 Sample: 11500000 / 53735682 Loss: 1.475116236658693\n",
      "Epoch: 0 Sample: 11510000 / 53735682 Loss: 1.5524228719238242\n",
      "Epoch: 0 Sample: 11520000 / 53735682 Loss: 1.4802134388716932\n",
      "Epoch: 0 Sample: 11530000 / 53735682 Loss: 1.4590611813915029\n",
      "Epoch: 0 Sample: 11540000 / 53735682 Loss: 1.4685188902744297\n",
      "Epoch: 0 Sample: 11550000 / 53735682 Loss: 1.553372386723953\n",
      "Epoch: 0 Sample: 11560000 / 53735682 Loss: 1.4823772845735568\n",
      "Epoch: 0 Sample: 11570000 / 53735682 Loss: 1.5690142761455326\n",
      "Epoch: 0 Sample: 11580000 / 53735682 Loss: 1.5025688173241045\n",
      "Epoch: 0 Sample: 11590000 / 53735682 Loss: 1.511428507607902\n",
      "Epoch: 0 Sample: 11600000 / 53735682 Loss: 1.5026212824511853\n",
      "Epoch: 0 Sample: 11610000 / 53735682 Loss: 1.4264266158209344\n",
      "Epoch: 0 Sample: 11620000 / 53735682 Loss: 1.4810923936342046\n",
      "Epoch: 0 Sample: 11630000 / 53735682 Loss: 1.5189112367316975\n",
      "Epoch: 0 Sample: 11640000 / 53735682 Loss: 1.5248620913828923\n",
      "Epoch: 0 Sample: 11650000 / 53735682 Loss: 1.5026277627920765\n",
      "Epoch: 0 Sample: 11660000 / 53735682 Loss: 1.506691780286987\n",
      "Epoch: 0 Sample: 11670000 / 53735682 Loss: 1.465964749066718\n",
      "Epoch: 0 Sample: 11680000 / 53735682 Loss: 1.5929396311397108\n",
      "Epoch: 0 Sample: 11690000 / 53735682 Loss: 1.5289411765188352\n",
      "Epoch: 0 Sample: 11700000 / 53735682 Loss: 1.5051155880233127\n",
      "Epoch: 0 Sample: 11710000 / 53735682 Loss: 1.4944680355899114\n",
      "Epoch: 0 Sample: 11720000 / 53735682 Loss: 1.5141064775385886\n",
      "Epoch: 0 Sample: 11730000 / 53735682 Loss: 1.592361073094292\n",
      "Epoch: 0 Sample: 11740000 / 53735682 Loss: 1.4880877571985698\n",
      "Epoch: 0 Sample: 11750000 / 53735682 Loss: 1.4864006749054082\n",
      "Epoch: 0 Sample: 11760000 / 53735682 Loss: 1.641323291751517\n",
      "Epoch: 0 Sample: 11770000 / 53735682 Loss: 1.4829653800190337\n",
      "Epoch: 0 Sample: 11780000 / 53735682 Loss: 1.5139795553378912\n",
      "Epoch: 0 Sample: 11790000 / 53735682 Loss: 1.5669360771327216\n",
      "Epoch: 0 Sample: 11800000 / 53735682 Loss: 1.4857028661597151\n",
      "Epoch: 0 Sample: 11810000 / 53735682 Loss: 1.472367019098652\n",
      "Epoch: 0 Sample: 11820000 / 53735682 Loss: 1.6171925950087611\n",
      "Epoch: 0 Sample: 11830000 / 53735682 Loss: 1.524111325172584\n",
      "Epoch: 0 Sample: 11840000 / 53735682 Loss: 1.4823323351977797\n",
      "Epoch: 0 Sample: 11850000 / 53735682 Loss: 1.6243355038290774\n",
      "Epoch: 0 Sample: 11860000 / 53735682 Loss: 1.5652099898250347\n",
      "Epoch: 0 Sample: 11870000 / 53735682 Loss: 1.4569443203169596\n",
      "Epoch: 0 Sample: 11880000 / 53735682 Loss: 1.4831092075595202\n",
      "Epoch: 0 Sample: 11890000 / 53735682 Loss: 1.5397840097946527\n",
      "Epoch: 0 Sample: 11900000 / 53735682 Loss: 1.4728188158470903\n",
      "Epoch: 0 Sample: 11910000 / 53735682 Loss: 1.489057579155032\n",
      "Epoch: 0 Sample: 11920000 / 53735682 Loss: 1.5005978307428935\n",
      "Epoch: 0 Sample: 11930000 / 53735682 Loss: 1.5309340250366554\n",
      "Epoch: 0 Sample: 11940000 / 53735682 Loss: 1.5527193964146981\n",
      "Epoch: 0 Sample: 11950000 / 53735682 Loss: 1.5823258335754038\n",
      "Epoch: 0 Sample: 11960000 / 53735682 Loss: 1.520605192898177\n",
      "Epoch: 0 Sample: 11970000 / 53735682 Loss: 1.5848185797101704\n",
      "Epoch: 0 Sample: 11980000 / 53735682 Loss: 1.5686889509973523\n",
      "Epoch: 0 Sample: 11990000 / 53735682 Loss: 1.4872925735269833\n",
      "Epoch: 0 Sample: 12000000 / 53735682 Loss: 1.5114121373047453\n",
      "Epoch: 0 Sample: 12010000 / 53735682 Loss: 1.5687784402352853\n",
      "Epoch: 0 Sample: 12020000 / 53735682 Loss: 1.458761452659307\n",
      "Epoch: 0 Sample: 12030000 / 53735682 Loss: 1.5544649041966703\n",
      "Epoch: 0 Sample: 12040000 / 53735682 Loss: 1.524653173934175\n",
      "Epoch: 0 Sample: 12050000 / 53735682 Loss: 1.5294168982983107\n",
      "Epoch: 0 Sample: 12060000 / 53735682 Loss: 1.5546352053336197\n",
      "Epoch: 0 Sample: 12070000 / 53735682 Loss: 1.5768029185964991\n",
      "Epoch: 0 Sample: 12080000 / 53735682 Loss: 1.4624486162292398\n",
      "Epoch: 0 Sample: 12090000 / 53735682 Loss: 1.6051198283671675\n",
      "Epoch: 0 Sample: 12100000 / 53735682 Loss: 1.4905477304752919\n",
      "Epoch: 0 Sample: 12110000 / 53735682 Loss: 1.547845780956683\n",
      "Epoch: 0 Sample: 12120000 / 53735682 Loss: 1.5091825005495303\n",
      "Epoch: 0 Sample: 12130000 / 53735682 Loss: 1.5113276758738623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 12140000 / 53735682 Loss: 1.4224917422513446\n",
      "Epoch: 0 Sample: 12150000 / 53735682 Loss: 1.4934634445248802\n",
      "Epoch: 0 Sample: 12160000 / 53735682 Loss: 1.5059088445617683\n",
      "Epoch: 0 Sample: 12170000 / 53735682 Loss: 1.5187565998371815\n",
      "Epoch: 0 Sample: 12180000 / 53735682 Loss: 1.5509571203820005\n",
      "Epoch: 0 Sample: 12190000 / 53735682 Loss: 1.5606946853161667\n",
      "Epoch: 0 Sample: 12200000 / 53735682 Loss: 1.4808796494477563\n",
      "Epoch: 0 Sample: 12210000 / 53735682 Loss: 1.5090490897463742\n",
      "Epoch: 0 Sample: 12220000 / 53735682 Loss: 1.521292974589549\n",
      "Epoch: 0 Sample: 12230000 / 53735682 Loss: 1.5288033006530222\n",
      "Epoch: 0 Sample: 12240000 / 53735682 Loss: 1.5383946770840753\n",
      "Epoch: 0 Sample: 12250000 / 53735682 Loss: 1.5589939766940304\n",
      "Epoch: 0 Sample: 12260000 / 53735682 Loss: 1.565308223907297\n",
      "Epoch: 0 Sample: 12270000 / 53735682 Loss: 1.4262783063632458\n",
      "Epoch: 0 Sample: 12280000 / 53735682 Loss: 1.5368940516523182\n",
      "Epoch: 0 Sample: 12290000 / 53735682 Loss: 1.4764026103892276\n",
      "Epoch: 0 Sample: 12300000 / 53735682 Loss: 1.5878648985820059\n",
      "Epoch: 0 Sample: 12310000 / 53735682 Loss: 1.5268962056999158\n",
      "Epoch: 0 Sample: 12320000 / 53735682 Loss: 1.546447649894985\n",
      "Epoch: 0 Sample: 12330000 / 53735682 Loss: 1.567816524125642\n",
      "Epoch: 0 Sample: 12340000 / 53735682 Loss: 1.5214737184056868\n",
      "Epoch: 0 Sample: 12350000 / 53735682 Loss: 1.5392339097171732\n",
      "Epoch: 0 Sample: 12360000 / 53735682 Loss: 1.4755634336868282\n",
      "Epoch: 0 Sample: 12370000 / 53735682 Loss: 1.4872386105128077\n",
      "Epoch: 0 Sample: 12380000 / 53735682 Loss: 1.4817972050697243\n",
      "Epoch: 0 Sample: 12390000 / 53735682 Loss: 1.570050219391471\n",
      "Epoch: 0 Sample: 12400000 / 53735682 Loss: 1.54218513844764\n",
      "Epoch: 0 Sample: 12410000 / 53735682 Loss: 1.5016902857026522\n",
      "Epoch: 0 Sample: 12420000 / 53735682 Loss: 1.5010721730660936\n",
      "Epoch: 0 Sample: 12430000 / 53735682 Loss: 1.464027964022087\n",
      "Epoch: 0 Sample: 12440000 / 53735682 Loss: 1.5142150222027684\n",
      "Epoch: 0 Sample: 12450000 / 53735682 Loss: 1.6529945190508597\n",
      "Epoch: 0 Sample: 12460000 / 53735682 Loss: 1.522082639770352\n",
      "Epoch: 0 Sample: 12470000 / 53735682 Loss: 1.438871794892958\n",
      "Epoch: 0 Sample: 12480000 / 53735682 Loss: 1.5737871013761788\n",
      "Epoch: 0 Sample: 12490000 / 53735682 Loss: 1.5366878180768864\n",
      "Epoch: 0 Sample: 12500000 / 53735682 Loss: 1.5179247591116085\n",
      "Epoch: 0 Sample: 12510000 / 53735682 Loss: 1.5130644331152054\n",
      "Epoch: 0 Sample: 12520000 / 53735682 Loss: 1.506360120542186\n",
      "Epoch: 0 Sample: 12530000 / 53735682 Loss: 1.489295008016653\n",
      "Epoch: 0 Sample: 12540000 / 53735682 Loss: 1.5121773809080552\n",
      "Epoch: 0 Sample: 12550000 / 53735682 Loss: 1.4802740404240868\n",
      "Epoch: 0 Sample: 12560000 / 53735682 Loss: 1.4336115499833855\n",
      "Epoch: 0 Sample: 12570000 / 53735682 Loss: 1.4883354942660136\n",
      "Epoch: 0 Sample: 12580000 / 53735682 Loss: 1.586226145800044\n",
      "Epoch: 0 Sample: 12590000 / 53735682 Loss: 1.4913290446491896\n",
      "Epoch: 0 Sample: 12600000 / 53735682 Loss: 1.4698460411205037\n",
      "Epoch: 0 Sample: 12610000 / 53735682 Loss: 1.4718192944383184\n",
      "Epoch: 0 Sample: 12620000 / 53735682 Loss: 1.48926410606571\n",
      "Epoch: 0 Sample: 12630000 / 53735682 Loss: 1.5504616355169314\n",
      "Epoch: 0 Sample: 12640000 / 53735682 Loss: 1.4725331668326986\n",
      "Epoch: 0 Sample: 12650000 / 53735682 Loss: 1.5220365876720225\n",
      "Epoch: 0 Sample: 12660000 / 53735682 Loss: 1.547633731923401\n",
      "Epoch: 0 Sample: 12670000 / 53735682 Loss: 1.4752109018729658\n",
      "Epoch: 0 Sample: 12680000 / 53735682 Loss: 1.500300993780174\n",
      "Epoch: 0 Sample: 12690000 / 53735682 Loss: 1.35890008766247\n",
      "Epoch: 0 Sample: 12700000 / 53735682 Loss: 1.5341600299742335\n",
      "Epoch: 0 Sample: 12710000 / 53735682 Loss: 1.4947991996956616\n",
      "Epoch: 0 Sample: 12720000 / 53735682 Loss: 1.5128731568347535\n",
      "Epoch: 0 Sample: 12730000 / 53735682 Loss: 1.4002901352623527\n",
      "Epoch: 0 Sample: 12740000 / 53735682 Loss: 1.544681365928493\n",
      "Epoch: 0 Sample: 12750000 / 53735682 Loss: 1.5154804427378705\n",
      "Epoch: 0 Sample: 12760000 / 53735682 Loss: 1.4668903651006548\n",
      "Epoch: 0 Sample: 12770000 / 53735682 Loss: 1.452672832891877\n",
      "Epoch: 0 Sample: 12780000 / 53735682 Loss: 1.5359628150130331\n",
      "Epoch: 0 Sample: 12790000 / 53735682 Loss: 1.4952263042305471\n",
      "Epoch: 0 Sample: 12800000 / 53735682 Loss: 1.5081836946894696\n",
      "Epoch: 0 Sample: 12810000 / 53735682 Loss: 1.59743367480905\n",
      "Epoch: 0 Sample: 12820000 / 53735682 Loss: 1.498975952800554\n",
      "Epoch: 0 Sample: 12830000 / 53735682 Loss: 1.5505652098225324\n",
      "Epoch: 0 Sample: 12840000 / 53735682 Loss: 1.5051911684373138\n",
      "Epoch: 0 Sample: 12850000 / 53735682 Loss: 1.5165971688930142\n",
      "Epoch: 0 Sample: 12860000 / 53735682 Loss: 1.4907939636622185\n",
      "Epoch: 0 Sample: 12870000 / 53735682 Loss: 1.546557521904316\n",
      "Epoch: 0 Sample: 12880000 / 53735682 Loss: 1.4929244701665991\n",
      "Epoch: 0 Sample: 12890000 / 53735682 Loss: 1.5775063534912146\n",
      "Epoch: 0 Sample: 12900000 / 53735682 Loss: 1.635073598050321\n",
      "Epoch: 0 Sample: 12910000 / 53735682 Loss: 1.511991567403736\n",
      "Epoch: 0 Sample: 12920000 / 53735682 Loss: 1.4915764632559734\n",
      "Epoch: 0 Sample: 12930000 / 53735682 Loss: 1.413355446770996\n",
      "Epoch: 0 Sample: 12940000 / 53735682 Loss: 1.5188486130558763\n",
      "Epoch: 0 Sample: 12950000 / 53735682 Loss: 1.520554606284048\n",
      "Epoch: 0 Sample: 12960000 / 53735682 Loss: 1.5262593071967503\n",
      "Epoch: 0 Sample: 12970000 / 53735682 Loss: 1.5018791388245303\n",
      "Epoch: 0 Sample: 12980000 / 53735682 Loss: 1.5342362864322738\n",
      "Epoch: 0 Sample: 12990000 / 53735682 Loss: 1.5153233490229026\n",
      "Epoch: 0 Sample: 13000000 / 53735682 Loss: 1.5751633125543414\n",
      "Epoch: 0 Sample: 13010000 / 53735682 Loss: 1.5600358762079645\n",
      "Epoch: 0 Sample: 13020000 / 53735682 Loss: 1.495125623272795\n",
      "Epoch: 0 Sample: 13030000 / 53735682 Loss: 1.4318955328243517\n",
      "Epoch: 0 Sample: 13040000 / 53735682 Loss: 1.4290828370917827\n",
      "Epoch: 0 Sample: 13050000 / 53735682 Loss: 1.4658517387449845\n",
      "Epoch: 0 Sample: 13060000 / 53735682 Loss: 1.5115887984750653\n",
      "Epoch: 0 Sample: 13070000 / 53735682 Loss: 1.5481391596384517\n",
      "Epoch: 0 Sample: 13080000 / 53735682 Loss: 1.527389406614269\n",
      "Epoch: 0 Sample: 13090000 / 53735682 Loss: 1.471811846086697\n",
      "Epoch: 0 Sample: 13100000 / 53735682 Loss: 1.458166202383386\n",
      "Epoch: 0 Sample: 13110000 / 53735682 Loss: 1.4657717427412311\n",
      "Epoch: 0 Sample: 13120000 / 53735682 Loss: 1.4729332922810463\n",
      "Epoch: 0 Sample: 13130000 / 53735682 Loss: 1.476878014135297\n",
      "Epoch: 0 Sample: 13140000 / 53735682 Loss: 1.5708518293894729\n",
      "Epoch: 0 Sample: 13150000 / 53735682 Loss: 1.4936880887542834\n",
      "Epoch: 0 Sample: 13160000 / 53735682 Loss: 1.4803222790140527\n",
      "Epoch: 0 Sample: 13170000 / 53735682 Loss: 1.4263036919924081\n",
      "Epoch: 0 Sample: 13180000 / 53735682 Loss: 1.4743217602179284\n",
      "Epoch: 0 Sample: 13190000 / 53735682 Loss: 1.551942176567729\n",
      "Epoch: 0 Sample: 13200000 / 53735682 Loss: 1.496614035499896\n",
      "Epoch: 0 Sample: 13210000 / 53735682 Loss: 1.4623622164517407\n",
      "Epoch: 0 Sample: 13220000 / 53735682 Loss: 1.4484653064128925\n",
      "Epoch: 0 Sample: 13230000 / 53735682 Loss: 1.513815454341699\n",
      "Epoch: 0 Sample: 13240000 / 53735682 Loss: 1.5057776061895531\n",
      "Epoch: 0 Sample: 13250000 / 53735682 Loss: 1.5263354102427407\n",
      "Epoch: 0 Sample: 13260000 / 53735682 Loss: 1.5114651467046842\n",
      "Epoch: 0 Sample: 13270000 / 53735682 Loss: 1.4994729082684883\n",
      "Epoch: 0 Sample: 13280000 / 53735682 Loss: 1.5162317455698542\n",
      "Epoch: 0 Sample: 13290000 / 53735682 Loss: 1.4840081034477248\n",
      "Epoch: 0 Sample: 13300000 / 53735682 Loss: 1.435042296562943\n",
      "Epoch: 0 Sample: 13310000 / 53735682 Loss: 1.4927012450636674\n",
      "Epoch: 0 Sample: 13320000 / 53735682 Loss: 1.4599129560956996\n",
      "Epoch: 0 Sample: 13330000 / 53735682 Loss: 1.4637231039425562\n",
      "Epoch: 0 Sample: 13340000 / 53735682 Loss: 1.5105805031703057\n",
      "Epoch: 0 Sample: 13350000 / 53735682 Loss: 1.4539800300801788\n",
      "Epoch: 0 Sample: 13360000 / 53735682 Loss: 1.5507835272433041\n",
      "Epoch: 0 Sample: 13370000 / 53735682 Loss: 1.4917466841375369\n",
      "Epoch: 0 Sample: 13380000 / 53735682 Loss: 1.592164862633633\n",
      "Epoch: 0 Sample: 13390000 / 53735682 Loss: 1.5126177790918398\n",
      "Epoch: 0 Sample: 13400000 / 53735682 Loss: 1.6850778255436483\n",
      "Epoch: 0 Sample: 13410000 / 53735682 Loss: 1.5187038736647835\n",
      "Epoch: 0 Sample: 13420000 / 53735682 Loss: 1.4278462227706061\n",
      "Epoch: 0 Sample: 13430000 / 53735682 Loss: 1.5258784878076024\n",
      "Epoch: 0 Sample: 13440000 / 53735682 Loss: 1.4262748257334563\n",
      "Epoch: 0 Sample: 13450000 / 53735682 Loss: 1.5104754895944024\n",
      "Epoch: 0 Sample: 13460000 / 53735682 Loss: 1.4792058936172512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 13470000 / 53735682 Loss: 1.5169223271250991\n",
      "Epoch: 0 Sample: 13480000 / 53735682 Loss: 1.4296682134375793\n",
      "Epoch: 0 Sample: 13490000 / 53735682 Loss: 1.4934034788425286\n",
      "Epoch: 0 Sample: 13500000 / 53735682 Loss: 1.566075895554619\n",
      "Epoch: 0 Sample: 13510000 / 53735682 Loss: 1.591447680802632\n",
      "Epoch: 0 Sample: 13520000 / 53735682 Loss: 1.479906752597566\n",
      "Epoch: 0 Sample: 13530000 / 53735682 Loss: 1.5406303242679766\n",
      "Epoch: 0 Sample: 13540000 / 53735682 Loss: 1.44113422822267\n",
      "Epoch: 0 Sample: 13550000 / 53735682 Loss: 1.5228922349094964\n",
      "Epoch: 0 Sample: 13560000 / 53735682 Loss: 1.561971029541365\n",
      "Epoch: 0 Sample: 13570000 / 53735682 Loss: 1.5866359066958178\n",
      "Epoch: 0 Sample: 13580000 / 53735682 Loss: 1.543643331915493\n",
      "Epoch: 0 Sample: 13590000 / 53735682 Loss: 1.4560082676976496\n",
      "Epoch: 0 Sample: 13600000 / 53735682 Loss: 1.4981098904438785\n",
      "Epoch: 0 Sample: 13610000 / 53735682 Loss: 1.5475671274343312\n",
      "Epoch: 0 Sample: 13620000 / 53735682 Loss: 1.4836697064189321\n",
      "Epoch: 0 Sample: 13630000 / 53735682 Loss: 1.5078522532541578\n",
      "Epoch: 0 Sample: 13640000 / 53735682 Loss: 1.4952151773669426\n",
      "Epoch: 0 Sample: 13650000 / 53735682 Loss: 1.4931768804570607\n",
      "Epoch: 0 Sample: 13660000 / 53735682 Loss: 1.5671628260808808\n",
      "Epoch: 0 Sample: 13670000 / 53735682 Loss: 1.4610027186453878\n",
      "Epoch: 0 Sample: 13680000 / 53735682 Loss: 1.5398958789887467\n",
      "Epoch: 0 Sample: 13690000 / 53735682 Loss: 1.5916355619424087\n",
      "Epoch: 0 Sample: 13700000 / 53735682 Loss: 1.5117514039544226\n",
      "Epoch: 0 Sample: 13710000 / 53735682 Loss: 1.4793502326942956\n",
      "Epoch: 0 Sample: 13720000 / 53735682 Loss: 1.4701449716229595\n",
      "Epoch: 0 Sample: 13730000 / 53735682 Loss: 1.485010717832519\n",
      "Epoch: 0 Sample: 13740000 / 53735682 Loss: 1.4817320257276436\n",
      "Epoch: 0 Sample: 13750000 / 53735682 Loss: 1.5053769704573012\n",
      "Epoch: 0 Sample: 13760000 / 53735682 Loss: 1.5327619606857643\n",
      "Epoch: 0 Sample: 13770000 / 53735682 Loss: 1.525680027473459\n",
      "Epoch: 0 Sample: 13780000 / 53735682 Loss: 1.5346404632828734\n",
      "Epoch: 0 Sample: 13790000 / 53735682 Loss: 1.4864914081878402\n",
      "Epoch: 0 Sample: 13800000 / 53735682 Loss: 1.5114938894904881\n",
      "Epoch: 0 Sample: 13810000 / 53735682 Loss: 1.5469430294925965\n",
      "Epoch: 0 Sample: 13820000 / 53735682 Loss: 1.6018945547566728\n",
      "Epoch: 0 Sample: 13830000 / 53735682 Loss: 1.5505626087108482\n",
      "Epoch: 0 Sample: 13840000 / 53735682 Loss: 1.534414138901712\n",
      "Epoch: 0 Sample: 13850000 / 53735682 Loss: 1.4721834659863167\n",
      "Epoch: 0 Sample: 13860000 / 53735682 Loss: 1.4857995650080933\n",
      "Epoch: 0 Sample: 13870000 / 53735682 Loss: 1.503960103797371\n",
      "Epoch: 0 Sample: 13880000 / 53735682 Loss: 1.468204526260941\n",
      "Epoch: 0 Sample: 13890000 / 53735682 Loss: 1.5159641180921455\n",
      "Epoch: 0 Sample: 13900000 / 53735682 Loss: 1.4418282558520086\n",
      "Epoch: 0 Sample: 13910000 / 53735682 Loss: 1.4795444180205768\n",
      "Epoch: 0 Sample: 13920000 / 53735682 Loss: 1.5494852370332626\n",
      "Epoch: 0 Sample: 13930000 / 53735682 Loss: 1.5401950952659496\n",
      "Epoch: 0 Sample: 13940000 / 53735682 Loss: 1.369562696821681\n",
      "Epoch: 0 Sample: 13950000 / 53735682 Loss: 1.469668706778593\n",
      "Epoch: 0 Sample: 13960000 / 53735682 Loss: 1.5350739122834756\n",
      "Epoch: 0 Sample: 13970000 / 53735682 Loss: 1.4599511395215832\n",
      "Epoch: 0 Sample: 13980000 / 53735682 Loss: 1.5209850219811254\n",
      "Epoch: 0 Sample: 13990000 / 53735682 Loss: 1.5531920732340831\n",
      "Epoch: 0 Sample: 14000000 / 53735682 Loss: 1.4131546240967046\n",
      "Epoch: 0 Sample: 14010000 / 53735682 Loss: 1.5347420775368326\n",
      "Epoch: 0 Sample: 14020000 / 53735682 Loss: 1.5419929625866131\n",
      "Epoch: 0 Sample: 14030000 / 53735682 Loss: 1.596867237239203\n",
      "Epoch: 0 Sample: 14040000 / 53735682 Loss: 1.4851004511937251\n",
      "Epoch: 0 Sample: 14050000 / 53735682 Loss: 1.535479005865045\n",
      "Epoch: 0 Sample: 14060000 / 53735682 Loss: 1.5170833371037757\n",
      "Epoch: 0 Sample: 14070000 / 53735682 Loss: 1.5608624013246026\n",
      "Epoch: 0 Sample: 14080000 / 53735682 Loss: 1.5589131952634225\n",
      "Epoch: 0 Sample: 14090000 / 53735682 Loss: 1.4965645615291476\n",
      "Epoch: 0 Sample: 14100000 / 53735682 Loss: 1.45039262224384\n",
      "Epoch: 0 Sample: 14110000 / 53735682 Loss: 1.471919001826477\n",
      "Epoch: 0 Sample: 14120000 / 53735682 Loss: 1.529502539615414\n",
      "Epoch: 0 Sample: 14130000 / 53735682 Loss: 1.434840316305433\n",
      "Epoch: 0 Sample: 14140000 / 53735682 Loss: 1.5061227149159588\n",
      "Epoch: 0 Sample: 14150000 / 53735682 Loss: 1.4423519755722598\n",
      "Epoch: 0 Sample: 14160000 / 53735682 Loss: 1.5389953753053573\n",
      "Epoch: 0 Sample: 14170000 / 53735682 Loss: 1.4771820272270513\n",
      "Epoch: 0 Sample: 14180000 / 53735682 Loss: 1.5245883536947604\n",
      "Epoch: 0 Sample: 14190000 / 53735682 Loss: 1.544199864044584\n",
      "Epoch: 0 Sample: 14200000 / 53735682 Loss: 1.5463803609622724\n",
      "Epoch: 0 Sample: 14210000 / 53735682 Loss: 1.4682895983146618\n",
      "Epoch: 0 Sample: 14220000 / 53735682 Loss: 1.4815753752239758\n",
      "Epoch: 0 Sample: 14230000 / 53735682 Loss: 1.475425308545756\n",
      "Epoch: 0 Sample: 14240000 / 53735682 Loss: 1.5623955244460122\n",
      "Epoch: 0 Sample: 14250000 / 53735682 Loss: 1.5285654970916385\n",
      "Epoch: 0 Sample: 14260000 / 53735682 Loss: 1.4858824975655502\n",
      "Epoch: 0 Sample: 14270000 / 53735682 Loss: 1.4811406200470225\n",
      "Epoch: 0 Sample: 14280000 / 53735682 Loss: 1.4082942307740831\n",
      "Epoch: 0 Sample: 14290000 / 53735682 Loss: 1.4867593062223883\n",
      "Epoch: 0 Sample: 14300000 / 53735682 Loss: 1.5930337906220875\n",
      "Epoch: 0 Sample: 14310000 / 53735682 Loss: 1.482488961799409\n",
      "Epoch: 0 Sample: 14320000 / 53735682 Loss: 1.5058872302102613\n",
      "Epoch: 0 Sample: 14330000 / 53735682 Loss: 1.5369750312939212\n",
      "Epoch: 0 Sample: 14340000 / 53735682 Loss: 1.5480171199945654\n",
      "Epoch: 0 Sample: 14350000 / 53735682 Loss: 1.4569142718395498\n",
      "Epoch: 0 Sample: 14360000 / 53735682 Loss: 1.48654112587058\n",
      "Epoch: 0 Sample: 14370000 / 53735682 Loss: 1.5137706252552747\n",
      "Epoch: 0 Sample: 14380000 / 53735682 Loss: 1.4850680449139406\n",
      "Epoch: 0 Sample: 14390000 / 53735682 Loss: 1.532523121264724\n",
      "Epoch: 0 Sample: 14400000 / 53735682 Loss: 1.5384113149056011\n",
      "Epoch: 0 Sample: 14410000 / 53735682 Loss: 1.4673354008270416\n",
      "Epoch: 0 Sample: 14420000 / 53735682 Loss: 1.4878904003210578\n",
      "Epoch: 0 Sample: 14430000 / 53735682 Loss: 1.5520497973038534\n",
      "Epoch: 0 Sample: 14440000 / 53735682 Loss: 1.5288310607053144\n",
      "Epoch: 0 Sample: 14450000 / 53735682 Loss: 1.4811545220114661\n",
      "Epoch: 0 Sample: 14460000 / 53735682 Loss: 1.529657965267407\n",
      "Epoch: 0 Sample: 14470000 / 53735682 Loss: 1.4297867210756896\n",
      "Epoch: 0 Sample: 14480000 / 53735682 Loss: 1.5552269223616888\n",
      "Epoch: 0 Sample: 14490000 / 53735682 Loss: 1.5287906135071823\n",
      "Epoch: 0 Sample: 14500000 / 53735682 Loss: 1.5378344214974735\n",
      "Epoch: 0 Sample: 14510000 / 53735682 Loss: 1.5062231160762138\n",
      "Epoch: 0 Sample: 14520000 / 53735682 Loss: 1.5072662591954884\n",
      "Epoch: 0 Sample: 14530000 / 53735682 Loss: 1.4803668801657814\n",
      "Epoch: 0 Sample: 14540000 / 53735682 Loss: 1.4680373533518751\n",
      "Epoch: 0 Sample: 14550000 / 53735682 Loss: 1.526248138205178\n",
      "Epoch: 0 Sample: 14560000 / 53735682 Loss: 1.493455901559411\n",
      "Epoch: 0 Sample: 14570000 / 53735682 Loss: 1.5572056377605379\n",
      "Epoch: 0 Sample: 14580000 / 53735682 Loss: 1.5134398162079348\n",
      "Epoch: 0 Sample: 14590000 / 53735682 Loss: 1.4612269675825167\n",
      "Epoch: 0 Sample: 14600000 / 53735682 Loss: 1.5794103952226661\n",
      "Epoch: 0 Sample: 14610000 / 53735682 Loss: 1.5203376433795694\n",
      "Epoch: 0 Sample: 14620000 / 53735682 Loss: 1.4339008193938425\n",
      "Epoch: 0 Sample: 14630000 / 53735682 Loss: 1.4578679572313435\n",
      "Epoch: 0 Sample: 14640000 / 53735682 Loss: 1.510110173698846\n",
      "Epoch: 0 Sample: 14650000 / 53735682 Loss: 1.5165734009627467\n",
      "Epoch: 0 Sample: 14660000 / 53735682 Loss: 1.4703959841371659\n",
      "Epoch: 0 Sample: 14670000 / 53735682 Loss: 1.499188540247823\n",
      "Epoch: 0 Sample: 14680000 / 53735682 Loss: 1.46724955327159\n",
      "Epoch: 0 Sample: 14690000 / 53735682 Loss: 1.5393744267794367\n",
      "Epoch: 0 Sample: 14700000 / 53735682 Loss: 1.5522184044674239\n",
      "Epoch: 0 Sample: 14710000 / 53735682 Loss: 1.4704717720367786\n",
      "Epoch: 0 Sample: 14720000 / 53735682 Loss: 1.4202834891273\n",
      "Epoch: 0 Sample: 14730000 / 53735682 Loss: 1.3667855296918638\n",
      "Epoch: 0 Sample: 14740000 / 53735682 Loss: 1.442600612936444\n",
      "Epoch: 0 Sample: 14750000 / 53735682 Loss: 1.4598008493431427\n",
      "Epoch: 0 Sample: 14760000 / 53735682 Loss: 1.468447947987943\n",
      "Epoch: 0 Sample: 14770000 / 53735682 Loss: 1.5620416856751187\n",
      "Epoch: 0 Sample: 14780000 / 53735682 Loss: 1.5184695366098162\n",
      "Epoch: 0 Sample: 14790000 / 53735682 Loss: 1.4828149726242863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 14800000 / 53735682 Loss: 1.4440095247244091\n",
      "Epoch: 0 Sample: 14810000 / 53735682 Loss: 1.4826166754934067\n",
      "Epoch: 0 Sample: 14820000 / 53735682 Loss: 1.4808787010937192\n",
      "Epoch: 0 Sample: 14830000 / 53735682 Loss: 1.4830071222843793\n",
      "Epoch: 0 Sample: 14840000 / 53735682 Loss: 1.585352433692763\n",
      "Epoch: 0 Sample: 14850000 / 53735682 Loss: 1.453240942209458\n",
      "Epoch: 0 Sample: 14860000 / 53735682 Loss: 1.4665750286283605\n",
      "Epoch: 0 Sample: 14870000 / 53735682 Loss: 1.5259199274062785\n",
      "Epoch: 0 Sample: 14880000 / 53735682 Loss: 1.4738593539612872\n",
      "Epoch: 0 Sample: 14890000 / 53735682 Loss: 1.6080460284122862\n",
      "Epoch: 0 Sample: 14900000 / 53735682 Loss: 1.5201004492025962\n",
      "Epoch: 0 Sample: 14910000 / 53735682 Loss: 1.4969460477434755\n",
      "Epoch: 0 Sample: 14920000 / 53735682 Loss: 1.4499863942058666\n",
      "Epoch: 0 Sample: 14930000 / 53735682 Loss: 1.530100012275321\n",
      "Epoch: 0 Sample: 14940000 / 53735682 Loss: 1.544617141622206\n",
      "Epoch: 0 Sample: 14950000 / 53735682 Loss: 1.532413757643903\n",
      "Epoch: 0 Sample: 14960000 / 53735682 Loss: 1.4850310495665777\n",
      "Epoch: 0 Sample: 14970000 / 53735682 Loss: 1.5607462196176507\n",
      "Epoch: 0 Sample: 14980000 / 53735682 Loss: 1.5702981210225135\n",
      "Epoch: 0 Sample: 14990000 / 53735682 Loss: 1.5940220856668947\n",
      "Epoch: 0 Sample: 15000000 / 53735682 Loss: 1.3994418112723017\n",
      "Epoch: 0 Sample: 15010000 / 53735682 Loss: 1.4964486470330556\n",
      "Epoch: 0 Sample: 15020000 / 53735682 Loss: 1.4304132939069438\n",
      "Epoch: 0 Sample: 15030000 / 53735682 Loss: 1.4434996995781395\n",
      "Epoch: 0 Sample: 15040000 / 53735682 Loss: 1.539757422744041\n",
      "Epoch: 0 Sample: 15050000 / 53735682 Loss: 1.560496938013607\n",
      "Epoch: 0 Sample: 15060000 / 53735682 Loss: 1.4336841268335405\n",
      "Epoch: 0 Sample: 15070000 / 53735682 Loss: 1.5798935562705831\n",
      "Epoch: 0 Sample: 15080000 / 53735682 Loss: 1.4915595635507035\n",
      "Epoch: 0 Sample: 15090000 / 53735682 Loss: 1.4601588139478063\n",
      "Epoch: 0 Sample: 15100000 / 53735682 Loss: 1.5627207561541279\n",
      "Epoch: 0 Sample: 15110000 / 53735682 Loss: 1.5405740958127847\n",
      "Epoch: 0 Sample: 15120000 / 53735682 Loss: 1.5191529877498176\n",
      "Epoch: 0 Sample: 15130000 / 53735682 Loss: 1.4647921961296984\n",
      "Epoch: 0 Sample: 15140000 / 53735682 Loss: 1.5943145727456183\n",
      "Epoch: 0 Sample: 15150000 / 53735682 Loss: 1.4901659867230337\n",
      "Epoch: 0 Sample: 15160000 / 53735682 Loss: 1.4479310764812494\n",
      "Epoch: 0 Sample: 15170000 / 53735682 Loss: 1.5453948240519733\n",
      "Epoch: 0 Sample: 15180000 / 53735682 Loss: 1.4634479910648355\n",
      "Epoch: 0 Sample: 15190000 / 53735682 Loss: 1.5265695275068396\n",
      "Epoch: 0 Sample: 15200000 / 53735682 Loss: 1.4684949192660626\n",
      "Epoch: 0 Sample: 15210000 / 53735682 Loss: 1.4796475423588564\n",
      "Epoch: 0 Sample: 15220000 / 53735682 Loss: 1.4902715447204287\n",
      "Epoch: 0 Sample: 15230000 / 53735682 Loss: 1.4857815593393275\n",
      "Epoch: 0 Sample: 15240000 / 53735682 Loss: 1.5540547272740475\n",
      "Epoch: 0 Sample: 15250000 / 53735682 Loss: 1.6496215623746608\n",
      "Epoch: 0 Sample: 15260000 / 53735682 Loss: 1.5448632126729238\n",
      "Epoch: 0 Sample: 15270000 / 53735682 Loss: 1.5371621122377364\n",
      "Epoch: 0 Sample: 15280000 / 53735682 Loss: 1.399487466764199\n",
      "Epoch: 0 Sample: 15290000 / 53735682 Loss: 1.4850874680468729\n",
      "Epoch: 0 Sample: 15300000 / 53735682 Loss: 1.5545075978313978\n",
      "Epoch: 0 Sample: 15310000 / 53735682 Loss: 1.4680612399687623\n",
      "Epoch: 0 Sample: 15320000 / 53735682 Loss: 1.5665958182119355\n",
      "Epoch: 0 Sample: 15330000 / 53735682 Loss: 1.5809016136054403\n",
      "Epoch: 0 Sample: 15340000 / 53735682 Loss: 1.5237332173434035\n",
      "Epoch: 0 Sample: 15350000 / 53735682 Loss: 1.4827491071174492\n",
      "Epoch: 0 Sample: 15360000 / 53735682 Loss: 1.5022893611061516\n",
      "Epoch: 0 Sample: 15370000 / 53735682 Loss: 1.464278626292047\n",
      "Epoch: 0 Sample: 15380000 / 53735682 Loss: 1.3552897778649968\n",
      "Epoch: 0 Sample: 15390000 / 53735682 Loss: 1.492373064567074\n",
      "Epoch: 0 Sample: 15400000 / 53735682 Loss: 1.5418244160146828\n",
      "Epoch: 0 Sample: 15410000 / 53735682 Loss: 1.4627621668562383\n",
      "Epoch: 0 Sample: 15420000 / 53735682 Loss: 1.4719019094858043\n",
      "Epoch: 0 Sample: 15430000 / 53735682 Loss: 1.4689545094630234\n",
      "Epoch: 0 Sample: 15440000 / 53735682 Loss: 1.5609745571974445\n",
      "Epoch: 0 Sample: 15450000 / 53735682 Loss: 1.4489033859743627\n",
      "Epoch: 0 Sample: 15460000 / 53735682 Loss: 1.4824557274537085\n",
      "Epoch: 0 Sample: 15470000 / 53735682 Loss: 1.503643966827485\n",
      "Epoch: 0 Sample: 15480000 / 53735682 Loss: 1.504194740682027\n",
      "Epoch: 0 Sample: 15490000 / 53735682 Loss: 1.543817814320578\n",
      "Epoch: 0 Sample: 15500000 / 53735682 Loss: 1.4542457248001446\n",
      "Epoch: 0 Sample: 15510000 / 53735682 Loss: 1.528728047028233\n",
      "Epoch: 0 Sample: 15520000 / 53735682 Loss: 1.5206334059614002\n",
      "Epoch: 0 Sample: 15530000 / 53735682 Loss: 1.5680446795749146\n",
      "Epoch: 0 Sample: 15540000 / 53735682 Loss: 1.4953029718973676\n",
      "Epoch: 0 Sample: 15550000 / 53735682 Loss: 1.501458404916863\n",
      "Epoch: 0 Sample: 15560000 / 53735682 Loss: 1.5978933004048184\n",
      "Epoch: 0 Sample: 15570000 / 53735682 Loss: 1.5074425905937585\n",
      "Epoch: 0 Sample: 15580000 / 53735682 Loss: 1.5746553413615478\n",
      "Epoch: 0 Sample: 15590000 / 53735682 Loss: 1.5524037446899435\n",
      "Epoch: 0 Sample: 15600000 / 53735682 Loss: 1.5958808419674964\n",
      "Epoch: 0 Sample: 15610000 / 53735682 Loss: 1.3922986096851289\n",
      "Epoch: 0 Sample: 15620000 / 53735682 Loss: 1.516179424287602\n",
      "Epoch: 0 Sample: 15630000 / 53735682 Loss: 1.5672599570759855\n",
      "Epoch: 0 Sample: 15640000 / 53735682 Loss: 1.5696922291456015\n",
      "Epoch: 0 Sample: 15650000 / 53735682 Loss: 1.624206802996501\n",
      "Epoch: 0 Sample: 15660000 / 53735682 Loss: 1.4216874650478668\n",
      "Epoch: 0 Sample: 15670000 / 53735682 Loss: 1.5422975600757582\n",
      "Epoch: 0 Sample: 15680000 / 53735682 Loss: 1.3899263709427205\n",
      "Epoch: 0 Sample: 15690000 / 53735682 Loss: 1.477260651656934\n",
      "Epoch: 0 Sample: 15700000 / 53735682 Loss: 1.524115248399948\n",
      "Epoch: 0 Sample: 15710000 / 53735682 Loss: 1.5400373827094573\n",
      "Epoch: 0 Sample: 15720000 / 53735682 Loss: 1.4853479282577118\n",
      "Epoch: 0 Sample: 15730000 / 53735682 Loss: 1.5440972589934816\n",
      "Epoch: 0 Sample: 15740000 / 53735682 Loss: 1.481996949495898\n",
      "Epoch: 0 Sample: 15750000 / 53735682 Loss: 1.5185117012126315\n",
      "Epoch: 0 Sample: 15760000 / 53735682 Loss: 1.4663154295281597\n",
      "Epoch: 0 Sample: 15770000 / 53735682 Loss: 1.5078319334671213\n",
      "Epoch: 0 Sample: 15780000 / 53735682 Loss: 1.474451902411031\n",
      "Epoch: 0 Sample: 15790000 / 53735682 Loss: 1.4823170180760006\n",
      "Epoch: 0 Sample: 15800000 / 53735682 Loss: 1.5123445054456455\n",
      "Epoch: 0 Sample: 15810000 / 53735682 Loss: 1.4691370852725538\n",
      "Epoch: 0 Sample: 15820000 / 53735682 Loss: 1.461215555460608\n",
      "Epoch: 0 Sample: 15830000 / 53735682 Loss: 1.4988505112342476\n",
      "Epoch: 0 Sample: 15840000 / 53735682 Loss: 1.4770661130777807\n",
      "Epoch: 0 Sample: 15850000 / 53735682 Loss: 1.4870699756326022\n",
      "Epoch: 0 Sample: 15860000 / 53735682 Loss: 1.547253987441183\n",
      "Epoch: 0 Sample: 15870000 / 53735682 Loss: 1.4676259996804162\n",
      "Epoch: 0 Sample: 15880000 / 53735682 Loss: 1.540650947926538\n",
      "Epoch: 0 Sample: 15890000 / 53735682 Loss: 1.4978249798147094\n",
      "Epoch: 0 Sample: 15900000 / 53735682 Loss: 1.5181459570060647\n",
      "Epoch: 0 Sample: 15910000 / 53735682 Loss: 1.5339781310557608\n",
      "Epoch: 0 Sample: 15920000 / 53735682 Loss: 1.537425794434494\n",
      "Epoch: 0 Sample: 15930000 / 53735682 Loss: 1.538830106054721\n",
      "Epoch: 0 Sample: 15940000 / 53735682 Loss: 1.4865345295256573\n",
      "Epoch: 0 Sample: 15950000 / 53735682 Loss: 1.4988039137257827\n",
      "Epoch: 0 Sample: 15960000 / 53735682 Loss: 1.5317088013064368\n",
      "Epoch: 0 Sample: 15970000 / 53735682 Loss: 1.4633380122236566\n",
      "Epoch: 0 Sample: 15980000 / 53735682 Loss: 1.4889511228120647\n",
      "Epoch: 0 Sample: 15990000 / 53735682 Loss: 1.4881913152288728\n",
      "Epoch: 0 Sample: 16000000 / 53735682 Loss: 1.4603376811530415\n",
      "Epoch: 0 Sample: 16010000 / 53735682 Loss: 1.4739268553254798\n",
      "Epoch: 0 Sample: 16020000 / 53735682 Loss: 1.4659939446153056\n",
      "Epoch: 0 Sample: 16030000 / 53735682 Loss: 1.5890462917584334\n",
      "Epoch: 0 Sample: 16040000 / 53735682 Loss: 1.5804862576371146\n",
      "Epoch: 0 Sample: 16050000 / 53735682 Loss: 1.3921203648019365\n",
      "Epoch: 0 Sample: 16060000 / 53735682 Loss: 1.470568549932055\n",
      "Epoch: 0 Sample: 16070000 / 53735682 Loss: 1.5356451317010222\n",
      "Epoch: 0 Sample: 16080000 / 53735682 Loss: 1.4691783383939476\n",
      "Epoch: 0 Sample: 16090000 / 53735682 Loss: 1.5315205445231728\n",
      "Epoch: 0 Sample: 16100000 / 53735682 Loss: 1.4796875411654289\n",
      "Epoch: 0 Sample: 16110000 / 53735682 Loss: 1.5461657956622665\n",
      "Epoch: 0 Sample: 16120000 / 53735682 Loss: 1.5171406076038576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 16130000 / 53735682 Loss: 1.6363244553456902\n",
      "Epoch: 0 Sample: 16140000 / 53735682 Loss: 1.5008579357778218\n",
      "Epoch: 0 Sample: 16150000 / 53735682 Loss: 1.5624703612137083\n",
      "Epoch: 0 Sample: 16160000 / 53735682 Loss: 1.4739192509207353\n",
      "Epoch: 0 Sample: 16170000 / 53735682 Loss: 1.4416325160756776\n",
      "Epoch: 0 Sample: 16180000 / 53735682 Loss: 1.5856480850023\n",
      "Epoch: 0 Sample: 16190000 / 53735682 Loss: 1.4254123601190298\n",
      "Epoch: 0 Sample: 16200000 / 53735682 Loss: 1.5850211266987217\n",
      "Epoch: 0 Sample: 16210000 / 53735682 Loss: 1.5528162592711956\n",
      "Epoch: 0 Sample: 16220000 / 53735682 Loss: 1.4270527027405842\n",
      "Epoch: 0 Sample: 16230000 / 53735682 Loss: 1.5194129499776554\n",
      "Epoch: 0 Sample: 16240000 / 53735682 Loss: 1.4392843822134143\n",
      "Epoch: 0 Sample: 16250000 / 53735682 Loss: 1.482004315750857\n",
      "Epoch: 0 Sample: 16260000 / 53735682 Loss: 1.4832074187315432\n",
      "Epoch: 0 Sample: 16270000 / 53735682 Loss: 1.5623038078858968\n",
      "Epoch: 0 Sample: 16280000 / 53735682 Loss: 1.5010256664621906\n",
      "Epoch: 0 Sample: 16290000 / 53735682 Loss: 1.4429502580513685\n",
      "Epoch: 0 Sample: 16300000 / 53735682 Loss: 1.5382168681335555\n",
      "Epoch: 0 Sample: 16310000 / 53735682 Loss: 1.5445623276125833\n",
      "Epoch: 0 Sample: 16320000 / 53735682 Loss: 1.5197333525438304\n",
      "Epoch: 0 Sample: 16330000 / 53735682 Loss: 1.491073097807089\n",
      "Epoch: 0 Sample: 16340000 / 53735682 Loss: 1.5214436975730012\n",
      "Epoch: 0 Sample: 16350000 / 53735682 Loss: 1.4407215779546105\n",
      "Epoch: 0 Sample: 16360000 / 53735682 Loss: 1.4386027502521608\n",
      "Epoch: 0 Sample: 16370000 / 53735682 Loss: 1.5449705750119305\n",
      "Epoch: 0 Sample: 16380000 / 53735682 Loss: 1.501387452768448\n",
      "Epoch: 0 Sample: 16390000 / 53735682 Loss: 1.4103059043161168\n",
      "Epoch: 0 Sample: 16400000 / 53735682 Loss: 1.5153171078426815\n",
      "Epoch: 0 Sample: 16410000 / 53735682 Loss: 1.4936746775645606\n",
      "Epoch: 0 Sample: 16420000 / 53735682 Loss: 1.3646919801841615\n",
      "Epoch: 0 Sample: 16430000 / 53735682 Loss: 1.5242416373200285\n",
      "Epoch: 0 Sample: 16440000 / 53735682 Loss: 1.5013248457108097\n",
      "Epoch: 0 Sample: 16450000 / 53735682 Loss: 1.5727186694355528\n",
      "Epoch: 0 Sample: 16460000 / 53735682 Loss: 1.4451725251523584\n",
      "Epoch: 0 Sample: 16470000 / 53735682 Loss: 1.6063229102925178\n",
      "Epoch: 0 Sample: 16480000 / 53735682 Loss: 1.5218343529674716\n",
      "Epoch: 0 Sample: 16490000 / 53735682 Loss: 1.521155235977487\n",
      "Epoch: 0 Sample: 16500000 / 53735682 Loss: 1.4703744154219902\n",
      "Epoch: 0 Sample: 16510000 / 53735682 Loss: 1.467708209726212\n",
      "Epoch: 0 Sample: 16520000 / 53735682 Loss: 1.474793769303794\n",
      "Epoch: 0 Sample: 16530000 / 53735682 Loss: 1.5364797218633484\n",
      "Epoch: 0 Sample: 16540000 / 53735682 Loss: 1.5470112133466412\n",
      "Epoch: 0 Sample: 16550000 / 53735682 Loss: 1.4328255398249952\n",
      "Epoch: 0 Sample: 16560000 / 53735682 Loss: 1.5253944613200456\n",
      "Epoch: 0 Sample: 16570000 / 53735682 Loss: 1.5164022774892691\n",
      "Epoch: 0 Sample: 16580000 / 53735682 Loss: 1.4269796841949045\n",
      "Epoch: 0 Sample: 16590000 / 53735682 Loss: 1.5175711472452242\n",
      "Epoch: 0 Sample: 16600000 / 53735682 Loss: 1.428438573425769\n",
      "Epoch: 0 Sample: 16610000 / 53735682 Loss: 1.5307705963784088\n",
      "Epoch: 0 Sample: 16620000 / 53735682 Loss: 1.43243018965557\n",
      "Epoch: 0 Sample: 16630000 / 53735682 Loss: 1.5332652381435397\n",
      "Epoch: 0 Sample: 16640000 / 53735682 Loss: 1.4824850636682898\n",
      "Epoch: 0 Sample: 16650000 / 53735682 Loss: 1.5450401836155816\n",
      "Epoch: 0 Sample: 16660000 / 53735682 Loss: 1.52794352545244\n",
      "Epoch: 0 Sample: 16670000 / 53735682 Loss: 1.5791239622960636\n",
      "Epoch: 0 Sample: 16680000 / 53735682 Loss: 1.4786327131907409\n",
      "Epoch: 0 Sample: 16690000 / 53735682 Loss: 1.5973300320444903\n",
      "Epoch: 0 Sample: 16700000 / 53735682 Loss: 1.4445438244282796\n",
      "Epoch: 0 Sample: 16710000 / 53735682 Loss: 1.4783187274973653\n",
      "Epoch: 0 Sample: 16720000 / 53735682 Loss: 1.4148967171383562\n",
      "Epoch: 0 Sample: 16730000 / 53735682 Loss: 1.434684920410546\n",
      "Epoch: 0 Sample: 16740000 / 53735682 Loss: 1.5515512588144498\n",
      "Epoch: 0 Sample: 16750000 / 53735682 Loss: 1.509645804734442\n",
      "Epoch: 0 Sample: 16760000 / 53735682 Loss: 1.4615961215503486\n",
      "Epoch: 0 Sample: 16770000 / 53735682 Loss: 1.444662335575095\n",
      "Epoch: 0 Sample: 16780000 / 53735682 Loss: 1.4835810885478873\n",
      "Epoch: 0 Sample: 16790000 / 53735682 Loss: 1.4474601795987412\n",
      "Epoch: 0 Sample: 16800000 / 53735682 Loss: 1.4013422002633127\n",
      "Epoch: 0 Sample: 16810000 / 53735682 Loss: 1.4542374599211203\n",
      "Epoch: 0 Sample: 16820000 / 53735682 Loss: 1.4906335424078523\n",
      "Epoch: 0 Sample: 16830000 / 53735682 Loss: 1.576989201194574\n",
      "Epoch: 0 Sample: 16840000 / 53735682 Loss: 1.4575755667158101\n",
      "Epoch: 0 Sample: 16850000 / 53735682 Loss: 1.4657915742383953\n",
      "Epoch: 0 Sample: 16860000 / 53735682 Loss: 1.5523727397542562\n",
      "Epoch: 0 Sample: 16870000 / 53735682 Loss: 1.4743521209908708\n",
      "Epoch: 0 Sample: 16880000 / 53735682 Loss: 1.5566064196553544\n",
      "Epoch: 0 Sample: 16890000 / 53735682 Loss: 1.4671833647283297\n",
      "Epoch: 0 Sample: 16900000 / 53735682 Loss: 1.5170620304181126\n",
      "Epoch: 0 Sample: 16910000 / 53735682 Loss: 1.4816683119570744\n",
      "Epoch: 0 Sample: 16920000 / 53735682 Loss: 1.4272328315826113\n",
      "Epoch: 0 Sample: 16930000 / 53735682 Loss: 1.3771998123884366\n",
      "Epoch: 0 Sample: 16940000 / 53735682 Loss: 1.4924967359024548\n",
      "Epoch: 0 Sample: 16950000 / 53735682 Loss: 1.5528360380401074\n",
      "Epoch: 0 Sample: 16960000 / 53735682 Loss: 1.4671008069738152\n",
      "Epoch: 0 Sample: 16970000 / 53735682 Loss: 1.4888171605766547\n",
      "Epoch: 0 Sample: 16980000 / 53735682 Loss: 1.4962398186229136\n",
      "Epoch: 0 Sample: 16990000 / 53735682 Loss: 1.4698578608313146\n",
      "Epoch: 0 Sample: 17000000 / 53735682 Loss: 1.4253473655076698\n",
      "Epoch: 0 Sample: 17010000 / 53735682 Loss: 1.5058361408268879\n",
      "Epoch: 0 Sample: 17020000 / 53735682 Loss: 1.5450781738970178\n",
      "Epoch: 0 Sample: 17030000 / 53735682 Loss: 1.563663199389663\n",
      "Epoch: 0 Sample: 17040000 / 53735682 Loss: 1.3761450377262463\n",
      "Epoch: 0 Sample: 17050000 / 53735682 Loss: 1.42561425375577\n",
      "Epoch: 0 Sample: 17060000 / 53735682 Loss: 1.4675039193492663\n",
      "Epoch: 0 Sample: 17070000 / 53735682 Loss: 1.5691302180867475\n",
      "Epoch: 0 Sample: 17080000 / 53735682 Loss: 1.5466003371157881\n",
      "Epoch: 0 Sample: 17090000 / 53735682 Loss: 1.505750485840235\n",
      "Epoch: 0 Sample: 17100000 / 53735682 Loss: 1.5158267958487142\n",
      "Epoch: 0 Sample: 17110000 / 53735682 Loss: 1.5357608488365533\n",
      "Epoch: 0 Sample: 17120000 / 53735682 Loss: 1.4634152388760933\n",
      "Epoch: 0 Sample: 17130000 / 53735682 Loss: 1.5198291607881576\n",
      "Epoch: 0 Sample: 17140000 / 53735682 Loss: 1.5086674526537114\n",
      "Epoch: 0 Sample: 17150000 / 53735682 Loss: 1.6072667555445364\n",
      "Epoch: 0 Sample: 17160000 / 53735682 Loss: 1.4918397883185253\n",
      "Epoch: 0 Sample: 17170000 / 53735682 Loss: 1.5032535003944112\n",
      "Epoch: 0 Sample: 17180000 / 53735682 Loss: 1.5364771468466154\n",
      "Epoch: 0 Sample: 17190000 / 53735682 Loss: 1.5205888548456086\n",
      "Epoch: 0 Sample: 17200000 / 53735682 Loss: 1.4673043326809874\n",
      "Epoch: 0 Sample: 17210000 / 53735682 Loss: 1.4773656535259305\n",
      "Epoch: 0 Sample: 17220000 / 53735682 Loss: 1.611838199720179\n",
      "Epoch: 0 Sample: 17230000 / 53735682 Loss: 1.5020407858097298\n",
      "Epoch: 0 Sample: 17240000 / 53735682 Loss: 1.4890021964345497\n",
      "Epoch: 0 Sample: 17250000 / 53735682 Loss: 1.5018644282307314\n",
      "Epoch: 0 Sample: 17260000 / 53735682 Loss: 1.5352964488725094\n",
      "Epoch: 0 Sample: 17270000 / 53735682 Loss: 1.538786342622523\n",
      "Epoch: 0 Sample: 17280000 / 53735682 Loss: 1.522396106722053\n",
      "Epoch: 0 Sample: 17290000 / 53735682 Loss: 1.4725895653109577\n",
      "Epoch: 0 Sample: 17300000 / 53735682 Loss: 1.420727570167457\n",
      "Epoch: 0 Sample: 17310000 / 53735682 Loss: 1.479779936515574\n",
      "Epoch: 0 Sample: 17320000 / 53735682 Loss: 1.5957367400032005\n",
      "Epoch: 0 Sample: 17330000 / 53735682 Loss: 1.5405686448182574\n",
      "Epoch: 0 Sample: 17340000 / 53735682 Loss: 1.451206579802947\n",
      "Epoch: 0 Sample: 17350000 / 53735682 Loss: 1.5964227881471578\n",
      "Epoch: 0 Sample: 17360000 / 53735682 Loss: 1.5384718970443794\n",
      "Epoch: 0 Sample: 17370000 / 53735682 Loss: 1.498295106133307\n",
      "Epoch: 0 Sample: 17380000 / 53735682 Loss: 1.44585806363156\n",
      "Epoch: 0 Sample: 17390000 / 53735682 Loss: 1.431844351906272\n",
      "Epoch: 0 Sample: 17400000 / 53735682 Loss: 1.5768966329041034\n",
      "Epoch: 0 Sample: 17410000 / 53735682 Loss: 1.5086502461470648\n",
      "Epoch: 0 Sample: 17420000 / 53735682 Loss: 1.441618099979023\n",
      "Epoch: 0 Sample: 17430000 / 53735682 Loss: 1.507613479710028\n",
      "Epoch: 0 Sample: 17440000 / 53735682 Loss: 1.4710754259252075\n",
      "Epoch: 0 Sample: 17450000 / 53735682 Loss: 1.4524951540369981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 17460000 / 53735682 Loss: 1.4574551472698944\n",
      "Epoch: 0 Sample: 17470000 / 53735682 Loss: 1.4974545447140486\n",
      "Epoch: 0 Sample: 17480000 / 53735682 Loss: 1.4397071130502823\n",
      "Epoch: 0 Sample: 17490000 / 53735682 Loss: 1.493715476653295\n",
      "Epoch: 0 Sample: 17500000 / 53735682 Loss: 1.5054650113666808\n",
      "Epoch: 0 Sample: 17510000 / 53735682 Loss: 1.4881111887465757\n",
      "Epoch: 0 Sample: 17520000 / 53735682 Loss: 1.6134696968818893\n",
      "Epoch: 0 Sample: 17530000 / 53735682 Loss: 1.4476057128082545\n",
      "Epoch: 0 Sample: 17540000 / 53735682 Loss: 1.5070362989363772\n",
      "Epoch: 0 Sample: 17550000 / 53735682 Loss: 1.469680458038294\n",
      "Epoch: 0 Sample: 17560000 / 53735682 Loss: 1.576383934998678\n",
      "Epoch: 0 Sample: 17570000 / 53735682 Loss: 1.4840254265550334\n",
      "Epoch: 0 Sample: 17580000 / 53735682 Loss: 1.5095450379087996\n",
      "Epoch: 0 Sample: 17590000 / 53735682 Loss: 1.5213575544339464\n",
      "Epoch: 0 Sample: 17600000 / 53735682 Loss: 1.5387288382342739\n",
      "Epoch: 0 Sample: 17610000 / 53735682 Loss: 1.5154089578122327\n",
      "Epoch: 0 Sample: 17620000 / 53735682 Loss: 1.5344042293539337\n",
      "Epoch: 0 Sample: 17630000 / 53735682 Loss: 1.531054437526076\n",
      "Epoch: 0 Sample: 17640000 / 53735682 Loss: 1.4235829850619344\n",
      "Epoch: 0 Sample: 17650000 / 53735682 Loss: 1.5218768826194298\n",
      "Epoch: 0 Sample: 17660000 / 53735682 Loss: 1.5313252553182273\n",
      "Epoch: 0 Sample: 17670000 / 53735682 Loss: 1.5138078744988333\n",
      "Epoch: 0 Sample: 17680000 / 53735682 Loss: 1.4743629654098775\n",
      "Epoch: 0 Sample: 17690000 / 53735682 Loss: 1.5275605710700382\n",
      "Epoch: 0 Sample: 17700000 / 53735682 Loss: 1.464072233721104\n",
      "Epoch: 0 Sample: 17710000 / 53735682 Loss: 1.4514793779640311\n",
      "Epoch: 0 Sample: 17720000 / 53735682 Loss: 1.5769861933439193\n",
      "Epoch: 0 Sample: 17730000 / 53735682 Loss: 1.5318660594319589\n",
      "Epoch: 0 Sample: 17740000 / 53735682 Loss: 1.5153927429525027\n",
      "Epoch: 0 Sample: 17750000 / 53735682 Loss: 1.4730604022865015\n",
      "Epoch: 0 Sample: 17760000 / 53735682 Loss: 1.4147482568748964\n",
      "Epoch: 0 Sample: 17770000 / 53735682 Loss: 1.4752950987561566\n",
      "Epoch: 0 Sample: 17780000 / 53735682 Loss: 1.4639133833699345\n",
      "Epoch: 0 Sample: 17790000 / 53735682 Loss: 1.4882054150253967\n",
      "Epoch: 0 Sample: 17800000 / 53735682 Loss: 1.481973416030561\n",
      "Epoch: 0 Sample: 17810000 / 53735682 Loss: 1.430089870332954\n",
      "Epoch: 0 Sample: 17820000 / 53735682 Loss: 1.5127368543257758\n",
      "Epoch: 0 Sample: 17830000 / 53735682 Loss: 1.4598269579069112\n",
      "Epoch: 0 Sample: 17840000 / 53735682 Loss: 1.4430232448826823\n",
      "Epoch: 0 Sample: 17850000 / 53735682 Loss: 1.5460069283221654\n",
      "Epoch: 0 Sample: 17860000 / 53735682 Loss: 1.4768211844697066\n",
      "Epoch: 0 Sample: 17870000 / 53735682 Loss: 1.4354427786630404\n",
      "Epoch: 0 Sample: 17880000 / 53735682 Loss: 1.4882884521979756\n",
      "Epoch: 0 Sample: 17890000 / 53735682 Loss: 1.4527661397294982\n",
      "Epoch: 0 Sample: 17900000 / 53735682 Loss: 1.5266499919928553\n",
      "Epoch: 0 Sample: 17910000 / 53735682 Loss: 1.4797276456903883\n",
      "Epoch: 0 Sample: 17920000 / 53735682 Loss: 1.5023694725456957\n",
      "Epoch: 0 Sample: 17930000 / 53735682 Loss: 1.598263912459449\n",
      "Epoch: 0 Sample: 17940000 / 53735682 Loss: 1.5001220088628429\n",
      "Epoch: 0 Sample: 17950000 / 53735682 Loss: 1.5546051322316736\n",
      "Epoch: 0 Sample: 17960000 / 53735682 Loss: 1.5243006176380824\n",
      "Epoch: 0 Sample: 17970000 / 53735682 Loss: 1.5119181243761135\n",
      "Epoch: 0 Sample: 17980000 / 53735682 Loss: 1.4241028018715547\n",
      "Epoch: 0 Sample: 17990000 / 53735682 Loss: 1.4421910495464654\n",
      "Epoch: 0 Sample: 18000000 / 53735682 Loss: 1.4619554861177815\n",
      "Epoch: 0 Sample: 18010000 / 53735682 Loss: 1.567303179584139\n",
      "Epoch: 0 Sample: 18020000 / 53735682 Loss: 1.5273430707830842\n",
      "Epoch: 0 Sample: 18030000 / 53735682 Loss: 1.447626389989398\n",
      "Epoch: 0 Sample: 18040000 / 53735682 Loss: 1.458031723343315\n",
      "Epoch: 0 Sample: 18050000 / 53735682 Loss: 1.4976127198790437\n",
      "Epoch: 0 Sample: 18060000 / 53735682 Loss: 1.459155034285236\n",
      "Epoch: 0 Sample: 18070000 / 53735682 Loss: 1.5034225313080225\n",
      "Epoch: 0 Sample: 18080000 / 53735682 Loss: 1.3964695789712476\n",
      "Epoch: 0 Sample: 18090000 / 53735682 Loss: 1.5463592185114856\n",
      "Epoch: 0 Sample: 18100000 / 53735682 Loss: 1.381626429507786\n",
      "Epoch: 0 Sample: 18110000 / 53735682 Loss: 1.5244687422902312\n",
      "Epoch: 0 Sample: 18120000 / 53735682 Loss: 1.5363282909746945\n",
      "Epoch: 0 Sample: 18130000 / 53735682 Loss: 1.5188681617773305\n",
      "Epoch: 0 Sample: 18140000 / 53735682 Loss: 1.5293966066752822\n",
      "Epoch: 0 Sample: 18150000 / 53735682 Loss: 1.4996883159826004\n",
      "Epoch: 0 Sample: 18160000 / 53735682 Loss: 1.5529859742689924\n",
      "Epoch: 0 Sample: 18170000 / 53735682 Loss: 1.468277300992003\n",
      "Epoch: 0 Sample: 18180000 / 53735682 Loss: 1.5395494168705013\n",
      "Epoch: 0 Sample: 18190000 / 53735682 Loss: 1.4780995621476203\n",
      "Epoch: 0 Sample: 18200000 / 53735682 Loss: 1.47003527066562\n",
      "Epoch: 0 Sample: 18210000 / 53735682 Loss: 1.4708452992715007\n",
      "Epoch: 0 Sample: 18220000 / 53735682 Loss: 1.4343662459368063\n",
      "Epoch: 0 Sample: 18230000 / 53735682 Loss: 1.4792980104504556\n",
      "Epoch: 0 Sample: 18240000 / 53735682 Loss: 1.501458465376782\n",
      "Epoch: 0 Sample: 18250000 / 53735682 Loss: 1.5377952226246787\n",
      "Epoch: 0 Sample: 18260000 / 53735682 Loss: 1.4797621839137027\n",
      "Epoch: 0 Sample: 18270000 / 53735682 Loss: 1.4540666862958769\n",
      "Epoch: 0 Sample: 18280000 / 53735682 Loss: 1.4944128711485165\n",
      "Epoch: 0 Sample: 18290000 / 53735682 Loss: 1.525663754328653\n",
      "Epoch: 0 Sample: 18300000 / 53735682 Loss: 1.5131126818443754\n",
      "Epoch: 0 Sample: 18310000 / 53735682 Loss: 1.5083258263667152\n",
      "Epoch: 0 Sample: 18320000 / 53735682 Loss: 1.5038031577537083\n",
      "Epoch: 0 Sample: 18330000 / 53735682 Loss: 1.4985189528851417\n",
      "Epoch: 0 Sample: 18340000 / 53735682 Loss: 1.5444447404536015\n",
      "Epoch: 0 Sample: 18350000 / 53735682 Loss: 1.4754524353834764\n",
      "Epoch: 0 Sample: 18360000 / 53735682 Loss: 1.453728122862144\n",
      "Epoch: 0 Sample: 18370000 / 53735682 Loss: 1.4726102626000173\n",
      "Epoch: 0 Sample: 18380000 / 53735682 Loss: 1.5793433654759674\n",
      "Epoch: 0 Sample: 18390000 / 53735682 Loss: 1.468470365456477\n",
      "Epoch: 0 Sample: 18400000 / 53735682 Loss: 1.4689506286843228\n",
      "Epoch: 0 Sample: 18410000 / 53735682 Loss: 1.6032868069262256\n",
      "Epoch: 0 Sample: 18420000 / 53735682 Loss: 1.4717925725298142\n",
      "Epoch: 0 Sample: 18430000 / 53735682 Loss: 1.5169541622699607\n",
      "Epoch: 0 Sample: 18440000 / 53735682 Loss: 1.4637208839691302\n",
      "Epoch: 0 Sample: 18450000 / 53735682 Loss: 1.5219204567849545\n",
      "Epoch: 0 Sample: 18460000 / 53735682 Loss: 1.5089381108904238\n",
      "Epoch: 0 Sample: 18470000 / 53735682 Loss: 1.5546367767230413\n",
      "Epoch: 0 Sample: 18480000 / 53735682 Loss: 1.5725572210235295\n",
      "Epoch: 0 Sample: 18490000 / 53735682 Loss: 1.5413860293259511\n",
      "Epoch: 0 Sample: 18500000 / 53735682 Loss: 1.5288587644917664\n",
      "Epoch: 0 Sample: 18510000 / 53735682 Loss: 1.6057220931303904\n",
      "Epoch: 0 Sample: 18520000 / 53735682 Loss: 1.4389434514745076\n",
      "Epoch: 0 Sample: 18530000 / 53735682 Loss: 1.4110559645063607\n",
      "Epoch: 0 Sample: 18540000 / 53735682 Loss: 1.4994162163426004\n",
      "Epoch: 0 Sample: 18550000 / 53735682 Loss: 1.482641491404221\n",
      "Epoch: 0 Sample: 18560000 / 53735682 Loss: 1.4218618080987748\n",
      "Epoch: 0 Sample: 18570000 / 53735682 Loss: 1.546722680627643\n",
      "Epoch: 0 Sample: 18580000 / 53735682 Loss: 1.5059088243155823\n",
      "Epoch: 0 Sample: 18590000 / 53735682 Loss: 1.5397604880816362\n",
      "Epoch: 0 Sample: 18600000 / 53735682 Loss: 1.5477405557095993\n",
      "Epoch: 0 Sample: 18610000 / 53735682 Loss: 1.5487314999530097\n",
      "Epoch: 0 Sample: 18620000 / 53735682 Loss: 1.5137497515996408\n",
      "Epoch: 0 Sample: 18630000 / 53735682 Loss: 1.4924071245684902\n",
      "Epoch: 0 Sample: 18640000 / 53735682 Loss: 1.4833695845059909\n",
      "Epoch: 0 Sample: 18650000 / 53735682 Loss: 1.5418951483841823\n",
      "Epoch: 0 Sample: 18660000 / 53735682 Loss: 1.4777774555496186\n",
      "Epoch: 0 Sample: 18670000 / 53735682 Loss: 1.489748268248471\n",
      "Epoch: 0 Sample: 18680000 / 53735682 Loss: 1.4363032373459343\n",
      "Epoch: 0 Sample: 18690000 / 53735682 Loss: 1.5674327945268582\n",
      "Epoch: 0 Sample: 18700000 / 53735682 Loss: 1.440325701482389\n",
      "Epoch: 0 Sample: 18710000 / 53735682 Loss: 1.427338125675075\n",
      "Epoch: 0 Sample: 18720000 / 53735682 Loss: 1.4620944432391325\n",
      "Epoch: 0 Sample: 18730000 / 53735682 Loss: 1.4756824041271768\n",
      "Epoch: 0 Sample: 18740000 / 53735682 Loss: 1.4957903506654562\n",
      "Epoch: 0 Sample: 18750000 / 53735682 Loss: 1.4601522072752562\n",
      "Epoch: 0 Sample: 18760000 / 53735682 Loss: 1.4748436692131053\n",
      "Epoch: 0 Sample: 18770000 / 53735682 Loss: 1.4241165945048289\n",
      "Epoch: 0 Sample: 18780000 / 53735682 Loss: 1.5645336385009436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 18790000 / 53735682 Loss: 1.4315638724757773\n",
      "Epoch: 0 Sample: 18800000 / 53735682 Loss: 1.5617176715037324\n",
      "Epoch: 0 Sample: 18810000 / 53735682 Loss: 1.4657544763931285\n",
      "Epoch: 0 Sample: 18820000 / 53735682 Loss: 1.5174852738272846\n",
      "Epoch: 0 Sample: 18830000 / 53735682 Loss: 1.4436856508188958\n",
      "Epoch: 0 Sample: 18840000 / 53735682 Loss: 1.4950642138822774\n",
      "Epoch: 0 Sample: 18850000 / 53735682 Loss: 1.461733413943616\n",
      "Epoch: 0 Sample: 18860000 / 53735682 Loss: 1.4557663481746816\n",
      "Epoch: 0 Sample: 18870000 / 53735682 Loss: 1.5237947946070292\n",
      "Epoch: 0 Sample: 18880000 / 53735682 Loss: 1.4800712825557159\n",
      "Epoch: 0 Sample: 18890000 / 53735682 Loss: 1.5113473170040532\n",
      "Epoch: 0 Sample: 18900000 / 53735682 Loss: 1.4901570348999853\n",
      "Epoch: 0 Sample: 18910000 / 53735682 Loss: 1.476188876080684\n",
      "Epoch: 0 Sample: 18920000 / 53735682 Loss: 1.43043340902745\n",
      "Epoch: 0 Sample: 18930000 / 53735682 Loss: 1.4833292936370588\n",
      "Epoch: 0 Sample: 18940000 / 53735682 Loss: 1.5632581112561357\n",
      "Epoch: 0 Sample: 18950000 / 53735682 Loss: 1.608300740007415\n",
      "Epoch: 0 Sample: 18960000 / 53735682 Loss: 1.4700681125801434\n",
      "Epoch: 0 Sample: 18970000 / 53735682 Loss: 1.5144611879241932\n",
      "Epoch: 0 Sample: 18980000 / 53735682 Loss: 1.5056768186296086\n",
      "Epoch: 0 Sample: 18990000 / 53735682 Loss: 1.4405952525060906\n",
      "Epoch: 0 Sample: 19000000 / 53735682 Loss: 1.4734641460083493\n",
      "Epoch: 0 Sample: 19010000 / 53735682 Loss: 1.5085097507916159\n",
      "Epoch: 0 Sample: 19020000 / 53735682 Loss: 1.5967682402318122\n",
      "Epoch: 0 Sample: 19030000 / 53735682 Loss: 1.4933757897991056\n",
      "Epoch: 0 Sample: 19040000 / 53735682 Loss: 1.4791189931738828\n",
      "Epoch: 0 Sample: 19050000 / 53735682 Loss: 1.5832408499212032\n",
      "Epoch: 0 Sample: 19060000 / 53735682 Loss: 1.5184877369499847\n",
      "Epoch: 0 Sample: 19070000 / 53735682 Loss: 1.4967659816930343\n",
      "Epoch: 0 Sample: 19080000 / 53735682 Loss: 1.5406003525303211\n",
      "Epoch: 0 Sample: 19090000 / 53735682 Loss: 1.4675471086342178\n",
      "Epoch: 0 Sample: 19100000 / 53735682 Loss: 1.5304848510612894\n",
      "Epoch: 0 Sample: 19110000 / 53735682 Loss: 1.430398744383452\n",
      "Epoch: 0 Sample: 19120000 / 53735682 Loss: 1.4427587944826956\n",
      "Epoch: 0 Sample: 19130000 / 53735682 Loss: 1.5414890664215362\n",
      "Epoch: 0 Sample: 19140000 / 53735682 Loss: 1.5084595720890643\n",
      "Epoch: 0 Sample: 19150000 / 53735682 Loss: 1.573262465394194\n",
      "Epoch: 0 Sample: 19160000 / 53735682 Loss: 1.5122014312611778\n",
      "Epoch: 0 Sample: 19170000 / 53735682 Loss: 1.5045343605539845\n",
      "Epoch: 0 Sample: 19180000 / 53735682 Loss: 1.5024318373305874\n",
      "Epoch: 0 Sample: 19190000 / 53735682 Loss: 1.5484830993472805\n",
      "Epoch: 0 Sample: 19200000 / 53735682 Loss: 1.4428030320411782\n",
      "Epoch: 0 Sample: 19210000 / 53735682 Loss: 1.5021482258286774\n",
      "Epoch: 0 Sample: 19220000 / 53735682 Loss: 1.4888447493145966\n",
      "Epoch: 0 Sample: 19230000 / 53735682 Loss: 1.4409205816842694\n",
      "Epoch: 0 Sample: 19240000 / 53735682 Loss: 1.4772558828996838\n",
      "Epoch: 0 Sample: 19250000 / 53735682 Loss: 1.4156384372065456\n",
      "Epoch: 0 Sample: 19260000 / 53735682 Loss: 1.5301204818989302\n",
      "Epoch: 0 Sample: 19270000 / 53735682 Loss: 1.4772017850449695\n",
      "Epoch: 0 Sample: 19280000 / 53735682 Loss: 1.5049370020240556\n",
      "Epoch: 0 Sample: 19290000 / 53735682 Loss: 1.5250528060971686\n",
      "Epoch: 0 Sample: 19300000 / 53735682 Loss: 1.5477633747812005\n",
      "Epoch: 0 Sample: 19310000 / 53735682 Loss: 1.5073364002898515\n",
      "Epoch: 0 Sample: 19320000 / 53735682 Loss: 1.544495907611759\n",
      "Epoch: 0 Sample: 19330000 / 53735682 Loss: 1.4944016073877964\n",
      "Epoch: 0 Sample: 19340000 / 53735682 Loss: 1.4369828768107464\n",
      "Epoch: 0 Sample: 19350000 / 53735682 Loss: 1.4931692018602702\n",
      "Epoch: 0 Sample: 19360000 / 53735682 Loss: 1.500103475003863\n",
      "Epoch: 0 Sample: 19370000 / 53735682 Loss: 1.607382674919449\n",
      "Epoch: 0 Sample: 19380000 / 53735682 Loss: 1.4160916801868644\n",
      "Epoch: 0 Sample: 19390000 / 53735682 Loss: 1.6210058399692917\n",
      "Epoch: 0 Sample: 19400000 / 53735682 Loss: 1.5636972930013808\n",
      "Epoch: 0 Sample: 19410000 / 53735682 Loss: 1.4608643894619877\n",
      "Epoch: 0 Sample: 19420000 / 53735682 Loss: 1.4950907320217581\n",
      "Epoch: 0 Sample: 19430000 / 53735682 Loss: 1.5177710162181146\n",
      "Epoch: 0 Sample: 19440000 / 53735682 Loss: 1.458079624182902\n",
      "Epoch: 0 Sample: 19450000 / 53735682 Loss: 1.545829074539607\n",
      "Epoch: 0 Sample: 19460000 / 53735682 Loss: 1.5736683199982644\n",
      "Epoch: 0 Sample: 19470000 / 53735682 Loss: 1.4870953054063425\n",
      "Epoch: 0 Sample: 19480000 / 53735682 Loss: 1.4554065947714483\n",
      "Epoch: 0 Sample: 19490000 / 53735682 Loss: 1.4615101611505796\n",
      "Epoch: 0 Sample: 19500000 / 53735682 Loss: 1.4907190668334844\n",
      "Epoch: 0 Sample: 19510000 / 53735682 Loss: 1.4936293119876067\n",
      "Epoch: 0 Sample: 19520000 / 53735682 Loss: 1.4356655142581531\n",
      "Epoch: 0 Sample: 19530000 / 53735682 Loss: 1.4891997838679218\n",
      "Epoch: 0 Sample: 19540000 / 53735682 Loss: 1.5626269416556546\n",
      "Epoch: 0 Sample: 19550000 / 53735682 Loss: 1.564664904354683\n",
      "Epoch: 0 Sample: 19560000 / 53735682 Loss: 1.4492475556596496\n",
      "Epoch: 0 Sample: 19570000 / 53735682 Loss: 1.544968201040794\n",
      "Epoch: 0 Sample: 19580000 / 53735682 Loss: 1.5617447471209844\n",
      "Epoch: 0 Sample: 19590000 / 53735682 Loss: 1.4873938604525216\n",
      "Epoch: 0 Sample: 19600000 / 53735682 Loss: 1.5857259028909365\n",
      "Epoch: 0 Sample: 19610000 / 53735682 Loss: 1.485676163537574\n",
      "Epoch: 0 Sample: 19620000 / 53735682 Loss: 1.5550514637573332\n",
      "Epoch: 0 Sample: 19630000 / 53735682 Loss: 1.4805242270087826\n",
      "Epoch: 0 Sample: 19640000 / 53735682 Loss: 1.4583366814677834\n",
      "Epoch: 0 Sample: 19650000 / 53735682 Loss: 1.472323191570945\n",
      "Epoch: 0 Sample: 19660000 / 53735682 Loss: 1.4564302959437243\n",
      "Epoch: 0 Sample: 19670000 / 53735682 Loss: 1.4539613682426502\n",
      "Epoch: 0 Sample: 19680000 / 53735682 Loss: 1.5189232925058713\n",
      "Epoch: 0 Sample: 19690000 / 53735682 Loss: 1.5074273170795345\n",
      "Epoch: 0 Sample: 19700000 / 53735682 Loss: 1.5185624900984074\n",
      "Epoch: 0 Sample: 19710000 / 53735682 Loss: 1.388903588666367\n",
      "Epoch: 0 Sample: 19720000 / 53735682 Loss: 1.4491438350045034\n",
      "Epoch: 0 Sample: 19730000 / 53735682 Loss: 1.494243552566667\n",
      "Epoch: 0 Sample: 19740000 / 53735682 Loss: 1.5317074302856422\n",
      "Epoch: 0 Sample: 19750000 / 53735682 Loss: 1.5468770818997553\n",
      "Epoch: 0 Sample: 19760000 / 53735682 Loss: 1.477002695037072\n",
      "Epoch: 0 Sample: 19770000 / 53735682 Loss: 1.5588996338222219\n",
      "Epoch: 0 Sample: 19780000 / 53735682 Loss: 1.4943757045724588\n",
      "Epoch: 0 Sample: 19790000 / 53735682 Loss: 1.509573786519133\n",
      "Epoch: 0 Sample: 19800000 / 53735682 Loss: 1.4794938869362992\n",
      "Epoch: 0 Sample: 19810000 / 53735682 Loss: 1.4908738280813694\n",
      "Epoch: 0 Sample: 19820000 / 53735682 Loss: 1.5139811249928585\n",
      "Epoch: 0 Sample: 19830000 / 53735682 Loss: 1.4967637178173567\n",
      "Epoch: 0 Sample: 19840000 / 53735682 Loss: 1.5242602030363273\n",
      "Epoch: 0 Sample: 19850000 / 53735682 Loss: 1.4369230668522743\n",
      "Epoch: 0 Sample: 19860000 / 53735682 Loss: 1.6007927623119784\n",
      "Epoch: 0 Sample: 19870000 / 53735682 Loss: 1.4367110602832152\n",
      "Epoch: 0 Sample: 19880000 / 53735682 Loss: 1.6188024213359915\n",
      "Epoch: 0 Sample: 19890000 / 53735682 Loss: 1.5013625841739335\n",
      "Epoch: 0 Sample: 19900000 / 53735682 Loss: 1.4806644299270006\n",
      "Epoch: 0 Sample: 19910000 / 53735682 Loss: 1.4419816907362637\n",
      "Epoch: 0 Sample: 19920000 / 53735682 Loss: 1.56966499017207\n",
      "Epoch: 0 Sample: 19930000 / 53735682 Loss: 1.4776369986348192\n",
      "Epoch: 0 Sample: 19940000 / 53735682 Loss: 1.4705768075753978\n",
      "Epoch: 0 Sample: 19950000 / 53735682 Loss: 1.4170979677076454\n",
      "Epoch: 0 Sample: 19960000 / 53735682 Loss: 1.4890147519458052\n",
      "Epoch: 0 Sample: 19970000 / 53735682 Loss: 1.6114142923844876\n",
      "Epoch: 0 Sample: 19980000 / 53735682 Loss: 1.5203354290865336\n",
      "Epoch: 0 Sample: 19990000 / 53735682 Loss: 1.4555811096763867\n",
      "Epoch: 0 Sample: 20000000 / 53735682 Loss: 1.3941077611682247\n",
      "Epoch: 0 Sample: 20010000 / 53735682 Loss: 1.5013470660928971\n",
      "Epoch: 0 Sample: 20020000 / 53735682 Loss: 1.4836463126787178\n",
      "Epoch: 0 Sample: 20030000 / 53735682 Loss: 1.5235622916046647\n",
      "Epoch: 0 Sample: 20040000 / 53735682 Loss: 1.4795125158444797\n",
      "Epoch: 0 Sample: 20050000 / 53735682 Loss: 1.476707022959609\n",
      "Epoch: 0 Sample: 20060000 / 53735682 Loss: 1.5012867937209222\n",
      "Epoch: 0 Sample: 20070000 / 53735682 Loss: 1.5114936791787765\n",
      "Epoch: 0 Sample: 20080000 / 53735682 Loss: 1.5036246170651746\n",
      "Epoch: 0 Sample: 20090000 / 53735682 Loss: 1.4927104530738884\n",
      "Epoch: 0 Sample: 20100000 / 53735682 Loss: 1.4560214510951506\n",
      "Epoch: 0 Sample: 20110000 / 53735682 Loss: 1.4260617988694526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 20120000 / 53735682 Loss: 1.5704120649260873\n",
      "Epoch: 0 Sample: 20130000 / 53735682 Loss: 1.5116191035388975\n",
      "Epoch: 0 Sample: 20140000 / 53735682 Loss: 1.572084663153262\n",
      "Epoch: 0 Sample: 20150000 / 53735682 Loss: 1.5485388200645989\n",
      "Epoch: 0 Sample: 20160000 / 53735682 Loss: 1.5803814379684276\n",
      "Epoch: 0 Sample: 20170000 / 53735682 Loss: 1.4532110084388177\n",
      "Epoch: 0 Sample: 20180000 / 53735682 Loss: 1.5479330090954162\n",
      "Epoch: 0 Sample: 20190000 / 53735682 Loss: 1.5128612350846475\n",
      "Epoch: 0 Sample: 20200000 / 53735682 Loss: 1.4873034414225277\n",
      "Epoch: 0 Sample: 20210000 / 53735682 Loss: 1.5582937037590332\n",
      "Epoch: 0 Sample: 20220000 / 53735682 Loss: 1.5087775701834425\n",
      "Epoch: 0 Sample: 20230000 / 53735682 Loss: 1.4969493173907567\n",
      "Epoch: 0 Sample: 20240000 / 53735682 Loss: 1.4133966119093004\n",
      "Epoch: 0 Sample: 20250000 / 53735682 Loss: 1.4799451463432818\n",
      "Epoch: 0 Sample: 20260000 / 53735682 Loss: 1.3778679417767037\n",
      "Epoch: 0 Sample: 20270000 / 53735682 Loss: 1.515877542384588\n",
      "Epoch: 0 Sample: 20280000 / 53735682 Loss: 1.476112108735895\n",
      "Epoch: 0 Sample: 20290000 / 53735682 Loss: 1.4833625976232347\n",
      "Epoch: 0 Sample: 20300000 / 53735682 Loss: 1.5047154618912808\n",
      "Epoch: 0 Sample: 20310000 / 53735682 Loss: 1.545312853362848\n",
      "Epoch: 0 Sample: 20320000 / 53735682 Loss: 1.492640873933158\n",
      "Epoch: 0 Sample: 20330000 / 53735682 Loss: 1.526409800202507\n",
      "Epoch: 0 Sample: 20340000 / 53735682 Loss: 1.470601870420281\n",
      "Epoch: 0 Sample: 20350000 / 53735682 Loss: 1.5107454152056157\n",
      "Epoch: 0 Sample: 20360000 / 53735682 Loss: 1.461624881206874\n",
      "Epoch: 0 Sample: 20370000 / 53735682 Loss: 1.527846824173172\n",
      "Epoch: 0 Sample: 20380000 / 53735682 Loss: 1.449844534112953\n",
      "Epoch: 0 Sample: 20390000 / 53735682 Loss: 1.5781683163907303\n",
      "Epoch: 0 Sample: 20400000 / 53735682 Loss: 1.4372402457007682\n",
      "Epoch: 0 Sample: 20410000 / 53735682 Loss: 1.4842335960440356\n",
      "Epoch: 0 Sample: 20420000 / 53735682 Loss: 1.4684815643894635\n",
      "Epoch: 0 Sample: 20430000 / 53735682 Loss: 1.5346693414984973\n",
      "Epoch: 0 Sample: 20440000 / 53735682 Loss: 1.490264717169469\n",
      "Epoch: 0 Sample: 20450000 / 53735682 Loss: 1.5008112111307221\n",
      "Epoch: 0 Sample: 20460000 / 53735682 Loss: 1.473387466425491\n",
      "Epoch: 0 Sample: 20470000 / 53735682 Loss: 1.481641551569711\n",
      "Epoch: 0 Sample: 20480000 / 53735682 Loss: 1.478043264609537\n",
      "Epoch: 0 Sample: 20490000 / 53735682 Loss: 1.4693127201820284\n",
      "Epoch: 0 Sample: 20500000 / 53735682 Loss: 1.5079369110831293\n",
      "Epoch: 0 Sample: 20510000 / 53735682 Loss: 1.528560334900349\n",
      "Epoch: 0 Sample: 20520000 / 53735682 Loss: 1.4807884161197813\n",
      "Epoch: 0 Sample: 20530000 / 53735682 Loss: 1.4908967961266109\n",
      "Epoch: 0 Sample: 20540000 / 53735682 Loss: 1.5042626218371171\n",
      "Epoch: 0 Sample: 20550000 / 53735682 Loss: 1.5642039550824154\n",
      "Epoch: 0 Sample: 20560000 / 53735682 Loss: 1.5360529907358824\n",
      "Epoch: 0 Sample: 20570000 / 53735682 Loss: 1.4456110717156878\n",
      "Epoch: 0 Sample: 20580000 / 53735682 Loss: 1.5595783857237935\n",
      "Epoch: 0 Sample: 20590000 / 53735682 Loss: 1.4627201270971264\n",
      "Epoch: 0 Sample: 20600000 / 53735682 Loss: 1.5431204081358123\n",
      "Epoch: 0 Sample: 20610000 / 53735682 Loss: 1.4501640938439317\n",
      "Epoch: 0 Sample: 20620000 / 53735682 Loss: 1.4848916994155967\n",
      "Epoch: 0 Sample: 20630000 / 53735682 Loss: 1.5570611217792054\n",
      "Epoch: 0 Sample: 20640000 / 53735682 Loss: 1.5127611874738063\n",
      "Epoch: 0 Sample: 20650000 / 53735682 Loss: 1.5258396368539953\n",
      "Epoch: 0 Sample: 20660000 / 53735682 Loss: 1.57272071326756\n",
      "Epoch: 0 Sample: 20670000 / 53735682 Loss: 1.5256438047919625\n",
      "Epoch: 0 Sample: 20680000 / 53735682 Loss: 1.6150158608659833\n",
      "Epoch: 0 Sample: 20690000 / 53735682 Loss: 1.5922569359338745\n",
      "Epoch: 0 Sample: 20700000 / 53735682 Loss: 1.45274722859011\n",
      "Epoch: 0 Sample: 20710000 / 53735682 Loss: 1.5335191013820004\n",
      "Epoch: 0 Sample: 20720000 / 53735682 Loss: 1.42538297496364\n",
      "Epoch: 0 Sample: 20730000 / 53735682 Loss: 1.4558214095680668\n",
      "Epoch: 0 Sample: 20740000 / 53735682 Loss: 1.4890606486949851\n",
      "Epoch: 0 Sample: 20750000 / 53735682 Loss: 1.44297732302991\n",
      "Epoch: 0 Sample: 20760000 / 53735682 Loss: 1.4705971459894829\n",
      "Epoch: 0 Sample: 20770000 / 53735682 Loss: 1.5248449103332797\n",
      "Epoch: 0 Sample: 20780000 / 53735682 Loss: 1.499341860886969\n",
      "Epoch: 0 Sample: 20790000 / 53735682 Loss: 1.5820929323609774\n",
      "Epoch: 0 Sample: 20800000 / 53735682 Loss: 1.418259051802748\n",
      "Epoch: 0 Sample: 20810000 / 53735682 Loss: 1.5253435653905116\n",
      "Epoch: 0 Sample: 20820000 / 53735682 Loss: 1.3798197239057368\n",
      "Epoch: 0 Sample: 20830000 / 53735682 Loss: 1.5099749829386866\n",
      "Epoch: 0 Sample: 20840000 / 53735682 Loss: 1.4481065473477557\n",
      "Epoch: 0 Sample: 20850000 / 53735682 Loss: 1.4653186883323528\n",
      "Epoch: 0 Sample: 20860000 / 53735682 Loss: 1.498367634409163\n",
      "Epoch: 0 Sample: 20870000 / 53735682 Loss: 1.4215659771094669\n",
      "Epoch: 0 Sample: 20880000 / 53735682 Loss: 1.5264937751338397\n",
      "Epoch: 0 Sample: 20890000 / 53735682 Loss: 1.466116415881228\n",
      "Epoch: 0 Sample: 20900000 / 53735682 Loss: 1.499710724709969\n",
      "Epoch: 0 Sample: 20910000 / 53735682 Loss: 1.4703651222322445\n",
      "Epoch: 0 Sample: 20920000 / 53735682 Loss: 1.4648475392126161\n",
      "Epoch: 0 Sample: 20930000 / 53735682 Loss: 1.4623901927662584\n",
      "Epoch: 0 Sample: 20940000 / 53735682 Loss: 1.4928068617324597\n",
      "Epoch: 0 Sample: 20950000 / 53735682 Loss: 1.5133104413301584\n",
      "Epoch: 0 Sample: 20960000 / 53735682 Loss: 1.5457879446057712\n",
      "Epoch: 0 Sample: 20970000 / 53735682 Loss: 1.4983192950510875\n",
      "Epoch: 0 Sample: 20980000 / 53735682 Loss: 1.4394143224744687\n",
      "Epoch: 0 Sample: 20990000 / 53735682 Loss: 1.5229602208143704\n",
      "Epoch: 0 Sample: 21000000 / 53735682 Loss: 1.5188199666052205\n",
      "Epoch: 0 Sample: 21010000 / 53735682 Loss: 1.4926147098005005\n",
      "Epoch: 0 Sample: 21020000 / 53735682 Loss: 1.5149883653439982\n",
      "Epoch: 0 Sample: 21030000 / 53735682 Loss: 1.544922754593872\n",
      "Epoch: 0 Sample: 21040000 / 53735682 Loss: 1.4646928492926001\n",
      "Epoch: 0 Sample: 21050000 / 53735682 Loss: 1.5118894966626426\n",
      "Epoch: 0 Sample: 21060000 / 53735682 Loss: 1.5032452354014154\n",
      "Epoch: 0 Sample: 21070000 / 53735682 Loss: 1.453032649584033\n",
      "Epoch: 0 Sample: 21080000 / 53735682 Loss: 1.48608861992949\n",
      "Epoch: 0 Sample: 21090000 / 53735682 Loss: 1.5323278679321688\n",
      "Epoch: 0 Sample: 21100000 / 53735682 Loss: 1.5584921646583307\n",
      "Epoch: 0 Sample: 21110000 / 53735682 Loss: 1.4931632060081297\n",
      "Epoch: 0 Sample: 21120000 / 53735682 Loss: 1.5445855832302668\n",
      "Epoch: 0 Sample: 21130000 / 53735682 Loss: 1.4915840884608453\n",
      "Epoch: 0 Sample: 21140000 / 53735682 Loss: 1.4734900929049974\n",
      "Epoch: 0 Sample: 21150000 / 53735682 Loss: 1.540462138281066\n",
      "Epoch: 0 Sample: 21160000 / 53735682 Loss: 1.552365380854333\n",
      "Epoch: 0 Sample: 21170000 / 53735682 Loss: 1.4424102501685994\n",
      "Epoch: 0 Sample: 21180000 / 53735682 Loss: 1.5548828040831781\n",
      "Epoch: 0 Sample: 21190000 / 53735682 Loss: 1.4798354139756023\n",
      "Epoch: 0 Sample: 21200000 / 53735682 Loss: 1.4359615654737818\n",
      "Epoch: 0 Sample: 21210000 / 53735682 Loss: 1.450417202593525\n",
      "Epoch: 0 Sample: 21220000 / 53735682 Loss: 1.4879175583029327\n",
      "Epoch: 0 Sample: 21230000 / 53735682 Loss: 1.4643058830795153\n",
      "Epoch: 0 Sample: 21240000 / 53735682 Loss: 1.3944489125247967\n",
      "Epoch: 0 Sample: 21250000 / 53735682 Loss: 1.5022433590576876\n",
      "Epoch: 0 Sample: 21260000 / 53735682 Loss: 1.4974968932545916\n",
      "Epoch: 0 Sample: 21270000 / 53735682 Loss: 1.5203193981192382\n",
      "Epoch: 0 Sample: 21280000 / 53735682 Loss: 1.5100616226338326\n",
      "Epoch: 0 Sample: 21290000 / 53735682 Loss: 1.5314920575160749\n",
      "Epoch: 0 Sample: 21300000 / 53735682 Loss: 1.4555869276496463\n",
      "Epoch: 0 Sample: 21310000 / 53735682 Loss: 1.5076151927278487\n",
      "Epoch: 0 Sample: 21320000 / 53735682 Loss: 1.53561261261452\n",
      "Epoch: 0 Sample: 21330000 / 53735682 Loss: 1.4905687196203565\n",
      "Epoch: 0 Sample: 21340000 / 53735682 Loss: 1.5201853274434145\n",
      "Epoch: 0 Sample: 21350000 / 53735682 Loss: 1.4844087553612888\n",
      "Epoch: 0 Sample: 21360000 / 53735682 Loss: 1.4909915540220608\n",
      "Epoch: 0 Sample: 21370000 / 53735682 Loss: 1.5080703658330088\n",
      "Epoch: 0 Sample: 21380000 / 53735682 Loss: 1.5278759993853743\n",
      "Epoch: 0 Sample: 21390000 / 53735682 Loss: 1.4612536796513658\n",
      "Epoch: 0 Sample: 21400000 / 53735682 Loss: 1.5375609317220724\n",
      "Epoch: 0 Sample: 21410000 / 53735682 Loss: 1.4983711490670197\n",
      "Epoch: 0 Sample: 21420000 / 53735682 Loss: 1.4534815068123415\n",
      "Epoch: 0 Sample: 21430000 / 53735682 Loss: 1.6017803421009318\n",
      "Epoch: 0 Sample: 21440000 / 53735682 Loss: 1.5426915122128544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 21450000 / 53735682 Loss: 1.5770680038107978\n",
      "Epoch: 0 Sample: 21460000 / 53735682 Loss: 1.5299173847225211\n",
      "Epoch: 0 Sample: 21470000 / 53735682 Loss: 1.5113385405573112\n",
      "Epoch: 0 Sample: 21480000 / 53735682 Loss: 1.455893194532588\n",
      "Epoch: 0 Sample: 21490000 / 53735682 Loss: 1.5295523912232616\n",
      "Epoch: 0 Sample: 21500000 / 53735682 Loss: 1.4912301024642467\n",
      "Epoch: 0 Sample: 21510000 / 53735682 Loss: 1.5125726554153345\n",
      "Epoch: 0 Sample: 21520000 / 53735682 Loss: 1.55372854879243\n",
      "Epoch: 0 Sample: 21530000 / 53735682 Loss: 1.5927633377919703\n",
      "Epoch: 0 Sample: 21540000 / 53735682 Loss: 1.4524856770249435\n",
      "Epoch: 0 Sample: 21550000 / 53735682 Loss: 1.5261120563948485\n",
      "Epoch: 0 Sample: 21560000 / 53735682 Loss: 1.4927946182318497\n",
      "Epoch: 0 Sample: 21570000 / 53735682 Loss: 1.5112276655298431\n",
      "Epoch: 0 Sample: 21580000 / 53735682 Loss: 1.569315239580747\n",
      "Epoch: 0 Sample: 21590000 / 53735682 Loss: 1.5014416626598446\n",
      "Epoch: 0 Sample: 21600000 / 53735682 Loss: 1.4410674702892805\n",
      "Epoch: 0 Sample: 21610000 / 53735682 Loss: 1.4683627162655988\n",
      "Epoch: 0 Sample: 21620000 / 53735682 Loss: 1.537637407509036\n",
      "Epoch: 0 Sample: 21630000 / 53735682 Loss: 1.452079765456377\n",
      "Epoch: 0 Sample: 21640000 / 53735682 Loss: 1.4270255725462668\n",
      "Epoch: 0 Sample: 21650000 / 53735682 Loss: 1.4816152774573497\n",
      "Epoch: 0 Sample: 21660000 / 53735682 Loss: 1.5467858871449665\n",
      "Epoch: 0 Sample: 21670000 / 53735682 Loss: 1.5067096913748341\n",
      "Epoch: 0 Sample: 21680000 / 53735682 Loss: 1.4867373227123335\n",
      "Epoch: 0 Sample: 21690000 / 53735682 Loss: 1.5065388834175222\n",
      "Epoch: 0 Sample: 21700000 / 53735682 Loss: 1.5027312641890411\n",
      "Epoch: 0 Sample: 21710000 / 53735682 Loss: 1.4506244398320813\n",
      "Epoch: 0 Sample: 21720000 / 53735682 Loss: 1.4812144980447481\n",
      "Epoch: 0 Sample: 21730000 / 53735682 Loss: 1.6362314170112082\n",
      "Epoch: 0 Sample: 21740000 / 53735682 Loss: 1.420598452870863\n",
      "Epoch: 0 Sample: 21750000 / 53735682 Loss: 1.5606476817601291\n",
      "Epoch: 0 Sample: 21760000 / 53735682 Loss: 1.5360101812692457\n",
      "Epoch: 0 Sample: 21770000 / 53735682 Loss: 1.5154982409330906\n",
      "Epoch: 0 Sample: 21780000 / 53735682 Loss: 1.4842724025310248\n",
      "Epoch: 0 Sample: 21790000 / 53735682 Loss: 1.4473892799495487\n",
      "Epoch: 0 Sample: 21800000 / 53735682 Loss: 1.519429911388094\n",
      "Epoch: 0 Sample: 21810000 / 53735682 Loss: 1.435145777167365\n",
      "Epoch: 0 Sample: 21820000 / 53735682 Loss: 1.5767232849874513\n",
      "Epoch: 0 Sample: 21830000 / 53735682 Loss: 1.4518962808571287\n",
      "Epoch: 0 Sample: 21840000 / 53735682 Loss: 1.5243174179129022\n",
      "Epoch: 0 Sample: 21850000 / 53735682 Loss: 1.539715952362437\n",
      "Epoch: 0 Sample: 21860000 / 53735682 Loss: 1.5184670193954304\n",
      "Epoch: 0 Sample: 21870000 / 53735682 Loss: 1.5187492505201556\n",
      "Epoch: 0 Sample: 21880000 / 53735682 Loss: 1.574925940180149\n",
      "Epoch: 0 Sample: 21890000 / 53735682 Loss: 1.5029686025453057\n",
      "Epoch: 0 Sample: 21900000 / 53735682 Loss: 1.4796376119140497\n",
      "Epoch: 0 Sample: 21910000 / 53735682 Loss: 1.4611235488092065\n",
      "Epoch: 0 Sample: 21920000 / 53735682 Loss: 1.518956152576516\n",
      "Epoch: 0 Sample: 21930000 / 53735682 Loss: 1.4520785053853023\n",
      "Epoch: 0 Sample: 21940000 / 53735682 Loss: 1.5025591248600862\n",
      "Epoch: 0 Sample: 21950000 / 53735682 Loss: 1.4894198073865055\n",
      "Epoch: 0 Sample: 21960000 / 53735682 Loss: 1.5654222652933936\n",
      "Epoch: 0 Sample: 21970000 / 53735682 Loss: 1.4323634913663166\n",
      "Epoch: 0 Sample: 21980000 / 53735682 Loss: 1.534132632796517\n",
      "Epoch: 0 Sample: 21990000 / 53735682 Loss: 1.6011698481370524\n",
      "Epoch: 0 Sample: 22000000 / 53735682 Loss: 1.4670684134058787\n",
      "Epoch: 0 Sample: 22010000 / 53735682 Loss: 1.4563132171872875\n",
      "Epoch: 0 Sample: 22020000 / 53735682 Loss: 1.49994389916777\n",
      "Epoch: 0 Sample: 22030000 / 53735682 Loss: 1.54812527856033\n",
      "Epoch: 0 Sample: 22040000 / 53735682 Loss: 1.413353816229907\n",
      "Epoch: 0 Sample: 22050000 / 53735682 Loss: 1.4158562309628278\n",
      "Epoch: 0 Sample: 22060000 / 53735682 Loss: 1.5250778785314678\n",
      "Epoch: 0 Sample: 22070000 / 53735682 Loss: 1.4233767190483912\n",
      "Epoch: 0 Sample: 22080000 / 53735682 Loss: 1.473332968251772\n",
      "Epoch: 0 Sample: 22090000 / 53735682 Loss: 1.4552764990235307\n",
      "Epoch: 0 Sample: 22100000 / 53735682 Loss: 1.501870294904026\n",
      "Epoch: 0 Sample: 22110000 / 53735682 Loss: 1.5369656725438434\n",
      "Epoch: 0 Sample: 22120000 / 53735682 Loss: 1.5098161311882219\n",
      "Epoch: 0 Sample: 22130000 / 53735682 Loss: 1.4877674349328878\n",
      "Epoch: 0 Sample: 22140000 / 53735682 Loss: 1.5217878452433964\n",
      "Epoch: 0 Sample: 22150000 / 53735682 Loss: 1.5231728109263072\n",
      "Epoch: 0 Sample: 22160000 / 53735682 Loss: 1.5202376886660165\n",
      "Epoch: 0 Sample: 22170000 / 53735682 Loss: 1.4753807850079057\n",
      "Epoch: 0 Sample: 22180000 / 53735682 Loss: 1.4660570382917446\n",
      "Epoch: 0 Sample: 22190000 / 53735682 Loss: 1.4527687089117873\n",
      "Epoch: 0 Sample: 22200000 / 53735682 Loss: 1.4816504899342435\n",
      "Epoch: 0 Sample: 22210000 / 53735682 Loss: 1.6282409812109966\n",
      "Epoch: 0 Sample: 22220000 / 53735682 Loss: 1.579725356207281\n",
      "Epoch: 0 Sample: 22230000 / 53735682 Loss: 1.5331406679911548\n",
      "Epoch: 0 Sample: 22240000 / 53735682 Loss: 1.4998781089254356\n",
      "Epoch: 0 Sample: 22250000 / 53735682 Loss: 1.4725571031605522\n",
      "Epoch: 0 Sample: 22260000 / 53735682 Loss: 1.5566053257334764\n",
      "Epoch: 0 Sample: 22270000 / 53735682 Loss: 1.5385272357307083\n",
      "Epoch: 0 Sample: 22280000 / 53735682 Loss: 1.3873080922981749\n",
      "Epoch: 0 Sample: 22290000 / 53735682 Loss: 1.5687326407800908\n",
      "Epoch: 0 Sample: 22300000 / 53735682 Loss: 1.5718914537912214\n",
      "Epoch: 0 Sample: 22310000 / 53735682 Loss: 1.5427977213991086\n",
      "Epoch: 0 Sample: 22320000 / 53735682 Loss: 1.5754896482630785\n",
      "Epoch: 0 Sample: 22330000 / 53735682 Loss: 1.497625547827152\n",
      "Epoch: 0 Sample: 22340000 / 53735682 Loss: 1.5399906707622213\n",
      "Epoch: 0 Sample: 22350000 / 53735682 Loss: 1.4869610992598048\n",
      "Epoch: 0 Sample: 22360000 / 53735682 Loss: 1.5384390415190072\n",
      "Epoch: 0 Sample: 22370000 / 53735682 Loss: 1.5329788333339258\n",
      "Epoch: 0 Sample: 22380000 / 53735682 Loss: 1.4858569474326289\n",
      "Epoch: 0 Sample: 22390000 / 53735682 Loss: 1.5284824726734474\n",
      "Epoch: 0 Sample: 22400000 / 53735682 Loss: 1.510710709790608\n",
      "Epoch: 0 Sample: 22410000 / 53735682 Loss: 1.5652926446057762\n",
      "Epoch: 0 Sample: 22420000 / 53735682 Loss: 1.4569152688965858\n",
      "Epoch: 0 Sample: 22430000 / 53735682 Loss: 1.5461849468699442\n",
      "Epoch: 0 Sample: 22440000 / 53735682 Loss: 1.533777911482285\n",
      "Epoch: 0 Sample: 22450000 / 53735682 Loss: 1.5565096061045136\n",
      "Epoch: 0 Sample: 22460000 / 53735682 Loss: 1.4820099093957522\n",
      "Epoch: 0 Sample: 22470000 / 53735682 Loss: 1.5113374702087379\n",
      "Epoch: 0 Sample: 22480000 / 53735682 Loss: 1.5525466722540802\n",
      "Epoch: 0 Sample: 22490000 / 53735682 Loss: 1.5539007331350412\n",
      "Epoch: 0 Sample: 22500000 / 53735682 Loss: 1.4157949040249918\n",
      "Epoch: 0 Sample: 22510000 / 53735682 Loss: 1.5000668780329443\n",
      "Epoch: 0 Sample: 22520000 / 53735682 Loss: 1.4662957362290685\n",
      "Epoch: 0 Sample: 22530000 / 53735682 Loss: 1.5260607224376352\n",
      "Epoch: 0 Sample: 22540000 / 53735682 Loss: 1.4601725028808707\n",
      "Epoch: 0 Sample: 22550000 / 53735682 Loss: 1.4688190490406425\n",
      "Epoch: 0 Sample: 22560000 / 53735682 Loss: 1.515641237232035\n",
      "Epoch: 0 Sample: 22570000 / 53735682 Loss: 1.4613530103096501\n",
      "Epoch: 0 Sample: 22580000 / 53735682 Loss: 1.4725849887968057\n",
      "Epoch: 0 Sample: 22590000 / 53735682 Loss: 1.5354638067535138\n",
      "Epoch: 0 Sample: 22600000 / 53735682 Loss: 1.5874898025741158\n",
      "Epoch: 0 Sample: 22610000 / 53735682 Loss: 1.543092714858295\n",
      "Epoch: 0 Sample: 22620000 / 53735682 Loss: 1.4556203270712003\n",
      "Epoch: 0 Sample: 22630000 / 53735682 Loss: 1.458616100299519\n",
      "Epoch: 0 Sample: 22640000 / 53735682 Loss: 1.5300366999898973\n",
      "Epoch: 0 Sample: 22650000 / 53735682 Loss: 1.3991604784952467\n",
      "Epoch: 0 Sample: 22660000 / 53735682 Loss: 1.514648459600752\n",
      "Epoch: 0 Sample: 22670000 / 53735682 Loss: 1.4608285087234756\n",
      "Epoch: 0 Sample: 22680000 / 53735682 Loss: 1.5382721863726523\n",
      "Epoch: 0 Sample: 22690000 / 53735682 Loss: 1.4827198665656138\n",
      "Epoch: 0 Sample: 22700000 / 53735682 Loss: 1.5103669875070733\n",
      "Epoch: 0 Sample: 22710000 / 53735682 Loss: 1.5528527182770633\n",
      "Epoch: 0 Sample: 22720000 / 53735682 Loss: 1.5191009492140135\n",
      "Epoch: 0 Sample: 22730000 / 53735682 Loss: 1.4702618575058315\n",
      "Epoch: 0 Sample: 22740000 / 53735682 Loss: 1.5369170002502082\n",
      "Epoch: 0 Sample: 22750000 / 53735682 Loss: 1.518504905386275\n",
      "Epoch: 0 Sample: 22760000 / 53735682 Loss: 1.4392089783757531\n",
      "Epoch: 0 Sample: 22770000 / 53735682 Loss: 1.5054491319232621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 22780000 / 53735682 Loss: 1.533702628498523\n",
      "Epoch: 0 Sample: 22790000 / 53735682 Loss: 1.533388650129055\n",
      "Epoch: 0 Sample: 22800000 / 53735682 Loss: 1.580610223304729\n",
      "Epoch: 0 Sample: 22810000 / 53735682 Loss: 1.5767174714378398\n",
      "Epoch: 0 Sample: 22820000 / 53735682 Loss: 1.5373088617531914\n",
      "Epoch: 0 Sample: 22830000 / 53735682 Loss: 1.405730657462377\n",
      "Epoch: 0 Sample: 22840000 / 53735682 Loss: 1.4540484830993567\n",
      "Epoch: 0 Sample: 22850000 / 53735682 Loss: 1.4797434320792506\n",
      "Epoch: 0 Sample: 22860000 / 53735682 Loss: 1.560419125812119\n",
      "Epoch: 0 Sample: 22870000 / 53735682 Loss: 1.4767574788891267\n",
      "Epoch: 0 Sample: 22880000 / 53735682 Loss: 1.5670748065402567\n",
      "Epoch: 0 Sample: 22890000 / 53735682 Loss: 1.5008121458716865\n",
      "Epoch: 0 Sample: 22900000 / 53735682 Loss: 1.5593022511719858\n",
      "Epoch: 0 Sample: 22910000 / 53735682 Loss: 1.4695399343825761\n",
      "Epoch: 0 Sample: 22920000 / 53735682 Loss: 1.4985331181782628\n",
      "Epoch: 0 Sample: 22930000 / 53735682 Loss: 1.5390930256519582\n",
      "Epoch: 0 Sample: 22940000 / 53735682 Loss: 1.469721155839856\n",
      "Epoch: 0 Sample: 22950000 / 53735682 Loss: 1.512130359936706\n",
      "Epoch: 0 Sample: 22960000 / 53735682 Loss: 1.4369046405840895\n",
      "Epoch: 0 Sample: 22970000 / 53735682 Loss: 1.5502648423445282\n",
      "Epoch: 0 Sample: 22980000 / 53735682 Loss: 1.6292256108216134\n",
      "Epoch: 0 Sample: 22990000 / 53735682 Loss: 1.564466873686073\n",
      "Epoch: 0 Sample: 23000000 / 53735682 Loss: 1.4804225639905884\n",
      "Epoch: 0 Sample: 23010000 / 53735682 Loss: 1.4513161091019091\n",
      "Epoch: 0 Sample: 23020000 / 53735682 Loss: 1.512950758916885\n",
      "Epoch: 0 Sample: 23030000 / 53735682 Loss: 1.490688605836113\n",
      "Epoch: 0 Sample: 23040000 / 53735682 Loss: 1.5347752516682642\n",
      "Epoch: 0 Sample: 23050000 / 53735682 Loss: 1.4881344175470455\n",
      "Epoch: 0 Sample: 23060000 / 53735682 Loss: 1.4703013905437081\n",
      "Epoch: 0 Sample: 23070000 / 53735682 Loss: 1.5034983435008327\n",
      "Epoch: 0 Sample: 23080000 / 53735682 Loss: 1.46628001913276\n",
      "Epoch: 0 Sample: 23090000 / 53735682 Loss: 1.5173613374186512\n",
      "Epoch: 0 Sample: 23100000 / 53735682 Loss: 1.534441651668852\n",
      "Epoch: 0 Sample: 23110000 / 53735682 Loss: 1.5471074479886497\n",
      "Epoch: 0 Sample: 23120000 / 53735682 Loss: 1.4680175762136995\n",
      "Epoch: 0 Sample: 23130000 / 53735682 Loss: 1.459408839039367\n",
      "Epoch: 0 Sample: 23140000 / 53735682 Loss: 1.5366002379730452\n",
      "Epoch: 0 Sample: 23150000 / 53735682 Loss: 1.5481896288099184\n",
      "Epoch: 0 Sample: 23160000 / 53735682 Loss: 1.5901569657019767\n",
      "Epoch: 0 Sample: 23170000 / 53735682 Loss: 1.5139486693005875\n",
      "Epoch: 0 Sample: 23180000 / 53735682 Loss: 1.4965463413986522\n",
      "Epoch: 0 Sample: 23190000 / 53735682 Loss: 1.4708143370882993\n",
      "Epoch: 0 Sample: 23200000 / 53735682 Loss: 1.5243985094015273\n",
      "Epoch: 0 Sample: 23210000 / 53735682 Loss: 1.4853107230520772\n",
      "Epoch: 0 Sample: 23220000 / 53735682 Loss: 1.55570003985755\n",
      "Epoch: 0 Sample: 23230000 / 53735682 Loss: 1.516053403374919\n",
      "Epoch: 0 Sample: 23240000 / 53735682 Loss: 1.4798532434736356\n",
      "Epoch: 0 Sample: 23250000 / 53735682 Loss: 1.4143672320913692\n",
      "Epoch: 0 Sample: 23260000 / 53735682 Loss: 1.5520915352195144\n",
      "Epoch: 0 Sample: 23270000 / 53735682 Loss: 1.4605838688754975\n",
      "Epoch: 0 Sample: 23280000 / 53735682 Loss: 1.5694767226353934\n",
      "Epoch: 0 Sample: 23290000 / 53735682 Loss: 1.469226912278617\n",
      "Epoch: 0 Sample: 23300000 / 53735682 Loss: 1.483808027881106\n",
      "Epoch: 0 Sample: 23310000 / 53735682 Loss: 1.5060529264938418\n",
      "Epoch: 0 Sample: 23320000 / 53735682 Loss: 1.494959926440658\n",
      "Epoch: 0 Sample: 23330000 / 53735682 Loss: 1.541213035903331\n",
      "Epoch: 0 Sample: 23340000 / 53735682 Loss: 1.5105811549129222\n",
      "Epoch: 0 Sample: 23350000 / 53735682 Loss: 1.4777813569380869\n",
      "Epoch: 0 Sample: 23360000 / 53735682 Loss: 1.5331446588359197\n",
      "Epoch: 0 Sample: 23370000 / 53735682 Loss: 1.4952678862725621\n",
      "Epoch: 0 Sample: 23380000 / 53735682 Loss: 1.5018355987744474\n",
      "Epoch: 0 Sample: 23390000 / 53735682 Loss: 1.502194076395213\n",
      "Epoch: 0 Sample: 23400000 / 53735682 Loss: 1.517555391887767\n",
      "Epoch: 0 Sample: 23410000 / 53735682 Loss: 1.5283318994253838\n",
      "Epoch: 0 Sample: 23420000 / 53735682 Loss: 1.5494961474760376\n",
      "Epoch: 0 Sample: 23430000 / 53735682 Loss: 1.5353782525815225\n",
      "Epoch: 0 Sample: 23440000 / 53735682 Loss: 1.5039185847909677\n",
      "Epoch: 0 Sample: 23450000 / 53735682 Loss: 1.5804420768759946\n",
      "Epoch: 0 Sample: 23460000 / 53735682 Loss: 1.5782212472203003\n",
      "Epoch: 0 Sample: 23470000 / 53735682 Loss: 1.4866248438079235\n",
      "Epoch: 0 Sample: 23480000 / 53735682 Loss: 1.3971181276384201\n",
      "Epoch: 0 Sample: 23490000 / 53735682 Loss: 1.5266428447170206\n",
      "Epoch: 0 Sample: 23500000 / 53735682 Loss: 1.4956397950739613\n",
      "Epoch: 0 Sample: 23510000 / 53735682 Loss: 1.4637444502104586\n",
      "Epoch: 0 Sample: 23520000 / 53735682 Loss: 1.506789406172055\n",
      "Epoch: 0 Sample: 23530000 / 53735682 Loss: 1.4787455247081818\n",
      "Epoch: 0 Sample: 23540000 / 53735682 Loss: 1.512835625464476\n",
      "Epoch: 0 Sample: 23550000 / 53735682 Loss: 1.5454360173640012\n",
      "Epoch: 0 Sample: 23560000 / 53735682 Loss: 1.5910181760852058\n",
      "Epoch: 0 Sample: 23570000 / 53735682 Loss: 1.5279112770847976\n",
      "Epoch: 0 Sample: 23580000 / 53735682 Loss: 1.5848627622904305\n",
      "Epoch: 0 Sample: 23590000 / 53735682 Loss: 1.5511282604155128\n",
      "Epoch: 0 Sample: 23600000 / 53735682 Loss: 1.584380372397232\n",
      "Epoch: 0 Sample: 23610000 / 53735682 Loss: 1.4493216103203643\n",
      "Epoch: 0 Sample: 23620000 / 53735682 Loss: 1.431711048757525\n",
      "Epoch: 0 Sample: 23630000 / 53735682 Loss: 1.486329621217311\n",
      "Epoch: 0 Sample: 23640000 / 53735682 Loss: 1.4566236493850495\n",
      "Epoch: 0 Sample: 23650000 / 53735682 Loss: 1.465814152012617\n",
      "Epoch: 0 Sample: 23660000 / 53735682 Loss: 1.525545640556486\n",
      "Epoch: 0 Sample: 23670000 / 53735682 Loss: 1.4702879817724022\n",
      "Epoch: 0 Sample: 23680000 / 53735682 Loss: 1.5026318364925468\n",
      "Epoch: 0 Sample: 23690000 / 53735682 Loss: 1.4728123161371867\n",
      "Epoch: 0 Sample: 23700000 / 53735682 Loss: 1.4800536293577624\n",
      "Epoch: 0 Sample: 23710000 / 53735682 Loss: 1.5332221238913966\n",
      "Epoch: 0 Sample: 23720000 / 53735682 Loss: 1.5171976596916357\n",
      "Epoch: 0 Sample: 23730000 / 53735682 Loss: 1.4495655882610279\n",
      "Epoch: 0 Sample: 23740000 / 53735682 Loss: 1.4601213293964803\n",
      "Epoch: 0 Sample: 23750000 / 53735682 Loss: 1.595197150724161\n",
      "Epoch: 0 Sample: 23760000 / 53735682 Loss: 1.4557192695964685\n",
      "Epoch: 0 Sample: 23770000 / 53735682 Loss: 1.5086063840838273\n",
      "Epoch: 0 Sample: 23780000 / 53735682 Loss: 1.5030568407096874\n",
      "Epoch: 0 Sample: 23790000 / 53735682 Loss: 1.4987504730335206\n",
      "Epoch: 0 Sample: 23800000 / 53735682 Loss: 1.5665123276832187\n",
      "Epoch: 0 Sample: 23810000 / 53735682 Loss: 1.5481931934199853\n",
      "Epoch: 0 Sample: 23820000 / 53735682 Loss: 1.5440007578573445\n",
      "Epoch: 0 Sample: 23830000 / 53735682 Loss: 1.5101274498258856\n",
      "Epoch: 0 Sample: 23840000 / 53735682 Loss: 1.496707620634359\n",
      "Epoch: 0 Sample: 23850000 / 53735682 Loss: 1.5525596376109279\n",
      "Epoch: 0 Sample: 23860000 / 53735682 Loss: 1.4117584815555873\n",
      "Epoch: 0 Sample: 23870000 / 53735682 Loss: 1.535582181056463\n",
      "Epoch: 0 Sample: 23880000 / 53735682 Loss: 1.428659321939032\n",
      "Epoch: 0 Sample: 23890000 / 53735682 Loss: 1.4555281919127747\n",
      "Epoch: 0 Sample: 23900000 / 53735682 Loss: 1.5155060135168301\n",
      "Epoch: 0 Sample: 23910000 / 53735682 Loss: 1.4606766968750347\n",
      "Epoch: 0 Sample: 23920000 / 53735682 Loss: 1.5019080253279058\n",
      "Epoch: 0 Sample: 23930000 / 53735682 Loss: 1.4494271801895144\n",
      "Epoch: 0 Sample: 23940000 / 53735682 Loss: 1.4433222755473525\n",
      "Epoch: 0 Sample: 23950000 / 53735682 Loss: 1.4175246142085318\n",
      "Epoch: 0 Sample: 23960000 / 53735682 Loss: 1.5228421942497132\n",
      "Epoch: 0 Sample: 23970000 / 53735682 Loss: 1.4447132750393221\n",
      "Epoch: 0 Sample: 23980000 / 53735682 Loss: 1.3903291573613354\n",
      "Epoch: 0 Sample: 23990000 / 53735682 Loss: 1.5543885713733612\n",
      "Epoch: 0 Sample: 24000000 / 53735682 Loss: 1.4549571194389932\n",
      "Epoch: 0 Sample: 24010000 / 53735682 Loss: 1.4762731272977847\n",
      "Epoch: 0 Sample: 24020000 / 53735682 Loss: 1.4699573650664424\n",
      "Epoch: 0 Sample: 24030000 / 53735682 Loss: 1.4010991999442222\n",
      "Epoch: 0 Sample: 24040000 / 53735682 Loss: 1.5128100819675103\n",
      "Epoch: 0 Sample: 24050000 / 53735682 Loss: 1.467067344315139\n",
      "Epoch: 0 Sample: 24060000 / 53735682 Loss: 1.5350540992840602\n",
      "Epoch: 0 Sample: 24070000 / 53735682 Loss: 1.5464084908348124\n",
      "Epoch: 0 Sample: 24080000 / 53735682 Loss: 1.5186008130593849\n",
      "Epoch: 0 Sample: 24090000 / 53735682 Loss: 1.4626673101653778\n",
      "Epoch: 0 Sample: 24100000 / 53735682 Loss: 1.5238123929308143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 24110000 / 53735682 Loss: 1.348757018012536\n",
      "Epoch: 0 Sample: 24120000 / 53735682 Loss: 1.5990718356243494\n",
      "Epoch: 0 Sample: 24130000 / 53735682 Loss: 1.4914497087580751\n",
      "Epoch: 0 Sample: 24140000 / 53735682 Loss: 1.457602576648246\n",
      "Epoch: 0 Sample: 24150000 / 53735682 Loss: 1.5335479859143009\n",
      "Epoch: 0 Sample: 24160000 / 53735682 Loss: 1.4934207037738774\n",
      "Epoch: 0 Sample: 24170000 / 53735682 Loss: 1.4564337132977405\n",
      "Epoch: 0 Sample: 24180000 / 53735682 Loss: 1.5038490456280678\n",
      "Epoch: 0 Sample: 24190000 / 53735682 Loss: 1.4438353875039773\n",
      "Epoch: 0 Sample: 24200000 / 53735682 Loss: 1.5088199392951478\n",
      "Epoch: 0 Sample: 24210000 / 53735682 Loss: 1.556788933880129\n",
      "Epoch: 0 Sample: 24220000 / 53735682 Loss: 1.4424454287412063\n",
      "Epoch: 0 Sample: 24230000 / 53735682 Loss: 1.4275955180782391\n",
      "Epoch: 0 Sample: 24240000 / 53735682 Loss: 1.547655752863057\n",
      "Epoch: 0 Sample: 24250000 / 53735682 Loss: 1.4636754358416044\n",
      "Epoch: 0 Sample: 24260000 / 53735682 Loss: 1.5067821291752026\n",
      "Epoch: 0 Sample: 24270000 / 53735682 Loss: 1.4813665995096756\n",
      "Epoch: 0 Sample: 24280000 / 53735682 Loss: 1.4536419936975724\n",
      "Epoch: 0 Sample: 24290000 / 53735682 Loss: 1.4901416138871992\n",
      "Epoch: 0 Sample: 24300000 / 53735682 Loss: 1.3608413072734042\n",
      "Epoch: 0 Sample: 24310000 / 53735682 Loss: 1.5244007897564216\n",
      "Epoch: 0 Sample: 24320000 / 53735682 Loss: 1.472667685624312\n",
      "Epoch: 0 Sample: 24330000 / 53735682 Loss: 1.5724483107235185\n",
      "Epoch: 0 Sample: 24340000 / 53735682 Loss: 1.4577421827420038\n",
      "Epoch: 0 Sample: 24350000 / 53735682 Loss: 1.4732663937041128\n",
      "Epoch: 0 Sample: 24360000 / 53735682 Loss: 1.5326173825111704\n",
      "Epoch: 0 Sample: 24370000 / 53735682 Loss: 1.4928515348588007\n",
      "Epoch: 0 Sample: 24380000 / 53735682 Loss: 1.5240111403042884\n",
      "Epoch: 0 Sample: 24390000 / 53735682 Loss: 1.4234510681136694\n",
      "Epoch: 0 Sample: 24400000 / 53735682 Loss: 1.5685159677742306\n",
      "Epoch: 0 Sample: 24410000 / 53735682 Loss: 1.5211907699443883\n",
      "Epoch: 0 Sample: 24420000 / 53735682 Loss: 1.5056489280770935\n",
      "Epoch: 0 Sample: 24430000 / 53735682 Loss: 1.531499478934741\n",
      "Epoch: 0 Sample: 24440000 / 53735682 Loss: 1.4050838173127431\n",
      "Epoch: 0 Sample: 24450000 / 53735682 Loss: 1.4987315236533807\n",
      "Epoch: 0 Sample: 24460000 / 53735682 Loss: 1.4451271482705124\n",
      "Epoch: 0 Sample: 24470000 / 53735682 Loss: 1.5413041867005044\n",
      "Epoch: 0 Sample: 24480000 / 53735682 Loss: 1.374131182483592\n",
      "Epoch: 0 Sample: 24490000 / 53735682 Loss: 1.4815704600542472\n",
      "Epoch: 0 Sample: 24500000 / 53735682 Loss: 1.488638055529131\n",
      "Epoch: 0 Sample: 24510000 / 53735682 Loss: 1.4788518210678085\n",
      "Epoch: 0 Sample: 24520000 / 53735682 Loss: 1.4634394751608648\n",
      "Epoch: 0 Sample: 24530000 / 53735682 Loss: 1.4265055001974576\n",
      "Epoch: 0 Sample: 24540000 / 53735682 Loss: 1.482482381930395\n",
      "Epoch: 0 Sample: 24550000 / 53735682 Loss: 1.4826438337181418\n",
      "Epoch: 0 Sample: 24560000 / 53735682 Loss: 1.5726620875376245\n",
      "Epoch: 0 Sample: 24570000 / 53735682 Loss: 1.626810850702043\n",
      "Epoch: 0 Sample: 24580000 / 53735682 Loss: 1.4223909770048258\n",
      "Epoch: 0 Sample: 24590000 / 53735682 Loss: 1.501076150033343\n",
      "Epoch: 0 Sample: 24600000 / 53735682 Loss: 1.4253702406531128\n",
      "Epoch: 0 Sample: 24610000 / 53735682 Loss: 1.570485199330661\n",
      "Epoch: 0 Sample: 24620000 / 53735682 Loss: 1.4980076119645216\n",
      "Epoch: 0 Sample: 24630000 / 53735682 Loss: 1.5632917251945477\n",
      "Epoch: 0 Sample: 24640000 / 53735682 Loss: 1.4173501735402358\n",
      "Epoch: 0 Sample: 24650000 / 53735682 Loss: 1.3518129561205907\n",
      "Epoch: 0 Sample: 24660000 / 53735682 Loss: 1.4367328314106\n",
      "Epoch: 0 Sample: 24670000 / 53735682 Loss: 1.5176012208497154\n",
      "Epoch: 0 Sample: 24680000 / 53735682 Loss: 1.4780423915848495\n",
      "Epoch: 0 Sample: 24690000 / 53735682 Loss: 1.5097674799141343\n",
      "Epoch: 0 Sample: 24700000 / 53735682 Loss: 1.4555219332826406\n",
      "Epoch: 0 Sample: 24710000 / 53735682 Loss: 1.5252218336339605\n",
      "Epoch: 0 Sample: 24720000 / 53735682 Loss: 1.4365413475135331\n",
      "Epoch: 0 Sample: 24730000 / 53735682 Loss: 1.4972148059930728\n",
      "Epoch: 0 Sample: 24740000 / 53735682 Loss: 1.4624878989551833\n",
      "Epoch: 0 Sample: 24750000 / 53735682 Loss: 1.5123866875654357\n",
      "Epoch: 0 Sample: 24760000 / 53735682 Loss: 1.5013743478934147\n",
      "Epoch: 0 Sample: 24770000 / 53735682 Loss: 1.4453627000144451\n",
      "Epoch: 0 Sample: 24780000 / 53735682 Loss: 1.460497279558475\n",
      "Epoch: 0 Sample: 24790000 / 53735682 Loss: 1.4074544681129304\n",
      "Epoch: 0 Sample: 24800000 / 53735682 Loss: 1.4569584138131353\n",
      "Epoch: 0 Sample: 24810000 / 53735682 Loss: 1.6060790922888046\n",
      "Epoch: 0 Sample: 24820000 / 53735682 Loss: 1.5398669466824955\n",
      "Epoch: 0 Sample: 24830000 / 53735682 Loss: 1.4871273989309564\n",
      "Epoch: 0 Sample: 24840000 / 53735682 Loss: 1.4402616059679905\n",
      "Epoch: 0 Sample: 24850000 / 53735682 Loss: 1.4374744274304132\n",
      "Epoch: 0 Sample: 24860000 / 53735682 Loss: 1.576874892617742\n",
      "Epoch: 0 Sample: 24870000 / 53735682 Loss: 1.539848206141873\n",
      "Epoch: 0 Sample: 24880000 / 53735682 Loss: 1.365982281041961\n",
      "Epoch: 0 Sample: 24890000 / 53735682 Loss: 1.4823203322243625\n",
      "Epoch: 0 Sample: 24900000 / 53735682 Loss: 1.4567794178664561\n",
      "Epoch: 0 Sample: 24910000 / 53735682 Loss: 1.5054109413907522\n",
      "Epoch: 0 Sample: 24920000 / 53735682 Loss: 1.532413252975525\n",
      "Epoch: 0 Sample: 24930000 / 53735682 Loss: 1.399780356644269\n",
      "Epoch: 0 Sample: 24940000 / 53735682 Loss: 1.671471095392358\n",
      "Epoch: 0 Sample: 24950000 / 53735682 Loss: 1.4801490525019592\n",
      "Epoch: 0 Sample: 24960000 / 53735682 Loss: 1.4826711911940564\n",
      "Epoch: 0 Sample: 24970000 / 53735682 Loss: 1.491411200749607\n",
      "Epoch: 0 Sample: 24980000 / 53735682 Loss: 1.4331891489306288\n",
      "Epoch: 0 Sample: 24990000 / 53735682 Loss: 1.5834741735718745\n",
      "Epoch: 0 Sample: 25000000 / 53735682 Loss: 1.5573887839951004\n",
      "Epoch: 0 Sample: 25010000 / 53735682 Loss: 1.5416847089857217\n",
      "Epoch: 0 Sample: 25020000 / 53735682 Loss: 1.568751551651666\n",
      "Epoch: 0 Sample: 25030000 / 53735682 Loss: 1.557443546822692\n",
      "Epoch: 0 Sample: 25040000 / 53735682 Loss: 1.4931433940848802\n",
      "Epoch: 0 Sample: 25050000 / 53735682 Loss: 1.4491136074823543\n",
      "Epoch: 0 Sample: 25060000 / 53735682 Loss: 1.5732636194571934\n",
      "Epoch: 0 Sample: 25070000 / 53735682 Loss: 1.5139588643444344\n",
      "Epoch: 0 Sample: 25080000 / 53735682 Loss: 1.4622278856139275\n",
      "Epoch: 0 Sample: 25090000 / 53735682 Loss: 1.5075951725152599\n",
      "Epoch: 0 Sample: 25100000 / 53735682 Loss: 1.4651597547171398\n",
      "Epoch: 0 Sample: 25110000 / 53735682 Loss: 1.5236050161576937\n",
      "Epoch: 0 Sample: 25120000 / 53735682 Loss: 1.452526773121634\n",
      "Epoch: 0 Sample: 25130000 / 53735682 Loss: 1.5531008885788244\n",
      "Epoch: 0 Sample: 25140000 / 53735682 Loss: 1.5225978885666822\n",
      "Epoch: 0 Sample: 25150000 / 53735682 Loss: 1.4284193632518094\n",
      "Epoch: 0 Sample: 25160000 / 53735682 Loss: 1.4348369864534405\n",
      "Epoch: 0 Sample: 25170000 / 53735682 Loss: 1.6265886253615673\n",
      "Epoch: 0 Sample: 25180000 / 53735682 Loss: 1.4976523866602853\n",
      "Epoch: 0 Sample: 25190000 / 53735682 Loss: 1.4388360367537418\n",
      "Epoch: 0 Sample: 25200000 / 53735682 Loss: 1.491838933666136\n",
      "Epoch: 0 Sample: 25210000 / 53735682 Loss: 1.4845935027711796\n",
      "Epoch: 0 Sample: 25220000 / 53735682 Loss: 1.5320625950582016\n",
      "Epoch: 0 Sample: 25230000 / 53735682 Loss: 1.4808959955747176\n",
      "Epoch: 0 Sample: 25240000 / 53735682 Loss: 1.376604499909794\n",
      "Epoch: 0 Sample: 25250000 / 53735682 Loss: 1.5269046401502413\n",
      "Epoch: 0 Sample: 25260000 / 53735682 Loss: 1.4923231029668047\n",
      "Epoch: 0 Sample: 25270000 / 53735682 Loss: 1.4452649864306517\n",
      "Epoch: 0 Sample: 25280000 / 53735682 Loss: 1.4786938881032567\n",
      "Epoch: 0 Sample: 25290000 / 53735682 Loss: 1.5591072414795533\n",
      "Epoch: 0 Sample: 25300000 / 53735682 Loss: 1.4455637737916405\n",
      "Epoch: 0 Sample: 25310000 / 53735682 Loss: 1.4623646072943906\n",
      "Epoch: 0 Sample: 25320000 / 53735682 Loss: 1.4485675604119463\n",
      "Epoch: 0 Sample: 25330000 / 53735682 Loss: 1.4890030143806716\n",
      "Epoch: 0 Sample: 25340000 / 53735682 Loss: 1.4535838442892257\n",
      "Epoch: 0 Sample: 25350000 / 53735682 Loss: 1.5381827570810687\n",
      "Epoch: 0 Sample: 25360000 / 53735682 Loss: 1.4581373667799378\n",
      "Epoch: 0 Sample: 25370000 / 53735682 Loss: 1.4961982619214615\n",
      "Epoch: 0 Sample: 25380000 / 53735682 Loss: 1.4405814327575281\n",
      "Epoch: 0 Sample: 25390000 / 53735682 Loss: 1.4513018389927785\n",
      "Epoch: 0 Sample: 25400000 / 53735682 Loss: 1.404692741537402\n",
      "Epoch: 0 Sample: 25410000 / 53735682 Loss: 1.49361369651169\n",
      "Epoch: 0 Sample: 25420000 / 53735682 Loss: 1.5400719719928793\n",
      "Epoch: 0 Sample: 25430000 / 53735682 Loss: 1.5164194073274027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 25440000 / 53735682 Loss: 1.521212506593713\n",
      "Epoch: 0 Sample: 25450000 / 53735682 Loss: 1.5328868369930273\n",
      "Epoch: 0 Sample: 25460000 / 53735682 Loss: 1.4504226924886092\n",
      "Epoch: 0 Sample: 25470000 / 53735682 Loss: 1.4728939017396518\n",
      "Epoch: 0 Sample: 25480000 / 53735682 Loss: 1.5336589907101565\n",
      "Epoch: 0 Sample: 25490000 / 53735682 Loss: 1.4457323416985113\n",
      "Epoch: 0 Sample: 25500000 / 53735682 Loss: 1.572303940462445\n",
      "Epoch: 0 Sample: 25510000 / 53735682 Loss: 1.4821137529091462\n",
      "Epoch: 0 Sample: 25520000 / 53735682 Loss: 1.4200722724808608\n",
      "Epoch: 0 Sample: 25530000 / 53735682 Loss: 1.4485076440966753\n",
      "Epoch: 0 Sample: 25540000 / 53735682 Loss: 1.47959929089548\n",
      "Epoch: 0 Sample: 25550000 / 53735682 Loss: 1.5171164390450844\n",
      "Epoch: 0 Sample: 25560000 / 53735682 Loss: 1.4462460593725435\n",
      "Epoch: 0 Sample: 25570000 / 53735682 Loss: 1.5188933802802973\n",
      "Epoch: 0 Sample: 25580000 / 53735682 Loss: 1.5323331662891784\n",
      "Epoch: 0 Sample: 25590000 / 53735682 Loss: 1.5439639805883343\n",
      "Epoch: 0 Sample: 25600000 / 53735682 Loss: 1.514293551588105\n",
      "Epoch: 0 Sample: 25610000 / 53735682 Loss: 1.5105532398282664\n",
      "Epoch: 0 Sample: 25620000 / 53735682 Loss: 1.4839041981383605\n",
      "Epoch: 0 Sample: 25630000 / 53735682 Loss: 1.492125842015048\n",
      "Epoch: 0 Sample: 25640000 / 53735682 Loss: 1.374248718628368\n",
      "Epoch: 0 Sample: 25650000 / 53735682 Loss: 1.4821452867472962\n",
      "Epoch: 0 Sample: 25660000 / 53735682 Loss: 1.5385296858124637\n",
      "Epoch: 0 Sample: 25670000 / 53735682 Loss: 1.5227598087603083\n",
      "Epoch: 0 Sample: 25680000 / 53735682 Loss: 1.5791752603153242\n",
      "Epoch: 0 Sample: 25690000 / 53735682 Loss: 1.4872919343205142\n",
      "Epoch: 0 Sample: 25700000 / 53735682 Loss: 1.507503850036044\n",
      "Epoch: 0 Sample: 25710000 / 53735682 Loss: 1.5110886051183456\n",
      "Epoch: 0 Sample: 25720000 / 53735682 Loss: 1.530030104098811\n",
      "Epoch: 0 Sample: 25730000 / 53735682 Loss: 1.442711372462155\n",
      "Epoch: 0 Sample: 25740000 / 53735682 Loss: 1.4529978619843336\n",
      "Epoch: 0 Sample: 25750000 / 53735682 Loss: 1.5393697028701308\n",
      "Epoch: 0 Sample: 25760000 / 53735682 Loss: 1.4788730026661696\n",
      "Epoch: 0 Sample: 25770000 / 53735682 Loss: 1.4961704699948035\n",
      "Epoch: 0 Sample: 25780000 / 53735682 Loss: 1.4793472987869267\n",
      "Epoch: 0 Sample: 25790000 / 53735682 Loss: 1.4447761294851937\n",
      "Epoch: 0 Sample: 25800000 / 53735682 Loss: 1.5271995308530868\n",
      "Epoch: 0 Sample: 25810000 / 53735682 Loss: 1.553279422321138\n",
      "Epoch: 0 Sample: 25820000 / 53735682 Loss: 1.5138044045712806\n",
      "Epoch: 0 Sample: 25830000 / 53735682 Loss: 1.5320455282762664\n",
      "Epoch: 0 Sample: 25840000 / 53735682 Loss: 1.495191884224469\n",
      "Epoch: 0 Sample: 25850000 / 53735682 Loss: 1.502236069521557\n",
      "Epoch: 0 Sample: 25860000 / 53735682 Loss: 1.4903734720474948\n",
      "Epoch: 0 Sample: 25870000 / 53735682 Loss: 1.4980177258125669\n",
      "Epoch: 0 Sample: 25880000 / 53735682 Loss: 1.4614987681691374\n",
      "Epoch: 0 Sample: 25890000 / 53735682 Loss: 1.4667499966191733\n",
      "Epoch: 0 Sample: 25900000 / 53735682 Loss: 1.4210674980074243\n",
      "Epoch: 0 Sample: 25910000 / 53735682 Loss: 1.513822838423184\n",
      "Epoch: 0 Sample: 25920000 / 53735682 Loss: 1.4431598384951765\n",
      "Epoch: 0 Sample: 25930000 / 53735682 Loss: 1.5244896577348412\n",
      "Epoch: 0 Sample: 25940000 / 53735682 Loss: 1.5366137854034014\n",
      "Epoch: 0 Sample: 25950000 / 53735682 Loss: 1.483932691721725\n",
      "Epoch: 0 Sample: 25960000 / 53735682 Loss: 1.5547658522488488\n",
      "Epoch: 0 Sample: 25970000 / 53735682 Loss: 1.486882249984842\n",
      "Epoch: 0 Sample: 25980000 / 53735682 Loss: 1.4921241613944483\n",
      "Epoch: 0 Sample: 25990000 / 53735682 Loss: 1.4685220359785969\n",
      "Epoch: 0 Sample: 26000000 / 53735682 Loss: 1.4646185290660478\n",
      "Epoch: 0 Sample: 26010000 / 53735682 Loss: 1.5001071020485508\n",
      "Epoch: 0 Sample: 26020000 / 53735682 Loss: 1.413786156601133\n",
      "Epoch: 0 Sample: 26030000 / 53735682 Loss: 1.5185502414540497\n",
      "Epoch: 0 Sample: 26040000 / 53735682 Loss: 1.428093089232117\n",
      "Epoch: 0 Sample: 26050000 / 53735682 Loss: 1.4690945518423217\n",
      "Epoch: 0 Sample: 26060000 / 53735682 Loss: 1.4550262254760833\n",
      "Epoch: 0 Sample: 26070000 / 53735682 Loss: 1.5674858708137458\n",
      "Epoch: 0 Sample: 26080000 / 53735682 Loss: 1.4166324873830973\n",
      "Epoch: 0 Sample: 26090000 / 53735682 Loss: 1.480112473397909\n",
      "Epoch: 0 Sample: 26100000 / 53735682 Loss: 1.5025569973839024\n",
      "Epoch: 0 Sample: 26110000 / 53735682 Loss: 1.4944990964394413\n",
      "Epoch: 0 Sample: 26120000 / 53735682 Loss: 1.481156971939594\n",
      "Epoch: 0 Sample: 26130000 / 53735682 Loss: 1.5350430493601845\n",
      "Epoch: 0 Sample: 26140000 / 53735682 Loss: 1.5441511987284668\n",
      "Epoch: 0 Sample: 26150000 / 53735682 Loss: 1.4592670475951457\n",
      "Epoch: 0 Sample: 26160000 / 53735682 Loss: 1.4673157504842558\n",
      "Epoch: 0 Sample: 26170000 / 53735682 Loss: 1.529927801874786\n",
      "Epoch: 0 Sample: 26180000 / 53735682 Loss: 1.510218822451455\n",
      "Epoch: 0 Sample: 26190000 / 53735682 Loss: 1.4951668008773602\n",
      "Epoch: 0 Sample: 26200000 / 53735682 Loss: 1.452301682898651\n",
      "Epoch: 0 Sample: 26210000 / 53735682 Loss: 1.5147512256940157\n",
      "Epoch: 0 Sample: 26220000 / 53735682 Loss: 1.5288219768110158\n",
      "Epoch: 0 Sample: 26230000 / 53735682 Loss: 1.5084744141892727\n",
      "Epoch: 0 Sample: 26240000 / 53735682 Loss: 1.5247054225917593\n",
      "Epoch: 0 Sample: 26250000 / 53735682 Loss: 1.4212094187529167\n",
      "Epoch: 0 Sample: 26260000 / 53735682 Loss: 1.5542682003547044\n",
      "Epoch: 0 Sample: 26270000 / 53735682 Loss: 1.449556308138069\n",
      "Epoch: 0 Sample: 26280000 / 53735682 Loss: 1.453026624945411\n",
      "Epoch: 0 Sample: 26290000 / 53735682 Loss: 1.3737275619123641\n",
      "Epoch: 0 Sample: 26300000 / 53735682 Loss: 1.449694079633917\n",
      "Epoch: 0 Sample: 26310000 / 53735682 Loss: 1.4750797894618233\n",
      "Epoch: 0 Sample: 26320000 / 53735682 Loss: 1.4096941656257425\n",
      "Epoch: 0 Sample: 26330000 / 53735682 Loss: 1.5006296850912775\n",
      "Epoch: 0 Sample: 26340000 / 53735682 Loss: 1.521441090704045\n",
      "Epoch: 0 Sample: 26350000 / 53735682 Loss: 1.4958604860887537\n",
      "Epoch: 0 Sample: 26360000 / 53735682 Loss: 1.4869844576392324\n",
      "Epoch: 0 Sample: 26370000 / 53735682 Loss: 1.522131859976017\n",
      "Epoch: 0 Sample: 26380000 / 53735682 Loss: 1.4836608181216615\n",
      "Epoch: 0 Sample: 26390000 / 53735682 Loss: 1.4449454505147301\n",
      "Epoch: 0 Sample: 26400000 / 53735682 Loss: 1.4798549415074795\n",
      "Epoch: 0 Sample: 26410000 / 53735682 Loss: 1.5547865788415627\n",
      "Epoch: 0 Sample: 26420000 / 53735682 Loss: 1.4912342529445226\n",
      "Epoch: 0 Sample: 26430000 / 53735682 Loss: 1.5262414803460138\n",
      "Epoch: 0 Sample: 26440000 / 53735682 Loss: 1.4921589770269408\n",
      "Epoch: 0 Sample: 26450000 / 53735682 Loss: 1.5458901213184806\n",
      "Epoch: 0 Sample: 26460000 / 53735682 Loss: 1.458759185644091\n",
      "Epoch: 0 Sample: 26470000 / 53735682 Loss: 1.5225147148097042\n",
      "Epoch: 0 Sample: 26480000 / 53735682 Loss: 1.4630700234914076\n",
      "Epoch: 0 Sample: 26490000 / 53735682 Loss: 1.5546404422914835\n",
      "Epoch: 0 Sample: 26500000 / 53735682 Loss: 1.5598917972714985\n",
      "Epoch: 0 Sample: 26510000 / 53735682 Loss: 1.507102944506629\n",
      "Epoch: 0 Sample: 26520000 / 53735682 Loss: 1.534725711710064\n",
      "Epoch: 0 Sample: 26530000 / 53735682 Loss: 1.5833256425296813\n",
      "Epoch: 0 Sample: 26540000 / 53735682 Loss: 1.5794459338847202\n",
      "Epoch: 0 Sample: 26550000 / 53735682 Loss: 1.4546195745344488\n",
      "Epoch: 0 Sample: 26560000 / 53735682 Loss: 1.4601732446266222\n",
      "Epoch: 0 Sample: 26570000 / 53735682 Loss: 1.5487159867745528\n",
      "Epoch: 0 Sample: 26580000 / 53735682 Loss: 1.5004830508484628\n",
      "Epoch: 0 Sample: 26590000 / 53735682 Loss: 1.4305756601591622\n",
      "Epoch: 0 Sample: 26600000 / 53735682 Loss: 1.544692468296677\n",
      "Epoch: 0 Sample: 26610000 / 53735682 Loss: 1.5084966401945603\n",
      "Epoch: 0 Sample: 26620000 / 53735682 Loss: 1.479995835257477\n",
      "Epoch: 0 Sample: 26630000 / 53735682 Loss: 1.4375034886700635\n",
      "Epoch: 0 Sample: 26640000 / 53735682 Loss: 1.5019977199890309\n",
      "Epoch: 0 Sample: 26650000 / 53735682 Loss: 1.4764742264185826\n",
      "Epoch: 0 Sample: 26660000 / 53735682 Loss: 1.5123818681093004\n",
      "Epoch: 0 Sample: 26670000 / 53735682 Loss: 1.4451687131156197\n",
      "Epoch: 0 Sample: 26680000 / 53735682 Loss: 1.4862244350208655\n",
      "Epoch: 0 Sample: 26690000 / 53735682 Loss: 1.5033899901729386\n",
      "Epoch: 0 Sample: 26700000 / 53735682 Loss: 1.4857462492653342\n",
      "Epoch: 0 Sample: 26710000 / 53735682 Loss: 1.4630463135546692\n",
      "Epoch: 0 Sample: 26720000 / 53735682 Loss: 1.438859637484296\n",
      "Epoch: 0 Sample: 26730000 / 53735682 Loss: 1.543826820313154\n",
      "Epoch: 0 Sample: 26740000 / 53735682 Loss: 1.537272049930618\n",
      "Epoch: 0 Sample: 26750000 / 53735682 Loss: 1.525947343518654\n",
      "Epoch: 0 Sample: 26760000 / 53735682 Loss: 1.435451308383635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 26770000 / 53735682 Loss: 1.4666231813668589\n",
      "Epoch: 0 Sample: 26780000 / 53735682 Loss: 1.4379267893218994\n",
      "Epoch: 0 Sample: 26790000 / 53735682 Loss: 1.508729474036702\n",
      "Epoch: 0 Sample: 26800000 / 53735682 Loss: 1.513937235891565\n",
      "Epoch: 0 Sample: 26810000 / 53735682 Loss: 1.4362998004550778\n",
      "Epoch: 0 Sample: 26820000 / 53735682 Loss: 1.4924914855467666\n",
      "Epoch: 0 Sample: 26830000 / 53735682 Loss: 1.5428531833215022\n",
      "Epoch: 0 Sample: 26840000 / 53735682 Loss: 1.4473703918837353\n",
      "Epoch: 0 Sample: 26850000 / 53735682 Loss: 1.5309023747776227\n",
      "Epoch: 0 Sample: 26860000 / 53735682 Loss: 1.4340218024475881\n",
      "Epoch: 0 Sample: 26870000 / 53735682 Loss: 1.4945930503029325\n",
      "Epoch: 0 Sample: 26880000 / 53735682 Loss: 1.4813417780625124\n",
      "Epoch: 0 Sample: 26890000 / 53735682 Loss: 1.564632888855853\n",
      "Epoch: 0 Sample: 26900000 / 53735682 Loss: 1.5766791102740938\n",
      "Epoch: 0 Sample: 26910000 / 53735682 Loss: 1.5880935680241477\n",
      "Epoch: 0 Sample: 26920000 / 53735682 Loss: 1.5398480051625043\n",
      "Epoch: 0 Sample: 26930000 / 53735682 Loss: 1.515564958634854\n",
      "Epoch: 0 Sample: 26940000 / 53735682 Loss: 1.629964780683957\n",
      "Epoch: 0 Sample: 26950000 / 53735682 Loss: 1.427343190735267\n",
      "Epoch: 0 Sample: 26960000 / 53735682 Loss: 1.333707347531303\n",
      "Epoch: 0 Sample: 26970000 / 53735682 Loss: 1.4965624882626374\n",
      "Epoch: 0 Sample: 26980000 / 53735682 Loss: 1.5140037564421631\n",
      "Epoch: 0 Sample: 26990000 / 53735682 Loss: 1.4999935682158623\n",
      "Epoch: 0 Sample: 27000000 / 53735682 Loss: 1.5083607357447284\n",
      "Epoch: 0 Sample: 27010000 / 53735682 Loss: 1.5023910281459711\n",
      "Epoch: 0 Sample: 27020000 / 53735682 Loss: 1.4870322098940498\n",
      "Epoch: 0 Sample: 27030000 / 53735682 Loss: 1.4478190797228985\n",
      "Epoch: 0 Sample: 27040000 / 53735682 Loss: 1.5669469559006257\n",
      "Epoch: 0 Sample: 27050000 / 53735682 Loss: 1.5694251614108465\n",
      "Epoch: 0 Sample: 27060000 / 53735682 Loss: 1.5165932394202015\n",
      "Epoch: 0 Sample: 27070000 / 53735682 Loss: 1.4691799198408946\n",
      "Epoch: 0 Sample: 27080000 / 53735682 Loss: 1.5849241253208863\n",
      "Epoch: 0 Sample: 27090000 / 53735682 Loss: 1.5462035239063643\n",
      "Epoch: 0 Sample: 27100000 / 53735682 Loss: 1.459086505320447\n",
      "Epoch: 0 Sample: 27110000 / 53735682 Loss: 1.4969606844423158\n",
      "Epoch: 0 Sample: 27120000 / 53735682 Loss: 1.4750664142188306\n",
      "Epoch: 0 Sample: 27130000 / 53735682 Loss: 1.6350158053632189\n",
      "Epoch: 0 Sample: 27140000 / 53735682 Loss: 1.5202435647714032\n",
      "Epoch: 0 Sample: 27150000 / 53735682 Loss: 1.4930178613328926\n",
      "Epoch: 0 Sample: 27160000 / 53735682 Loss: 1.4594212204407548\n",
      "Epoch: 0 Sample: 27170000 / 53735682 Loss: 1.491183892857905\n",
      "Epoch: 0 Sample: 27180000 / 53735682 Loss: 1.5509585463189104\n",
      "Epoch: 0 Sample: 27190000 / 53735682 Loss: 1.4490138024991301\n",
      "Epoch: 0 Sample: 27200000 / 53735682 Loss: 1.5192051158518227\n",
      "Epoch: 0 Sample: 27210000 / 53735682 Loss: 1.501710286201336\n",
      "Epoch: 0 Sample: 27220000 / 53735682 Loss: 1.454511659884898\n",
      "Epoch: 0 Sample: 27230000 / 53735682 Loss: 1.5167309439404428\n",
      "Epoch: 0 Sample: 27240000 / 53735682 Loss: 1.497280490482523\n",
      "Epoch: 0 Sample: 27250000 / 53735682 Loss: 1.5470796845439296\n",
      "Epoch: 0 Sample: 27260000 / 53735682 Loss: 1.4285944474031047\n",
      "Epoch: 0 Sample: 27270000 / 53735682 Loss: 1.520383004809037\n",
      "Epoch: 0 Sample: 27280000 / 53735682 Loss: 1.4457035118536399\n",
      "Epoch: 0 Sample: 27290000 / 53735682 Loss: 1.3940161676731866\n",
      "Epoch: 0 Sample: 27300000 / 53735682 Loss: 1.5072977741801143\n",
      "Epoch: 0 Sample: 27310000 / 53735682 Loss: 1.5388708293309339\n",
      "Epoch: 0 Sample: 27320000 / 53735682 Loss: 1.539004094541706\n",
      "Epoch: 0 Sample: 27330000 / 53735682 Loss: 1.3925915160818705\n",
      "Epoch: 0 Sample: 27340000 / 53735682 Loss: 1.5170581149787248\n",
      "Epoch: 0 Sample: 27350000 / 53735682 Loss: 1.5124054955783208\n",
      "Epoch: 0 Sample: 27360000 / 53735682 Loss: 1.4431668079140039\n",
      "Epoch: 0 Sample: 27370000 / 53735682 Loss: 1.4498817686740424\n",
      "Epoch: 0 Sample: 27380000 / 53735682 Loss: 1.393517729275159\n",
      "Epoch: 0 Sample: 27390000 / 53735682 Loss: 1.4949811816362883\n",
      "Epoch: 0 Sample: 27400000 / 53735682 Loss: 1.4988582859444604\n",
      "Epoch: 0 Sample: 27410000 / 53735682 Loss: 1.5385801449510121\n",
      "Epoch: 0 Sample: 27420000 / 53735682 Loss: 1.545453938089119\n",
      "Epoch: 0 Sample: 27430000 / 53735682 Loss: 1.5177049670248124\n",
      "Epoch: 0 Sample: 27440000 / 53735682 Loss: 1.4774292543138352\n",
      "Epoch: 0 Sample: 27450000 / 53735682 Loss: 1.4020687091723352\n",
      "Epoch: 0 Sample: 27460000 / 53735682 Loss: 1.506957377624389\n",
      "Epoch: 0 Sample: 27470000 / 53735682 Loss: 1.4548166524827244\n",
      "Epoch: 0 Sample: 27480000 / 53735682 Loss: 1.5037761881794327\n",
      "Epoch: 0 Sample: 27490000 / 53735682 Loss: 1.5396201569705374\n",
      "Epoch: 0 Sample: 27500000 / 53735682 Loss: 1.4895529873703697\n",
      "Epoch: 0 Sample: 27510000 / 53735682 Loss: 1.5631071132577181\n",
      "Epoch: 0 Sample: 27520000 / 53735682 Loss: 1.4705722374919121\n",
      "Epoch: 0 Sample: 27530000 / 53735682 Loss: 1.5640871552740605\n",
      "Epoch: 0 Sample: 27540000 / 53735682 Loss: 1.4975786708890966\n",
      "Epoch: 0 Sample: 27550000 / 53735682 Loss: 1.5506422154647803\n",
      "Epoch: 0 Sample: 27560000 / 53735682 Loss: 1.4693951396533413\n",
      "Epoch: 0 Sample: 27570000 / 53735682 Loss: 1.4581028629602857\n",
      "Epoch: 0 Sample: 27580000 / 53735682 Loss: 1.5100775245009732\n",
      "Epoch: 0 Sample: 27590000 / 53735682 Loss: 1.4408499333415707\n",
      "Epoch: 0 Sample: 27600000 / 53735682 Loss: 1.5158578016096667\n",
      "Epoch: 0 Sample: 27610000 / 53735682 Loss: 1.482801035520355\n",
      "Epoch: 0 Sample: 27620000 / 53735682 Loss: 1.4763457400158186\n",
      "Epoch: 0 Sample: 27630000 / 53735682 Loss: 1.5107535861359336\n",
      "Epoch: 0 Sample: 27640000 / 53735682 Loss: 1.4779338164928841\n",
      "Epoch: 0 Sample: 27650000 / 53735682 Loss: 1.429163327069713\n",
      "Epoch: 0 Sample: 27660000 / 53735682 Loss: 1.5308879696407263\n",
      "Epoch: 0 Sample: 27670000 / 53735682 Loss: 1.4361477578544644\n",
      "Epoch: 0 Sample: 27680000 / 53735682 Loss: 1.5424708796860946\n",
      "Epoch: 0 Sample: 27690000 / 53735682 Loss: 1.466778863578023\n",
      "Epoch: 0 Sample: 27700000 / 53735682 Loss: 1.4324002654864196\n",
      "Epoch: 0 Sample: 27710000 / 53735682 Loss: 1.4894170291827626\n",
      "Epoch: 0 Sample: 27720000 / 53735682 Loss: 1.482577171688164\n",
      "Epoch: 0 Sample: 27730000 / 53735682 Loss: 1.4873309101561965\n",
      "Epoch: 0 Sample: 27740000 / 53735682 Loss: 1.4427116127848554\n",
      "Epoch: 0 Sample: 27750000 / 53735682 Loss: 1.4160158356528818\n",
      "Epoch: 0 Sample: 27760000 / 53735682 Loss: 1.466538813098485\n",
      "Epoch: 0 Sample: 27770000 / 53735682 Loss: 1.536872275221473\n",
      "Epoch: 0 Sample: 27780000 / 53735682 Loss: 1.488341569342973\n",
      "Epoch: 0 Sample: 27790000 / 53735682 Loss: 1.5254756502577997\n",
      "Epoch: 0 Sample: 27800000 / 53735682 Loss: 1.5145710607347553\n",
      "Epoch: 0 Sample: 27810000 / 53735682 Loss: 1.5041997294892295\n",
      "Epoch: 0 Sample: 27820000 / 53735682 Loss: 1.4500405935639515\n",
      "Epoch: 0 Sample: 27830000 / 53735682 Loss: 1.4977502371596478\n",
      "Epoch: 0 Sample: 27840000 / 53735682 Loss: 1.4839572966487606\n",
      "Epoch: 0 Sample: 27850000 / 53735682 Loss: 1.4557180762475328\n",
      "Epoch: 0 Sample: 27860000 / 53735682 Loss: 1.4146607997694485\n",
      "Epoch: 0 Sample: 27870000 / 53735682 Loss: 1.46920557259409\n",
      "Epoch: 0 Sample: 27880000 / 53735682 Loss: 1.4967726190230857\n",
      "Epoch: 0 Sample: 27890000 / 53735682 Loss: 1.4221519695295144\n",
      "Epoch: 0 Sample: 27900000 / 53735682 Loss: 1.4580211232427926\n",
      "Epoch: 0 Sample: 27910000 / 53735682 Loss: 1.4858142064745026\n",
      "Epoch: 0 Sample: 27920000 / 53735682 Loss: 1.5479201895512666\n",
      "Epoch: 0 Sample: 27930000 / 53735682 Loss: 1.5271934177926674\n",
      "Epoch: 0 Sample: 27940000 / 53735682 Loss: 1.515714019123751\n",
      "Epoch: 0 Sample: 27950000 / 53735682 Loss: 1.5438974992038155\n",
      "Epoch: 0 Sample: 27960000 / 53735682 Loss: 1.5020308845138786\n",
      "Epoch: 0 Sample: 27970000 / 53735682 Loss: 1.4672013527200916\n",
      "Epoch: 0 Sample: 27980000 / 53735682 Loss: 1.5063178243176303\n",
      "Epoch: 0 Sample: 27990000 / 53735682 Loss: 1.4802153913713332\n",
      "Epoch: 0 Sample: 28000000 / 53735682 Loss: 1.5079987410128064\n",
      "Epoch: 0 Sample: 28010000 / 53735682 Loss: 1.5224688368163768\n",
      "Epoch: 0 Sample: 28020000 / 53735682 Loss: 1.5640818627243216\n",
      "Epoch: 0 Sample: 28030000 / 53735682 Loss: 1.4099179319417205\n",
      "Epoch: 0 Sample: 28040000 / 53735682 Loss: 1.4483214665102646\n",
      "Epoch: 0 Sample: 28050000 / 53735682 Loss: 1.4772296833348246\n",
      "Epoch: 0 Sample: 28060000 / 53735682 Loss: 1.541402515320042\n",
      "Epoch: 0 Sample: 28070000 / 53735682 Loss: 1.4350064604375974\n",
      "Epoch: 0 Sample: 28080000 / 53735682 Loss: 1.4302059048166407\n",
      "Epoch: 0 Sample: 28090000 / 53735682 Loss: 1.50479830320361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 28100000 / 53735682 Loss: 1.5171075276742951\n",
      "Epoch: 0 Sample: 28110000 / 53735682 Loss: 1.5385357068065098\n",
      "Epoch: 0 Sample: 28120000 / 53735682 Loss: 1.4962824298026427\n",
      "Epoch: 0 Sample: 28130000 / 53735682 Loss: 1.454904870336054\n",
      "Epoch: 0 Sample: 28140000 / 53735682 Loss: 1.4346268447493884\n",
      "Epoch: 0 Sample: 28150000 / 53735682 Loss: 1.4839124873948486\n",
      "Epoch: 0 Sample: 28160000 / 53735682 Loss: 1.508139493388327\n",
      "Epoch: 0 Sample: 28170000 / 53735682 Loss: 1.5453734531370755\n",
      "Epoch: 0 Sample: 28180000 / 53735682 Loss: 1.5105775096880816\n",
      "Epoch: 0 Sample: 28190000 / 53735682 Loss: 1.462343607180431\n",
      "Epoch: 0 Sample: 28200000 / 53735682 Loss: 1.5147246564259675\n",
      "Epoch: 0 Sample: 28210000 / 53735682 Loss: 1.5157073061360773\n",
      "Epoch: 0 Sample: 28220000 / 53735682 Loss: 1.51143952118876\n",
      "Epoch: 0 Sample: 28230000 / 53735682 Loss: 1.5353201327667119\n",
      "Epoch: 0 Sample: 28240000 / 53735682 Loss: 1.5086457543588614\n",
      "Epoch: 0 Sample: 28250000 / 53735682 Loss: 1.4399174219878301\n",
      "Epoch: 0 Sample: 28260000 / 53735682 Loss: 1.5267044295347583\n",
      "Epoch: 0 Sample: 28270000 / 53735682 Loss: 1.404312472701415\n",
      "Epoch: 0 Sample: 28280000 / 53735682 Loss: 1.5399662275241495\n",
      "Epoch: 0 Sample: 28290000 / 53735682 Loss: 1.5030933351799132\n",
      "Epoch: 0 Sample: 28300000 / 53735682 Loss: 1.5363673401150597\n",
      "Epoch: 0 Sample: 28310000 / 53735682 Loss: 1.5263537858577938\n",
      "Epoch: 0 Sample: 28320000 / 53735682 Loss: 1.4908952822200723\n",
      "Epoch: 0 Sample: 28330000 / 53735682 Loss: 1.498073749078901\n",
      "Epoch: 0 Sample: 28340000 / 53735682 Loss: 1.5500764770722042\n",
      "Epoch: 0 Sample: 28350000 / 53735682 Loss: 1.5480370737344038\n",
      "Epoch: 0 Sample: 28360000 / 53735682 Loss: 1.4543985162600856\n",
      "Epoch: 0 Sample: 28370000 / 53735682 Loss: 1.5009423264904755\n",
      "Epoch: 0 Sample: 28380000 / 53735682 Loss: 1.4649419417774199\n",
      "Epoch: 0 Sample: 28390000 / 53735682 Loss: 1.481819736470795\n",
      "Epoch: 0 Sample: 28400000 / 53735682 Loss: 1.4513243829155704\n",
      "Epoch: 0 Sample: 28410000 / 53735682 Loss: 1.5643329349372725\n",
      "Epoch: 0 Sample: 28420000 / 53735682 Loss: 1.5004988124664447\n",
      "Epoch: 0 Sample: 28430000 / 53735682 Loss: 1.4820939746280912\n",
      "Epoch: 0 Sample: 28440000 / 53735682 Loss: 1.5322299939811919\n",
      "Epoch: 0 Sample: 28450000 / 53735682 Loss: 1.5744285758481813\n",
      "Epoch: 0 Sample: 28460000 / 53735682 Loss: 1.4406276036769343\n",
      "Epoch: 0 Sample: 28470000 / 53735682 Loss: 1.5219865688389236\n",
      "Epoch: 0 Sample: 28480000 / 53735682 Loss: 1.5216429567379595\n",
      "Epoch: 0 Sample: 28490000 / 53735682 Loss: 1.5100499850768148\n",
      "Epoch: 0 Sample: 28500000 / 53735682 Loss: 1.465919732051586\n",
      "Epoch: 0 Sample: 28510000 / 53735682 Loss: 1.455140375030352\n",
      "Epoch: 0 Sample: 28520000 / 53735682 Loss: 1.5431225793434993\n",
      "Epoch: 0 Sample: 28530000 / 53735682 Loss: 1.5161964352046857\n",
      "Epoch: 0 Sample: 28540000 / 53735682 Loss: 1.5114659421602281\n",
      "Epoch: 0 Sample: 28550000 / 53735682 Loss: 1.5123811556510542\n",
      "Epoch: 0 Sample: 28560000 / 53735682 Loss: 1.495676532591553\n",
      "Epoch: 0 Sample: 28570000 / 53735682 Loss: 1.5203549806263639\n",
      "Epoch: 0 Sample: 28580000 / 53735682 Loss: 1.4648933463528024\n",
      "Epoch: 0 Sample: 28590000 / 53735682 Loss: 1.5138480630876676\n",
      "Epoch: 0 Sample: 28600000 / 53735682 Loss: 1.4899990004451245\n",
      "Epoch: 0 Sample: 28610000 / 53735682 Loss: 1.45979746308524\n",
      "Epoch: 0 Sample: 28620000 / 53735682 Loss: 1.517326702289893\n",
      "Epoch: 0 Sample: 28630000 / 53735682 Loss: 1.5054362546233402\n",
      "Epoch: 0 Sample: 28640000 / 53735682 Loss: 1.4223898061551057\n",
      "Epoch: 0 Sample: 28650000 / 53735682 Loss: 1.5197676580763906\n",
      "Epoch: 0 Sample: 28660000 / 53735682 Loss: 1.4990506321949841\n",
      "Epoch: 0 Sample: 28670000 / 53735682 Loss: 1.5861530236691417\n",
      "Epoch: 0 Sample: 28680000 / 53735682 Loss: 1.4859202018206727\n",
      "Epoch: 0 Sample: 28690000 / 53735682 Loss: 1.441203843444786\n",
      "Epoch: 0 Sample: 28700000 / 53735682 Loss: 1.450776081202052\n",
      "Epoch: 0 Sample: 28710000 / 53735682 Loss: 1.4794176759036888\n",
      "Epoch: 0 Sample: 28720000 / 53735682 Loss: 1.4409550826941222\n",
      "Epoch: 0 Sample: 28730000 / 53735682 Loss: 1.5229272491460133\n",
      "Epoch: 0 Sample: 28740000 / 53735682 Loss: 1.5037334262211153\n",
      "Epoch: 0 Sample: 28750000 / 53735682 Loss: 1.5286925817640586\n",
      "Epoch: 0 Sample: 28760000 / 53735682 Loss: 1.5570691135669446\n",
      "Epoch: 0 Sample: 28770000 / 53735682 Loss: 1.4098933974361159\n",
      "Epoch: 0 Sample: 28780000 / 53735682 Loss: 1.5336488162464768\n",
      "Epoch: 0 Sample: 28790000 / 53735682 Loss: 1.4560866666193464\n",
      "Epoch: 0 Sample: 28800000 / 53735682 Loss: 1.4851599770150847\n",
      "Epoch: 0 Sample: 28810000 / 53735682 Loss: 1.4684686789379795\n",
      "Epoch: 0 Sample: 28820000 / 53735682 Loss: 1.4232664268743744\n",
      "Epoch: 0 Sample: 28830000 / 53735682 Loss: 1.6060139745207147\n",
      "Epoch: 0 Sample: 28840000 / 53735682 Loss: 1.5425810874364057\n",
      "Epoch: 0 Sample: 28850000 / 53735682 Loss: 1.5110501002663426\n",
      "Epoch: 0 Sample: 28860000 / 53735682 Loss: 1.52655504303094\n",
      "Epoch: 0 Sample: 28870000 / 53735682 Loss: 1.517753293764275\n",
      "Epoch: 0 Sample: 28880000 / 53735682 Loss: 1.5708076707568068\n",
      "Epoch: 0 Sample: 28890000 / 53735682 Loss: 1.5160280473251075\n",
      "Epoch: 0 Sample: 28900000 / 53735682 Loss: 1.408994130981491\n",
      "Epoch: 0 Sample: 28910000 / 53735682 Loss: 1.5487650601449232\n",
      "Epoch: 0 Sample: 28920000 / 53735682 Loss: 1.414242556376171\n",
      "Epoch: 0 Sample: 28930000 / 53735682 Loss: 1.485647700915233\n",
      "Epoch: 0 Sample: 28940000 / 53735682 Loss: 1.4762415137750802\n",
      "Epoch: 0 Sample: 28950000 / 53735682 Loss: 1.451670709719428\n",
      "Epoch: 0 Sample: 28960000 / 53735682 Loss: 1.4345684281359492\n",
      "Epoch: 0 Sample: 28970000 / 53735682 Loss: 1.621279354816061\n",
      "Epoch: 0 Sample: 28980000 / 53735682 Loss: 1.4805079041843916\n",
      "Epoch: 0 Sample: 28990000 / 53735682 Loss: 1.5116860837100108\n",
      "Epoch: 0 Sample: 29000000 / 53735682 Loss: 1.486251756621596\n",
      "Epoch: 0 Sample: 29010000 / 53735682 Loss: 1.511626313767971\n",
      "Epoch: 0 Sample: 29020000 / 53735682 Loss: 1.4304376955060092\n",
      "Epoch: 0 Sample: 29030000 / 53735682 Loss: 1.4547688280036541\n",
      "Epoch: 0 Sample: 29040000 / 53735682 Loss: 1.510612036371974\n",
      "Epoch: 0 Sample: 29050000 / 53735682 Loss: 1.5083715373539701\n",
      "Epoch: 0 Sample: 29060000 / 53735682 Loss: 1.4750720710975904\n",
      "Epoch: 0 Sample: 29070000 / 53735682 Loss: 1.3754021206635199\n",
      "Epoch: 0 Sample: 29080000 / 53735682 Loss: 1.4493545879639902\n",
      "Epoch: 0 Sample: 29090000 / 53735682 Loss: 1.4284667047907098\n",
      "Epoch: 0 Sample: 29100000 / 53735682 Loss: 1.5003051649613495\n",
      "Epoch: 0 Sample: 29110000 / 53735682 Loss: 1.4725330796751268\n",
      "Epoch: 0 Sample: 29120000 / 53735682 Loss: 1.4564734218393238\n",
      "Epoch: 0 Sample: 29130000 / 53735682 Loss: 1.4248750383103599\n",
      "Epoch: 0 Sample: 29140000 / 53735682 Loss: 1.5446363664437084\n",
      "Epoch: 0 Sample: 29150000 / 53735682 Loss: 1.4936233821429268\n",
      "Epoch: 0 Sample: 29160000 / 53735682 Loss: 1.5914172764966614\n",
      "Epoch: 0 Sample: 29170000 / 53735682 Loss: 1.4469674049908503\n",
      "Epoch: 0 Sample: 29180000 / 53735682 Loss: 1.4563275948946925\n",
      "Epoch: 0 Sample: 29190000 / 53735682 Loss: 1.477524250072003\n",
      "Epoch: 0 Sample: 29200000 / 53735682 Loss: 1.4886284584033929\n",
      "Epoch: 0 Sample: 29210000 / 53735682 Loss: 1.5091416422722737\n",
      "Epoch: 0 Sample: 29220000 / 53735682 Loss: 1.5110932886552875\n",
      "Epoch: 0 Sample: 29230000 / 53735682 Loss: 1.4431636222046142\n",
      "Epoch: 0 Sample: 29240000 / 53735682 Loss: 1.500730020493827\n",
      "Epoch: 0 Sample: 29250000 / 53735682 Loss: 1.4525604150226363\n",
      "Epoch: 0 Sample: 29260000 / 53735682 Loss: 1.4762414587354113\n",
      "Epoch: 0 Sample: 29270000 / 53735682 Loss: 1.4961898438491246\n",
      "Epoch: 0 Sample: 29280000 / 53735682 Loss: 1.466216037076867\n",
      "Epoch: 0 Sample: 29290000 / 53735682 Loss: 1.4714761796295202\n",
      "Epoch: 0 Sample: 29300000 / 53735682 Loss: 1.4947862522329656\n",
      "Epoch: 0 Sample: 29310000 / 53735682 Loss: 1.5210960486741083\n",
      "Epoch: 0 Sample: 29320000 / 53735682 Loss: 1.465806637998278\n",
      "Epoch: 0 Sample: 29330000 / 53735682 Loss: 1.4881362950161368\n",
      "Epoch: 0 Sample: 29340000 / 53735682 Loss: 1.5172854252154409\n",
      "Epoch: 0 Sample: 29350000 / 53735682 Loss: 1.4330133684370372\n",
      "Epoch: 0 Sample: 29360000 / 53735682 Loss: 1.5021139645256807\n",
      "Epoch: 0 Sample: 29370000 / 53735682 Loss: 1.5070448590715695\n",
      "Epoch: 0 Sample: 29380000 / 53735682 Loss: 1.5856465710127694\n",
      "Epoch: 0 Sample: 29390000 / 53735682 Loss: 1.5292353946403126\n",
      "Epoch: 0 Sample: 29400000 / 53735682 Loss: 1.3935125182215056\n",
      "Epoch: 0 Sample: 29410000 / 53735682 Loss: 1.458966007855829\n",
      "Epoch: 0 Sample: 29420000 / 53735682 Loss: 1.452581561205941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 29430000 / 53735682 Loss: 1.4924203520999486\n",
      "Epoch: 0 Sample: 29440000 / 53735682 Loss: 1.4643292388191167\n",
      "Epoch: 0 Sample: 29450000 / 53735682 Loss: 1.406228175293291\n",
      "Epoch: 0 Sample: 29460000 / 53735682 Loss: 1.3977623961086816\n",
      "Epoch: 0 Sample: 29470000 / 53735682 Loss: 1.4759849987421134\n",
      "Epoch: 0 Sample: 29480000 / 53735682 Loss: 1.5065966814879976\n",
      "Epoch: 0 Sample: 29490000 / 53735682 Loss: 1.5306378134930863\n",
      "Epoch: 0 Sample: 29500000 / 53735682 Loss: 1.4705580688922892\n",
      "Epoch: 0 Sample: 29510000 / 53735682 Loss: 1.4216157997074403\n",
      "Epoch: 0 Sample: 29520000 / 53735682 Loss: 1.467048932760508\n",
      "Epoch: 0 Sample: 29530000 / 53735682 Loss: 1.5254250247297259\n",
      "Epoch: 0 Sample: 29540000 / 53735682 Loss: 1.4328579072707335\n",
      "Epoch: 0 Sample: 29550000 / 53735682 Loss: 1.397393675386137\n",
      "Epoch: 0 Sample: 29560000 / 53735682 Loss: 1.4794071877821453\n",
      "Epoch: 0 Sample: 29570000 / 53735682 Loss: 1.3921983774931397\n",
      "Epoch: 0 Sample: 29580000 / 53735682 Loss: 1.44471787588457\n",
      "Epoch: 0 Sample: 29590000 / 53735682 Loss: 1.5081830067528579\n",
      "Epoch: 0 Sample: 29600000 / 53735682 Loss: 1.4325220332137616\n",
      "Epoch: 0 Sample: 29610000 / 53735682 Loss: 1.4652192604196692\n",
      "Epoch: 0 Sample: 29620000 / 53735682 Loss: 1.3952528057728215\n",
      "Epoch: 0 Sample: 29630000 / 53735682 Loss: 1.5225877969281765\n",
      "Epoch: 0 Sample: 29640000 / 53735682 Loss: 1.421027737605713\n",
      "Epoch: 0 Sample: 29650000 / 53735682 Loss: 1.5163001647123902\n",
      "Epoch: 0 Sample: 29660000 / 53735682 Loss: 1.5176500912596829\n",
      "Epoch: 0 Sample: 29670000 / 53735682 Loss: 1.4850621733330627\n",
      "Epoch: 0 Sample: 29680000 / 53735682 Loss: 1.484591827102983\n",
      "Epoch: 0 Sample: 29690000 / 53735682 Loss: 1.3910913419507094\n",
      "Epoch: 0 Sample: 29700000 / 53735682 Loss: 1.4618947621518896\n",
      "Epoch: 0 Sample: 29710000 / 53735682 Loss: 1.478584271153433\n",
      "Epoch: 0 Sample: 29720000 / 53735682 Loss: 1.4852406208727773\n",
      "Epoch: 0 Sample: 29730000 / 53735682 Loss: 1.457128306597225\n",
      "Epoch: 0 Sample: 29740000 / 53735682 Loss: 1.4618604367034982\n",
      "Epoch: 0 Sample: 29750000 / 53735682 Loss: 1.5015959317043133\n",
      "Epoch: 0 Sample: 29760000 / 53735682 Loss: 1.4816058450303\n",
      "Epoch: 0 Sample: 29770000 / 53735682 Loss: 1.5259476261481613\n",
      "Epoch: 0 Sample: 29780000 / 53735682 Loss: 1.5554361452500844\n",
      "Epoch: 0 Sample: 29790000 / 53735682 Loss: 1.4870256303992533\n",
      "Epoch: 0 Sample: 29800000 / 53735682 Loss: 1.4780824580299905\n",
      "Epoch: 0 Sample: 29810000 / 53735682 Loss: 1.4392774453041008\n",
      "Epoch: 0 Sample: 29820000 / 53735682 Loss: 1.5319120712447103\n",
      "Epoch: 0 Sample: 29830000 / 53735682 Loss: 1.5321853985675615\n",
      "Epoch: 0 Sample: 29840000 / 53735682 Loss: 1.5284202728255634\n",
      "Epoch: 0 Sample: 29850000 / 53735682 Loss: 1.5050324573930989\n",
      "Epoch: 0 Sample: 29860000 / 53735682 Loss: 1.53174474593391\n",
      "Epoch: 0 Sample: 29870000 / 53735682 Loss: 1.652370705575615\n",
      "Epoch: 0 Sample: 29880000 / 53735682 Loss: 1.5842058159471903\n",
      "Epoch: 0 Sample: 29890000 / 53735682 Loss: 1.4628378798727466\n",
      "Epoch: 0 Sample: 29900000 / 53735682 Loss: 1.4928697370128263\n",
      "Epoch: 0 Sample: 29910000 / 53735682 Loss: 1.5745779734851084\n",
      "Epoch: 0 Sample: 29920000 / 53735682 Loss: 1.5461439515598503\n",
      "Epoch: 0 Sample: 29930000 / 53735682 Loss: 1.4948227158888814\n",
      "Epoch: 0 Sample: 29940000 / 53735682 Loss: 1.5503136126392958\n",
      "Epoch: 0 Sample: 29950000 / 53735682 Loss: 1.4550172134399917\n",
      "Epoch: 0 Sample: 29960000 / 53735682 Loss: 1.4780298432764225\n",
      "Epoch: 0 Sample: 29970000 / 53735682 Loss: 1.46331245819326\n",
      "Epoch: 0 Sample: 29980000 / 53735682 Loss: 1.5002296366899022\n",
      "Epoch: 0 Sample: 29990000 / 53735682 Loss: 1.6030805879683143\n",
      "Epoch: 0 Sample: 30000000 / 53735682 Loss: 1.4802159861578508\n",
      "Epoch: 0 Sample: 30010000 / 53735682 Loss: 1.4904918542223113\n",
      "Epoch: 0 Sample: 30020000 / 53735682 Loss: 1.5116197651459917\n",
      "Epoch: 0 Sample: 30030000 / 53735682 Loss: 1.4612799228667284\n",
      "Epoch: 0 Sample: 30040000 / 53735682 Loss: 1.4979900115158424\n",
      "Epoch: 0 Sample: 30050000 / 53735682 Loss: 1.5330060765160716\n",
      "Epoch: 0 Sample: 30060000 / 53735682 Loss: 1.5229831733580292\n",
      "Epoch: 0 Sample: 30070000 / 53735682 Loss: 1.4968643129703698\n",
      "Epoch: 0 Sample: 30080000 / 53735682 Loss: 1.4880071832337585\n",
      "Epoch: 0 Sample: 30090000 / 53735682 Loss: 1.5868697004652426\n",
      "Epoch: 0 Sample: 30100000 / 53735682 Loss: 1.506600939895681\n",
      "Epoch: 0 Sample: 30110000 / 53735682 Loss: 1.5477696951256903\n",
      "Epoch: 0 Sample: 30120000 / 53735682 Loss: 1.525487089897962\n",
      "Epoch: 0 Sample: 30130000 / 53735682 Loss: 1.5533195966791995\n",
      "Epoch: 0 Sample: 30140000 / 53735682 Loss: 1.5011860529624572\n",
      "Epoch: 0 Sample: 30150000 / 53735682 Loss: 1.5398223912748457\n",
      "Epoch: 0 Sample: 30160000 / 53735682 Loss: 1.5439399124184143\n",
      "Epoch: 0 Sample: 30170000 / 53735682 Loss: 1.5347448766602598\n",
      "Epoch: 0 Sample: 30180000 / 53735682 Loss: 1.4993907054903999\n",
      "Epoch: 0 Sample: 30190000 / 53735682 Loss: 1.5048565606205515\n",
      "Epoch: 0 Sample: 30200000 / 53735682 Loss: 1.4913434390655067\n",
      "Epoch: 0 Sample: 30210000 / 53735682 Loss: 1.499569255608773\n",
      "Epoch: 0 Sample: 30220000 / 53735682 Loss: 1.4240346012269571\n",
      "Epoch: 0 Sample: 30230000 / 53735682 Loss: 1.497261544401185\n",
      "Epoch: 0 Sample: 30240000 / 53735682 Loss: 1.6115401818692738\n",
      "Epoch: 0 Sample: 30250000 / 53735682 Loss: 1.416376029417769\n",
      "Epoch: 0 Sample: 30260000 / 53735682 Loss: 1.5375898037444604\n",
      "Epoch: 0 Sample: 30270000 / 53735682 Loss: 1.495423615941038\n",
      "Epoch: 0 Sample: 30280000 / 53735682 Loss: 1.5129422424239416\n",
      "Epoch: 0 Sample: 30290000 / 53735682 Loss: 1.4644353747072132\n",
      "Epoch: 0 Sample: 30300000 / 53735682 Loss: 1.5191091211686008\n",
      "Epoch: 0 Sample: 30310000 / 53735682 Loss: 1.4751625500614098\n",
      "Epoch: 0 Sample: 30320000 / 53735682 Loss: 1.4375829787503394\n",
      "Epoch: 0 Sample: 30330000 / 53735682 Loss: 1.482900637085626\n",
      "Epoch: 0 Sample: 30340000 / 53735682 Loss: 1.4638732346496655\n",
      "Epoch: 0 Sample: 30350000 / 53735682 Loss: 1.46690284572344\n",
      "Epoch: 0 Sample: 30360000 / 53735682 Loss: 1.4983275948616297\n",
      "Epoch: 0 Sample: 30370000 / 53735682 Loss: 1.5425563640284232\n",
      "Epoch: 0 Sample: 30380000 / 53735682 Loss: 1.4737496792555502\n",
      "Epoch: 0 Sample: 30390000 / 53735682 Loss: 1.4554382556683976\n",
      "Epoch: 0 Sample: 30400000 / 53735682 Loss: 1.5146539546971527\n",
      "Epoch: 0 Sample: 30410000 / 53735682 Loss: 1.5031603979221497\n",
      "Epoch: 0 Sample: 30420000 / 53735682 Loss: 1.4812570559612688\n",
      "Epoch: 0 Sample: 30430000 / 53735682 Loss: 1.543358297249494\n",
      "Epoch: 0 Sample: 30440000 / 53735682 Loss: 1.4904654690993822\n",
      "Epoch: 0 Sample: 30450000 / 53735682 Loss: 1.5076801890296783\n",
      "Epoch: 0 Sample: 30460000 / 53735682 Loss: 1.541125924723067\n",
      "Epoch: 0 Sample: 30470000 / 53735682 Loss: 1.4532137204732598\n",
      "Epoch: 0 Sample: 30480000 / 53735682 Loss: 1.4925385347943776\n",
      "Epoch: 0 Sample: 30490000 / 53735682 Loss: 1.492523823088583\n",
      "Epoch: 0 Sample: 30500000 / 53735682 Loss: 1.5359873733579539\n",
      "Epoch: 0 Sample: 30510000 / 53735682 Loss: 1.4702125475928298\n",
      "Epoch: 0 Sample: 30520000 / 53735682 Loss: 1.434328664045982\n",
      "Epoch: 0 Sample: 30530000 / 53735682 Loss: 1.4890150534138207\n",
      "Epoch: 0 Sample: 30540000 / 53735682 Loss: 1.454616448052867\n",
      "Epoch: 0 Sample: 30550000 / 53735682 Loss: 1.5150647260898915\n",
      "Epoch: 0 Sample: 30560000 / 53735682 Loss: 1.496107973523349\n",
      "Epoch: 0 Sample: 30570000 / 53735682 Loss: 1.5050742664701302\n",
      "Epoch: 0 Sample: 30580000 / 53735682 Loss: 1.4191721332991687\n",
      "Epoch: 0 Sample: 30590000 / 53735682 Loss: 1.4573009176164289\n",
      "Epoch: 0 Sample: 30600000 / 53735682 Loss: 1.6131504991938606\n",
      "Epoch: 0 Sample: 30610000 / 53735682 Loss: 1.5382749501541348\n",
      "Epoch: 0 Sample: 30620000 / 53735682 Loss: 1.4822444067060854\n",
      "Epoch: 0 Sample: 30630000 / 53735682 Loss: 1.582044425735278\n",
      "Epoch: 0 Sample: 30640000 / 53735682 Loss: 1.460989339224581\n",
      "Epoch: 0 Sample: 30650000 / 53735682 Loss: 1.4900497548392149\n",
      "Epoch: 0 Sample: 30660000 / 53735682 Loss: 1.5469693463538856\n",
      "Epoch: 0 Sample: 30670000 / 53735682 Loss: 1.4537387468161982\n",
      "Epoch: 0 Sample: 30680000 / 53735682 Loss: 1.4679729140223965\n",
      "Epoch: 0 Sample: 30690000 / 53735682 Loss: 1.4810262670802725\n",
      "Epoch: 0 Sample: 30700000 / 53735682 Loss: 1.4475483037865666\n",
      "Epoch: 0 Sample: 30710000 / 53735682 Loss: 1.4949371720196476\n",
      "Epoch: 0 Sample: 30720000 / 53735682 Loss: 1.4128449687457385\n",
      "Epoch: 0 Sample: 30730000 / 53735682 Loss: 1.6074114696603563\n",
      "Epoch: 0 Sample: 30740000 / 53735682 Loss: 1.5079321196547042\n",
      "Epoch: 0 Sample: 30750000 / 53735682 Loss: 1.5363326095973888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 30760000 / 53735682 Loss: 1.5097963768268539\n",
      "Epoch: 0 Sample: 30770000 / 53735682 Loss: 1.5396856995777979\n",
      "Epoch: 0 Sample: 30780000 / 53735682 Loss: 1.5266512135850228\n",
      "Epoch: 0 Sample: 30790000 / 53735682 Loss: 1.530277901542356\n",
      "Epoch: 0 Sample: 30800000 / 53735682 Loss: 1.457034542693373\n",
      "Epoch: 0 Sample: 30810000 / 53735682 Loss: 1.506185317306893\n",
      "Epoch: 0 Sample: 30820000 / 53735682 Loss: 1.5279426605493658\n",
      "Epoch: 0 Sample: 30830000 / 53735682 Loss: 1.5277989733875816\n",
      "Epoch: 0 Sample: 30840000 / 53735682 Loss: 1.4392547300399725\n",
      "Epoch: 0 Sample: 30850000 / 53735682 Loss: 1.4899977748293471\n",
      "Epoch: 0 Sample: 30860000 / 53735682 Loss: 1.5010707687609157\n",
      "Epoch: 0 Sample: 30870000 / 53735682 Loss: 1.3891822643105312\n",
      "Epoch: 0 Sample: 30880000 / 53735682 Loss: 1.4789370739311773\n",
      "Epoch: 0 Sample: 30890000 / 53735682 Loss: 1.4643219029060923\n",
      "Epoch: 0 Sample: 30900000 / 53735682 Loss: 1.4529871739473426\n",
      "Epoch: 0 Sample: 30910000 / 53735682 Loss: 1.4544830572550445\n",
      "Epoch: 0 Sample: 30920000 / 53735682 Loss: 1.5627272490090602\n",
      "Epoch: 0 Sample: 30930000 / 53735682 Loss: 1.452358566433667\n",
      "Epoch: 0 Sample: 30940000 / 53735682 Loss: 1.4995117932477617\n",
      "Epoch: 0 Sample: 30950000 / 53735682 Loss: 1.4572949327246854\n",
      "Epoch: 0 Sample: 30960000 / 53735682 Loss: 1.4495452334373902\n",
      "Epoch: 0 Sample: 30970000 / 53735682 Loss: 1.515023952262123\n",
      "Epoch: 0 Sample: 30980000 / 53735682 Loss: 1.5265651604887833\n",
      "Epoch: 0 Sample: 30990000 / 53735682 Loss: 1.4640322768872756\n",
      "Epoch: 0 Sample: 31000000 / 53735682 Loss: 1.4935132141601581\n",
      "Epoch: 0 Sample: 31010000 / 53735682 Loss: 1.4996531851163248\n",
      "Epoch: 0 Sample: 31020000 / 53735682 Loss: 1.4597304396820872\n",
      "Epoch: 0 Sample: 31030000 / 53735682 Loss: 1.5673363697807197\n",
      "Epoch: 0 Sample: 31040000 / 53735682 Loss: 1.5018826882637462\n",
      "Epoch: 0 Sample: 31050000 / 53735682 Loss: 1.5357792268259445\n",
      "Epoch: 0 Sample: 31060000 / 53735682 Loss: 1.5847843712042526\n",
      "Epoch: 0 Sample: 31070000 / 53735682 Loss: 1.4474164681079758\n",
      "Epoch: 0 Sample: 31080000 / 53735682 Loss: 1.5015844085013172\n",
      "Epoch: 0 Sample: 31090000 / 53735682 Loss: 1.5816682937839948\n",
      "Epoch: 0 Sample: 31100000 / 53735682 Loss: 1.4892360876873156\n",
      "Epoch: 0 Sample: 31110000 / 53735682 Loss: 1.4868320222074827\n",
      "Epoch: 0 Sample: 31120000 / 53735682 Loss: 1.5582201404898433\n",
      "Epoch: 0 Sample: 31130000 / 53735682 Loss: 1.4926654354994162\n",
      "Epoch: 0 Sample: 31140000 / 53735682 Loss: 1.3933042268628837\n",
      "Epoch: 0 Sample: 31150000 / 53735682 Loss: 1.476725101444269\n",
      "Epoch: 0 Sample: 31160000 / 53735682 Loss: 1.4958350802753804\n",
      "Epoch: 0 Sample: 31170000 / 53735682 Loss: 1.4221239410728534\n",
      "Epoch: 0 Sample: 31180000 / 53735682 Loss: 1.4577763081331914\n",
      "Epoch: 0 Sample: 31190000 / 53735682 Loss: 1.416429459560653\n",
      "Epoch: 0 Sample: 31200000 / 53735682 Loss: 1.5176026268900369\n",
      "Epoch: 0 Sample: 31210000 / 53735682 Loss: 1.523346521899927\n",
      "Epoch: 0 Sample: 31220000 / 53735682 Loss: 1.6181472565065862\n",
      "Epoch: 0 Sample: 31230000 / 53735682 Loss: 1.4927375142589803\n",
      "Epoch: 0 Sample: 31240000 / 53735682 Loss: 1.413773671037809\n",
      "Epoch: 0 Sample: 31250000 / 53735682 Loss: 1.5816615034974095\n",
      "Epoch: 0 Sample: 31260000 / 53735682 Loss: 1.4817608656218004\n",
      "Epoch: 0 Sample: 31270000 / 53735682 Loss: 1.4675904732507943\n",
      "Epoch: 0 Sample: 31280000 / 53735682 Loss: 1.4342155601931632\n",
      "Epoch: 0 Sample: 31290000 / 53735682 Loss: 1.422776446169522\n",
      "Epoch: 0 Sample: 31300000 / 53735682 Loss: 1.4239326782358552\n",
      "Epoch: 0 Sample: 31310000 / 53735682 Loss: 1.518380966517816\n",
      "Epoch: 0 Sample: 31320000 / 53735682 Loss: 1.5490427579970285\n",
      "Epoch: 0 Sample: 31330000 / 53735682 Loss: 1.5103282320678653\n",
      "Epoch: 0 Sample: 31340000 / 53735682 Loss: 1.4909948157944934\n",
      "Epoch: 0 Sample: 31350000 / 53735682 Loss: 1.4452911220490159\n",
      "Epoch: 0 Sample: 31360000 / 53735682 Loss: 1.522565973724145\n",
      "Epoch: 0 Sample: 31370000 / 53735682 Loss: 1.5179732719884615\n",
      "Epoch: 0 Sample: 31380000 / 53735682 Loss: 1.4378866492232838\n",
      "Epoch: 0 Sample: 31390000 / 53735682 Loss: 1.4880759405183877\n",
      "Epoch: 0 Sample: 31400000 / 53735682 Loss: 1.4710893303875525\n",
      "Epoch: 0 Sample: 31410000 / 53735682 Loss: 1.4798178214062288\n",
      "Epoch: 0 Sample: 31420000 / 53735682 Loss: 1.5410923989237757\n",
      "Epoch: 0 Sample: 31430000 / 53735682 Loss: 1.5177327055872463\n",
      "Epoch: 0 Sample: 31440000 / 53735682 Loss: 1.458607498159222\n",
      "Epoch: 0 Sample: 31450000 / 53735682 Loss: 1.5592052622516206\n",
      "Epoch: 0 Sample: 31460000 / 53735682 Loss: 1.4769374254594678\n",
      "Epoch: 0 Sample: 31470000 / 53735682 Loss: 1.5174852359536208\n",
      "Epoch: 0 Sample: 31480000 / 53735682 Loss: 1.4513717812008762\n",
      "Epoch: 0 Sample: 31490000 / 53735682 Loss: 1.4799800522117863\n",
      "Epoch: 0 Sample: 31500000 / 53735682 Loss: 1.4647460201263574\n",
      "Epoch: 0 Sample: 31510000 / 53735682 Loss: 1.5281542960178136\n",
      "Epoch: 0 Sample: 31520000 / 53735682 Loss: 1.535612966858918\n",
      "Epoch: 0 Sample: 31530000 / 53735682 Loss: 1.4956816340412509\n",
      "Epoch: 0 Sample: 31540000 / 53735682 Loss: 1.4777298134518921\n",
      "Epoch: 0 Sample: 31550000 / 53735682 Loss: 1.4474635739255772\n",
      "Epoch: 0 Sample: 31560000 / 53735682 Loss: 1.5145701210973441\n",
      "Epoch: 0 Sample: 31570000 / 53735682 Loss: 1.4918496502019385\n",
      "Epoch: 0 Sample: 31580000 / 53735682 Loss: 1.531214824855465\n",
      "Epoch: 0 Sample: 31590000 / 53735682 Loss: 1.5396017993241269\n",
      "Epoch: 0 Sample: 31600000 / 53735682 Loss: 1.5589313823996462\n",
      "Epoch: 0 Sample: 31610000 / 53735682 Loss: 1.562684125769752\n",
      "Epoch: 0 Sample: 31620000 / 53735682 Loss: 1.4768708826553758\n",
      "Epoch: 0 Sample: 31630000 / 53735682 Loss: 1.4588857839333824\n",
      "Epoch: 0 Sample: 31640000 / 53735682 Loss: 1.594261554874345\n",
      "Epoch: 0 Sample: 31650000 / 53735682 Loss: 1.4309340732034586\n",
      "Epoch: 0 Sample: 31660000 / 53735682 Loss: 1.5086723564463744\n",
      "Epoch: 0 Sample: 31670000 / 53735682 Loss: 1.4887751698288496\n",
      "Epoch: 0 Sample: 31680000 / 53735682 Loss: 1.5368892826347378\n",
      "Epoch: 0 Sample: 31690000 / 53735682 Loss: 1.444722958839113\n",
      "Epoch: 0 Sample: 31700000 / 53735682 Loss: 1.4475001199220663\n",
      "Epoch: 0 Sample: 31710000 / 53735682 Loss: 1.4437465781196321\n",
      "Epoch: 0 Sample: 31720000 / 53735682 Loss: 1.540457768837211\n",
      "Epoch: 0 Sample: 31730000 / 53735682 Loss: 1.4450297132338146\n",
      "Epoch: 0 Sample: 31740000 / 53735682 Loss: 1.4580436023346002\n",
      "Epoch: 0 Sample: 31750000 / 53735682 Loss: 1.5128196531258598\n",
      "Epoch: 0 Sample: 31760000 / 53735682 Loss: 1.488666492347002\n",
      "Epoch: 0 Sample: 31770000 / 53735682 Loss: 1.5293633606401809\n",
      "Epoch: 0 Sample: 31780000 / 53735682 Loss: 1.4850039900219738\n",
      "Epoch: 0 Sample: 31790000 / 53735682 Loss: 1.4024646305963977\n",
      "Epoch: 0 Sample: 31800000 / 53735682 Loss: 1.5454610989971012\n",
      "Epoch: 0 Sample: 31810000 / 53735682 Loss: 1.5013140035052845\n",
      "Epoch: 0 Sample: 31820000 / 53735682 Loss: 1.519308637125201\n",
      "Epoch: 0 Sample: 31830000 / 53735682 Loss: 1.490258061824473\n",
      "Epoch: 0 Sample: 31840000 / 53735682 Loss: 1.475928077623819\n",
      "Epoch: 0 Sample: 31850000 / 53735682 Loss: 1.489532622934203\n",
      "Epoch: 0 Sample: 31860000 / 53735682 Loss: 1.4556888459120183\n",
      "Epoch: 0 Sample: 31870000 / 53735682 Loss: 1.5348874384990656\n",
      "Epoch: 0 Sample: 31880000 / 53735682 Loss: 1.4818458712595088\n",
      "Epoch: 0 Sample: 31890000 / 53735682 Loss: 1.5458368805517155\n",
      "Epoch: 0 Sample: 31900000 / 53735682 Loss: 1.5515228434279411\n",
      "Epoch: 0 Sample: 31910000 / 53735682 Loss: 1.479510157834235\n",
      "Epoch: 0 Sample: 31920000 / 53735682 Loss: 1.4660826171118757\n",
      "Epoch: 0 Sample: 31930000 / 53735682 Loss: 1.3893853877344053\n",
      "Epoch: 0 Sample: 31940000 / 53735682 Loss: 1.4834024735180515\n",
      "Epoch: 0 Sample: 31950000 / 53735682 Loss: 1.5869239637504269\n",
      "Epoch: 0 Sample: 31960000 / 53735682 Loss: 1.4525428677658707\n",
      "Epoch: 0 Sample: 31970000 / 53735682 Loss: 1.5617015269645615\n",
      "Epoch: 0 Sample: 31980000 / 53735682 Loss: 1.4411808084744893\n",
      "Epoch: 0 Sample: 31990000 / 53735682 Loss: 1.4684255920338072\n",
      "Epoch: 0 Sample: 32000000 / 53735682 Loss: 1.5822941325997713\n",
      "Epoch: 0 Sample: 32010000 / 53735682 Loss: 1.455566232164952\n",
      "Epoch: 0 Sample: 32020000 / 53735682 Loss: 1.458409226999173\n",
      "Epoch: 0 Sample: 32030000 / 53735682 Loss: 1.4781393596803474\n",
      "Epoch: 0 Sample: 32040000 / 53735682 Loss: 1.5374559857592418\n",
      "Epoch: 0 Sample: 32050000 / 53735682 Loss: 1.555366328425444\n",
      "Epoch: 0 Sample: 32060000 / 53735682 Loss: 1.4111577646744637\n",
      "Epoch: 0 Sample: 32070000 / 53735682 Loss: 1.475880842083898\n",
      "Epoch: 0 Sample: 32080000 / 53735682 Loss: 1.5213479715038472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 32090000 / 53735682 Loss: 1.4860264299831902\n",
      "Epoch: 0 Sample: 32100000 / 53735682 Loss: 1.513263186470672\n",
      "Epoch: 0 Sample: 32110000 / 53735682 Loss: 1.4707008159164725\n",
      "Epoch: 0 Sample: 32120000 / 53735682 Loss: 1.4549988036909316\n",
      "Epoch: 0 Sample: 32130000 / 53735682 Loss: 1.4092845707982171\n",
      "Epoch: 0 Sample: 32140000 / 53735682 Loss: 1.5088038699371196\n",
      "Epoch: 0 Sample: 32150000 / 53735682 Loss: 1.5065778383725572\n",
      "Epoch: 0 Sample: 32160000 / 53735682 Loss: 1.5116904357668095\n",
      "Epoch: 0 Sample: 32170000 / 53735682 Loss: 1.4219687791853954\n",
      "Epoch: 0 Sample: 32180000 / 53735682 Loss: 1.5535609699329989\n",
      "Epoch: 0 Sample: 32190000 / 53735682 Loss: 1.4941410374312127\n",
      "Epoch: 0 Sample: 32200000 / 53735682 Loss: 1.5376093990556778\n",
      "Epoch: 0 Sample: 32210000 / 53735682 Loss: 1.4621069562401487\n",
      "Epoch: 0 Sample: 32220000 / 53735682 Loss: 1.4696161936632044\n",
      "Epoch: 0 Sample: 32230000 / 53735682 Loss: 1.524524511700033\n",
      "Epoch: 0 Sample: 32240000 / 53735682 Loss: 1.5525874613094766\n",
      "Epoch: 0 Sample: 32250000 / 53735682 Loss: 1.5071564063595084\n",
      "Epoch: 0 Sample: 32260000 / 53735682 Loss: 1.5652925473797155\n",
      "Epoch: 0 Sample: 32270000 / 53735682 Loss: 1.4726248781955886\n",
      "Epoch: 0 Sample: 32280000 / 53735682 Loss: 1.5118978262553222\n",
      "Epoch: 0 Sample: 32290000 / 53735682 Loss: 1.5387661825434213\n",
      "Epoch: 0 Sample: 32300000 / 53735682 Loss: 1.4672558678924066\n",
      "Epoch: 0 Sample: 32310000 / 53735682 Loss: 1.4020799523849439\n",
      "Epoch: 0 Sample: 32320000 / 53735682 Loss: 1.5090168145378215\n",
      "Epoch: 0 Sample: 32330000 / 53735682 Loss: 1.5381922468635967\n",
      "Epoch: 0 Sample: 32340000 / 53735682 Loss: 1.4379178502415955\n",
      "Epoch: 0 Sample: 32350000 / 53735682 Loss: 1.467234030440184\n",
      "Epoch: 0 Sample: 32360000 / 53735682 Loss: 1.5394987268968778\n",
      "Epoch: 0 Sample: 32370000 / 53735682 Loss: 1.4983522496165256\n",
      "Epoch: 0 Sample: 32380000 / 53735682 Loss: 1.6176891917791858\n",
      "Epoch: 0 Sample: 32390000 / 53735682 Loss: 1.4138373363611034\n",
      "Epoch: 0 Sample: 32400000 / 53735682 Loss: 1.516776373045174\n",
      "Epoch: 0 Sample: 32410000 / 53735682 Loss: 1.5737080537525232\n",
      "Epoch: 0 Sample: 32420000 / 53735682 Loss: 1.4789918596798288\n",
      "Epoch: 0 Sample: 32430000 / 53735682 Loss: 1.5351511352259848\n",
      "Epoch: 0 Sample: 32440000 / 53735682 Loss: 1.5522783044065465\n",
      "Epoch: 0 Sample: 32450000 / 53735682 Loss: 1.4864555256751673\n",
      "Epoch: 0 Sample: 32460000 / 53735682 Loss: 1.5039602442658744\n",
      "Epoch: 0 Sample: 32470000 / 53735682 Loss: 1.4747740332057606\n",
      "Epoch: 0 Sample: 32480000 / 53735682 Loss: 1.496762371552987\n",
      "Epoch: 0 Sample: 32490000 / 53735682 Loss: 1.4080445699257935\n",
      "Epoch: 0 Sample: 32500000 / 53735682 Loss: 1.4657645403113342\n",
      "Epoch: 0 Sample: 32510000 / 53735682 Loss: 1.5787311742718566\n",
      "Epoch: 0 Sample: 32520000 / 53735682 Loss: 1.5071000324468593\n",
      "Epoch: 0 Sample: 32530000 / 53735682 Loss: 1.5900452833266412\n",
      "Epoch: 0 Sample: 32540000 / 53735682 Loss: 1.5563194681292505\n",
      "Epoch: 0 Sample: 32550000 / 53735682 Loss: 1.540712025712585\n",
      "Epoch: 0 Sample: 32560000 / 53735682 Loss: 1.4680354492110985\n",
      "Epoch: 0 Sample: 32570000 / 53735682 Loss: 1.5339744532881385\n",
      "Epoch: 0 Sample: 32580000 / 53735682 Loss: 1.4872187246206483\n",
      "Epoch: 0 Sample: 32590000 / 53735682 Loss: 1.5033367073103838\n",
      "Epoch: 0 Sample: 32600000 / 53735682 Loss: 1.4439450402819138\n",
      "Epoch: 0 Sample: 32610000 / 53735682 Loss: 1.6335166579859988\n",
      "Epoch: 0 Sample: 32620000 / 53735682 Loss: 1.4909579559914996\n",
      "Epoch: 0 Sample: 32630000 / 53735682 Loss: 1.6294409188838435\n",
      "Epoch: 0 Sample: 32640000 / 53735682 Loss: 1.5892161662497983\n",
      "Epoch: 0 Sample: 32650000 / 53735682 Loss: 1.4028760462214576\n",
      "Epoch: 0 Sample: 32660000 / 53735682 Loss: 1.505686018424021\n",
      "Epoch: 0 Sample: 32670000 / 53735682 Loss: 1.5069441153894156\n",
      "Epoch: 0 Sample: 32680000 / 53735682 Loss: 1.5312968095754254\n",
      "Epoch: 0 Sample: 32690000 / 53735682 Loss: 1.487337917368127\n",
      "Epoch: 0 Sample: 32700000 / 53735682 Loss: 1.530083760618992\n",
      "Epoch: 0 Sample: 32710000 / 53735682 Loss: 1.504487800537118\n",
      "Epoch: 0 Sample: 32720000 / 53735682 Loss: 1.5200194556266742\n",
      "Epoch: 0 Sample: 32730000 / 53735682 Loss: 1.4869122054595407\n",
      "Epoch: 0 Sample: 32740000 / 53735682 Loss: 1.4907421383865493\n",
      "Epoch: 0 Sample: 32750000 / 53735682 Loss: 1.5509058096085442\n",
      "Epoch: 0 Sample: 32760000 / 53735682 Loss: 1.495807541549243\n",
      "Epoch: 0 Sample: 32770000 / 53735682 Loss: 1.584571995182892\n",
      "Epoch: 0 Sample: 32780000 / 53735682 Loss: 1.495775825057526\n",
      "Epoch: 0 Sample: 32790000 / 53735682 Loss: 1.5230155561596608\n",
      "Epoch: 0 Sample: 32800000 / 53735682 Loss: 1.5273173141373495\n",
      "Epoch: 0 Sample: 32810000 / 53735682 Loss: 1.5580606419891774\n",
      "Epoch: 0 Sample: 32820000 / 53735682 Loss: 1.4297231737906404\n",
      "Epoch: 0 Sample: 32830000 / 53735682 Loss: 1.488742590351023\n",
      "Epoch: 0 Sample: 32840000 / 53735682 Loss: 1.4476234531561774\n",
      "Epoch: 0 Sample: 32850000 / 53735682 Loss: 1.4967826595976843\n",
      "Epoch: 0 Sample: 32860000 / 53735682 Loss: 1.5570485675642822\n",
      "Epoch: 0 Sample: 32870000 / 53735682 Loss: 1.520404619462167\n",
      "Epoch: 0 Sample: 32880000 / 53735682 Loss: 1.4991967582024008\n",
      "Epoch: 0 Sample: 32890000 / 53735682 Loss: 1.4666918691401687\n",
      "Epoch: 0 Sample: 32900000 / 53735682 Loss: 1.4816582012305344\n",
      "Epoch: 0 Sample: 32910000 / 53735682 Loss: 1.4235211175634477\n",
      "Epoch: 0 Sample: 32920000 / 53735682 Loss: 1.414556548303886\n",
      "Epoch: 0 Sample: 32930000 / 53735682 Loss: 1.4763241072783193\n",
      "Epoch: 0 Sample: 32940000 / 53735682 Loss: 1.4273437822718336\n",
      "Epoch: 0 Sample: 32950000 / 53735682 Loss: 1.4051367567737119\n",
      "Epoch: 0 Sample: 32960000 / 53735682 Loss: 1.4596212055127917\n",
      "Epoch: 0 Sample: 32970000 / 53735682 Loss: 1.4982274738036745\n",
      "Epoch: 0 Sample: 32980000 / 53735682 Loss: 1.4456025471572382\n",
      "Epoch: 0 Sample: 32990000 / 53735682 Loss: 1.4767305293334545\n",
      "Epoch: 0 Sample: 33000000 / 53735682 Loss: 1.5250242441818567\n",
      "Epoch: 0 Sample: 33010000 / 53735682 Loss: 1.5459156687928073\n",
      "Epoch: 0 Sample: 33020000 / 53735682 Loss: 1.5731105048645049\n",
      "Epoch: 0 Sample: 33030000 / 53735682 Loss: 1.4888789141864311\n",
      "Epoch: 0 Sample: 33040000 / 53735682 Loss: 1.4731452739679178\n",
      "Epoch: 0 Sample: 33050000 / 53735682 Loss: 1.55756336310978\n",
      "Epoch: 0 Sample: 33060000 / 53735682 Loss: 1.5967325743366874\n",
      "Epoch: 0 Sample: 33070000 / 53735682 Loss: 1.5290423588969004\n",
      "Epoch: 0 Sample: 33080000 / 53735682 Loss: 1.4538456777150732\n",
      "Epoch: 0 Sample: 33090000 / 53735682 Loss: 1.5466075433625406\n",
      "Epoch: 0 Sample: 33100000 / 53735682 Loss: 1.5041007479081812\n",
      "Epoch: 0 Sample: 33110000 / 53735682 Loss: 1.5369519933837439\n",
      "Epoch: 0 Sample: 33120000 / 53735682 Loss: 1.4849235120141024\n",
      "Epoch: 0 Sample: 33130000 / 53735682 Loss: 1.5198502769866362\n",
      "Epoch: 0 Sample: 33140000 / 53735682 Loss: 1.4781157647088286\n",
      "Epoch: 0 Sample: 33150000 / 53735682 Loss: 1.3824781336713075\n",
      "Epoch: 0 Sample: 33160000 / 53735682 Loss: 1.5872184952037622\n",
      "Epoch: 0 Sample: 33170000 / 53735682 Loss: 1.5118303430662325\n",
      "Epoch: 0 Sample: 33180000 / 53735682 Loss: 1.5015250655024983\n",
      "Epoch: 0 Sample: 33190000 / 53735682 Loss: 1.4889138686683159\n",
      "Epoch: 0 Sample: 33200000 / 53735682 Loss: 1.5306458350232086\n",
      "Epoch: 0 Sample: 33210000 / 53735682 Loss: 1.5301725339512773\n",
      "Epoch: 0 Sample: 33220000 / 53735682 Loss: 1.448299710022397\n",
      "Epoch: 0 Sample: 33230000 / 53735682 Loss: 1.469654861904867\n",
      "Epoch: 0 Sample: 33240000 / 53735682 Loss: 1.4581812591830738\n",
      "Epoch: 0 Sample: 33250000 / 53735682 Loss: 1.4975956728327946\n",
      "Epoch: 0 Sample: 33260000 / 53735682 Loss: 1.4674803216626837\n",
      "Epoch: 0 Sample: 33270000 / 53735682 Loss: 1.4642514591377422\n",
      "Epoch: 0 Sample: 33280000 / 53735682 Loss: 1.459915876245565\n",
      "Epoch: 0 Sample: 33290000 / 53735682 Loss: 1.416844762387535\n",
      "Epoch: 0 Sample: 33300000 / 53735682 Loss: 1.472846639456206\n",
      "Epoch: 0 Sample: 33310000 / 53735682 Loss: 1.3893050991278588\n",
      "Epoch: 0 Sample: 33320000 / 53735682 Loss: 1.5692548964269954\n",
      "Epoch: 0 Sample: 33330000 / 53735682 Loss: 1.459296007772292\n",
      "Epoch: 0 Sample: 33340000 / 53735682 Loss: 1.554521069493083\n",
      "Epoch: 0 Sample: 33350000 / 53735682 Loss: 1.4803776137861824\n",
      "Epoch: 0 Sample: 33360000 / 53735682 Loss: 1.456221488197035\n",
      "Epoch: 0 Sample: 33370000 / 53735682 Loss: 1.4267432701891787\n",
      "Epoch: 0 Sample: 33380000 / 53735682 Loss: 1.4831192951764764\n",
      "Epoch: 0 Sample: 33390000 / 53735682 Loss: 1.5131678598766993\n",
      "Epoch: 0 Sample: 33400000 / 53735682 Loss: 1.5053799976647053\n",
      "Epoch: 0 Sample: 33410000 / 53735682 Loss: 1.4959196794829996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 33420000 / 53735682 Loss: 1.5503030227268537\n",
      "Epoch: 0 Sample: 33430000 / 53735682 Loss: 1.5175696304870288\n",
      "Epoch: 0 Sample: 33440000 / 53735682 Loss: 1.504341788517614\n",
      "Epoch: 0 Sample: 33450000 / 53735682 Loss: 1.477731729724319\n",
      "Epoch: 0 Sample: 33460000 / 53735682 Loss: 1.48367939697092\n",
      "Epoch: 0 Sample: 33470000 / 53735682 Loss: 1.5041545198288107\n",
      "Epoch: 0 Sample: 33480000 / 53735682 Loss: 1.543275191720076\n",
      "Epoch: 0 Sample: 33490000 / 53735682 Loss: 1.455868194218581\n",
      "Epoch: 0 Sample: 33500000 / 53735682 Loss: 1.5056800731072857\n",
      "Epoch: 0 Sample: 33510000 / 53735682 Loss: 1.4724333403356389\n",
      "Epoch: 0 Sample: 33520000 / 53735682 Loss: 1.5262937898040385\n",
      "Epoch: 0 Sample: 33530000 / 53735682 Loss: 1.4648706707359969\n",
      "Epoch: 0 Sample: 33540000 / 53735682 Loss: 1.460307726394491\n",
      "Epoch: 0 Sample: 33550000 / 53735682 Loss: 1.4533289806447351\n",
      "Epoch: 0 Sample: 33560000 / 53735682 Loss: 1.4321347668422157\n",
      "Epoch: 0 Sample: 33570000 / 53735682 Loss: 1.496207923445843\n",
      "Epoch: 0 Sample: 33580000 / 53735682 Loss: 1.4295679358917792\n",
      "Epoch: 0 Sample: 33590000 / 53735682 Loss: 1.472578152590597\n",
      "Epoch: 0 Sample: 33600000 / 53735682 Loss: 1.3559663751792166\n",
      "Epoch: 0 Sample: 33610000 / 53735682 Loss: 1.4335601348291431\n",
      "Epoch: 0 Sample: 33620000 / 53735682 Loss: 1.4512365025118834\n",
      "Epoch: 0 Sample: 33630000 / 53735682 Loss: 1.5249565323629053\n",
      "Epoch: 0 Sample: 33640000 / 53735682 Loss: 1.4646638971766501\n",
      "Epoch: 0 Sample: 33650000 / 53735682 Loss: 1.4817659007621153\n",
      "Epoch: 0 Sample: 33660000 / 53735682 Loss: 1.4693507254774305\n",
      "Epoch: 0 Sample: 33670000 / 53735682 Loss: 1.5155676943468817\n",
      "Epoch: 0 Sample: 33680000 / 53735682 Loss: 1.5365400588805398\n",
      "Epoch: 0 Sample: 33690000 / 53735682 Loss: 1.3880487703108986\n",
      "Epoch: 0 Sample: 33700000 / 53735682 Loss: 1.5428035568170995\n",
      "Epoch: 0 Sample: 33710000 / 53735682 Loss: 1.513934430782034\n",
      "Epoch: 0 Sample: 33720000 / 53735682 Loss: 1.4665380044180938\n",
      "Epoch: 0 Sample: 33730000 / 53735682 Loss: 1.4751325650066651\n",
      "Epoch: 0 Sample: 33740000 / 53735682 Loss: 1.500166349700087\n",
      "Epoch: 0 Sample: 33750000 / 53735682 Loss: 1.5598375568362615\n",
      "Epoch: 0 Sample: 33760000 / 53735682 Loss: 1.4769584621438971\n",
      "Epoch: 0 Sample: 33770000 / 53735682 Loss: 1.50592800003007\n",
      "Epoch: 0 Sample: 33780000 / 53735682 Loss: 1.4534578904817292\n",
      "Epoch: 0 Sample: 33790000 / 53735682 Loss: 1.5012752033360255\n",
      "Epoch: 0 Sample: 33800000 / 53735682 Loss: 1.4801876406192958\n",
      "Epoch: 0 Sample: 33810000 / 53735682 Loss: 1.4215061827903168\n",
      "Epoch: 0 Sample: 33820000 / 53735682 Loss: 1.4761278278537993\n",
      "Epoch: 0 Sample: 33830000 / 53735682 Loss: 1.4722087661122707\n",
      "Epoch: 0 Sample: 33840000 / 53735682 Loss: 1.4996345968803784\n",
      "Epoch: 0 Sample: 33850000 / 53735682 Loss: 1.5081529790532135\n",
      "Epoch: 0 Sample: 33860000 / 53735682 Loss: 1.4839159201604435\n",
      "Epoch: 0 Sample: 33870000 / 53735682 Loss: 1.472644054722521\n",
      "Epoch: 0 Sample: 33880000 / 53735682 Loss: 1.5191730995157604\n",
      "Epoch: 0 Sample: 33890000 / 53735682 Loss: 1.4800540455595685\n",
      "Epoch: 0 Sample: 33900000 / 53735682 Loss: 1.496880660930922\n",
      "Epoch: 0 Sample: 33910000 / 53735682 Loss: 1.4828979605798578\n",
      "Epoch: 0 Sample: 33920000 / 53735682 Loss: 1.5014425240031106\n",
      "Epoch: 0 Sample: 33930000 / 53735682 Loss: 1.4877287738637668\n",
      "Epoch: 0 Sample: 33940000 / 53735682 Loss: 1.495608844764923\n",
      "Epoch: 0 Sample: 33950000 / 53735682 Loss: 1.4816788106775869\n",
      "Epoch: 0 Sample: 33960000 / 53735682 Loss: 1.523800365892724\n",
      "Epoch: 0 Sample: 33970000 / 53735682 Loss: 1.523169009584078\n",
      "Epoch: 0 Sample: 33980000 / 53735682 Loss: 1.4821521750020483\n",
      "Epoch: 0 Sample: 33990000 / 53735682 Loss: 1.499659617509035\n",
      "Epoch: 0 Sample: 34000000 / 53735682 Loss: 1.5167331622066855\n",
      "Epoch: 0 Sample: 34010000 / 53735682 Loss: 1.504777190689095\n",
      "Epoch: 0 Sample: 34020000 / 53735682 Loss: 1.3866107252188227\n",
      "Epoch: 0 Sample: 34030000 / 53735682 Loss: 1.5475392208794578\n",
      "Epoch: 0 Sample: 34040000 / 53735682 Loss: 1.520294518127144\n",
      "Epoch: 0 Sample: 34050000 / 53735682 Loss: 1.4048522619977224\n",
      "Epoch: 0 Sample: 34060000 / 53735682 Loss: 1.431316545240171\n",
      "Epoch: 0 Sample: 34070000 / 53735682 Loss: 1.4009860268192966\n",
      "Epoch: 0 Sample: 34080000 / 53735682 Loss: 1.4619953463918711\n",
      "Epoch: 0 Sample: 34090000 / 53735682 Loss: 1.511138260371706\n",
      "Epoch: 0 Sample: 34100000 / 53735682 Loss: 1.510924109781837\n",
      "Epoch: 0 Sample: 34110000 / 53735682 Loss: 1.5177594093358537\n",
      "Epoch: 0 Sample: 34120000 / 53735682 Loss: 1.5019130445176683\n",
      "Epoch: 0 Sample: 34130000 / 53735682 Loss: 1.4040106574207034\n",
      "Epoch: 0 Sample: 34140000 / 53735682 Loss: 1.4890982754039794\n",
      "Epoch: 0 Sample: 34150000 / 53735682 Loss: 1.5016692341185078\n",
      "Epoch: 0 Sample: 34160000 / 53735682 Loss: 1.4646851336552422\n",
      "Epoch: 0 Sample: 34170000 / 53735682 Loss: 1.457985536376089\n",
      "Epoch: 0 Sample: 34180000 / 53735682 Loss: 1.528110154867092\n",
      "Epoch: 0 Sample: 34190000 / 53735682 Loss: 1.4362681754319322\n",
      "Epoch: 0 Sample: 34200000 / 53735682 Loss: 1.532508396980671\n",
      "Epoch: 0 Sample: 34210000 / 53735682 Loss: 1.4422774227858928\n",
      "Epoch: 0 Sample: 34220000 / 53735682 Loss: 1.4730525545269137\n",
      "Epoch: 0 Sample: 34230000 / 53735682 Loss: 1.47350451628788\n",
      "Epoch: 0 Sample: 34240000 / 53735682 Loss: 1.5834285101748498\n",
      "Epoch: 0 Sample: 34250000 / 53735682 Loss: 1.4855947213081107\n",
      "Epoch: 0 Sample: 34260000 / 53735682 Loss: 1.5259549051355168\n",
      "Epoch: 0 Sample: 34270000 / 53735682 Loss: 1.3991680794039256\n",
      "Epoch: 0 Sample: 34280000 / 53735682 Loss: 1.5399993225170636\n",
      "Epoch: 0 Sample: 34290000 / 53735682 Loss: 1.5361116832350918\n",
      "Epoch: 0 Sample: 34300000 / 53735682 Loss: 1.525060732064063\n",
      "Epoch: 0 Sample: 34310000 / 53735682 Loss: 1.4930826274704851\n",
      "Epoch: 0 Sample: 34320000 / 53735682 Loss: 1.4933740652812006\n",
      "Epoch: 0 Sample: 34330000 / 53735682 Loss: 1.4386121179882116\n",
      "Epoch: 0 Sample: 34340000 / 53735682 Loss: 1.3860685592118172\n",
      "Epoch: 0 Sample: 34350000 / 53735682 Loss: 1.4105011934758425\n",
      "Epoch: 0 Sample: 34360000 / 53735682 Loss: 1.4533442746690544\n",
      "Epoch: 0 Sample: 34370000 / 53735682 Loss: 1.4592679467241307\n",
      "Epoch: 0 Sample: 34380000 / 53735682 Loss: 1.4715412526799105\n",
      "Epoch: 0 Sample: 34390000 / 53735682 Loss: 1.5353275664997903\n",
      "Epoch: 0 Sample: 34400000 / 53735682 Loss: 1.455684749489865\n",
      "Epoch: 0 Sample: 34410000 / 53735682 Loss: 1.4343422934243444\n",
      "Epoch: 0 Sample: 34420000 / 53735682 Loss: 1.513224372623248\n",
      "Epoch: 0 Sample: 34430000 / 53735682 Loss: 1.4692020457831791\n",
      "Epoch: 0 Sample: 34440000 / 53735682 Loss: 1.4375020374245642\n",
      "Epoch: 0 Sample: 34450000 / 53735682 Loss: 1.4115661723198278\n",
      "Epoch: 0 Sample: 34460000 / 53735682 Loss: 1.4736100441287205\n",
      "Epoch: 0 Sample: 34470000 / 53735682 Loss: 1.5832707274776312\n",
      "Epoch: 0 Sample: 34480000 / 53735682 Loss: 1.4700383342107297\n",
      "Epoch: 0 Sample: 34490000 / 53735682 Loss: 1.425768672321969\n",
      "Epoch: 0 Sample: 34500000 / 53735682 Loss: 1.4105737086529888\n",
      "Epoch: 0 Sample: 34510000 / 53735682 Loss: 1.498551898767717\n",
      "Epoch: 0 Sample: 34520000 / 53735682 Loss: 1.4644895013133425\n",
      "Epoch: 0 Sample: 34530000 / 53735682 Loss: 1.5456147903185242\n",
      "Epoch: 0 Sample: 34540000 / 53735682 Loss: 1.5275258294970948\n",
      "Epoch: 0 Sample: 34550000 / 53735682 Loss: 1.516386031911046\n",
      "Epoch: 0 Sample: 34560000 / 53735682 Loss: 1.458999656881946\n",
      "Epoch: 0 Sample: 34570000 / 53735682 Loss: 1.4643897179073595\n",
      "Epoch: 0 Sample: 34580000 / 53735682 Loss: 1.5490088259954575\n",
      "Epoch: 0 Sample: 34590000 / 53735682 Loss: 1.5335288492335961\n",
      "Epoch: 0 Sample: 34600000 / 53735682 Loss: 1.4778187670853755\n",
      "Epoch: 0 Sample: 34610000 / 53735682 Loss: 1.520478425878176\n",
      "Epoch: 0 Sample: 34620000 / 53735682 Loss: 1.551675955323212\n",
      "Epoch: 0 Sample: 34630000 / 53735682 Loss: 1.5331188324156853\n",
      "Epoch: 0 Sample: 34640000 / 53735682 Loss: 1.4316269570102487\n",
      "Epoch: 0 Sample: 34650000 / 53735682 Loss: 1.534669412339852\n",
      "Epoch: 0 Sample: 34660000 / 53735682 Loss: 1.5131491314837202\n",
      "Epoch: 0 Sample: 34670000 / 53735682 Loss: 1.4477763134849408\n",
      "Epoch: 0 Sample: 34680000 / 53735682 Loss: 1.479675089501559\n",
      "Epoch: 0 Sample: 34690000 / 53735682 Loss: 1.5143566474536319\n",
      "Epoch: 0 Sample: 34700000 / 53735682 Loss: 1.5353799748339467\n",
      "Epoch: 0 Sample: 34710000 / 53735682 Loss: 1.5474309172312966\n",
      "Epoch: 0 Sample: 34720000 / 53735682 Loss: 1.524649889128519\n",
      "Epoch: 0 Sample: 34730000 / 53735682 Loss: 1.557141970533885\n",
      "Epoch: 0 Sample: 34740000 / 53735682 Loss: 1.5450124919053316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 34750000 / 53735682 Loss: 1.4618618912869363\n",
      "Epoch: 0 Sample: 34760000 / 53735682 Loss: 1.4441612734865452\n",
      "Epoch: 0 Sample: 34770000 / 53735682 Loss: 1.5120929986572325\n",
      "Epoch: 0 Sample: 34780000 / 53735682 Loss: 1.3963174226282833\n",
      "Epoch: 0 Sample: 34790000 / 53735682 Loss: 1.427175555741334\n",
      "Epoch: 0 Sample: 34800000 / 53735682 Loss: 1.495822989770032\n",
      "Epoch: 0 Sample: 34810000 / 53735682 Loss: 1.4756148788078218\n",
      "Epoch: 0 Sample: 34820000 / 53735682 Loss: 1.4737429050484026\n",
      "Epoch: 0 Sample: 34830000 / 53735682 Loss: 1.5353496554891488\n",
      "Epoch: 0 Sample: 34840000 / 53735682 Loss: 1.4936843195501555\n",
      "Epoch: 0 Sample: 34850000 / 53735682 Loss: 1.494321855904576\n",
      "Epoch: 0 Sample: 34860000 / 53735682 Loss: 1.4341468639445898\n",
      "Epoch: 0 Sample: 34870000 / 53735682 Loss: 1.5787758528166052\n",
      "Epoch: 0 Sample: 34880000 / 53735682 Loss: 1.5074152495814688\n",
      "Epoch: 0 Sample: 34890000 / 53735682 Loss: 1.4664216042192235\n",
      "Epoch: 0 Sample: 34900000 / 53735682 Loss: 1.4944904836119606\n",
      "Epoch: 0 Sample: 34910000 / 53735682 Loss: 1.4413980655527703\n",
      "Epoch: 0 Sample: 34920000 / 53735682 Loss: 1.4771793888161366\n",
      "Epoch: 0 Sample: 34930000 / 53735682 Loss: 1.5093623704665091\n",
      "Epoch: 0 Sample: 34940000 / 53735682 Loss: 1.507981624747874\n",
      "Epoch: 0 Sample: 34950000 / 53735682 Loss: 1.5668945387941533\n",
      "Epoch: 0 Sample: 34960000 / 53735682 Loss: 1.5063069626762418\n",
      "Epoch: 0 Sample: 34970000 / 53735682 Loss: 1.5013822391824707\n",
      "Epoch: 0 Sample: 34980000 / 53735682 Loss: 1.4521866443605993\n",
      "Epoch: 0 Sample: 34990000 / 53735682 Loss: 1.4874805488702019\n",
      "Epoch: 0 Sample: 35000000 / 53735682 Loss: 1.531182641261666\n",
      "Epoch: 0 Sample: 35010000 / 53735682 Loss: 1.5691039442393913\n",
      "Epoch: 0 Sample: 35020000 / 53735682 Loss: 1.560654976412048\n",
      "Epoch: 0 Sample: 35030000 / 53735682 Loss: 1.5002175280391001\n",
      "Epoch: 0 Sample: 35040000 / 53735682 Loss: 1.4779610870575097\n",
      "Epoch: 0 Sample: 35050000 / 53735682 Loss: 1.5544189139056188\n",
      "Epoch: 0 Sample: 35060000 / 53735682 Loss: 1.4656858062448115\n",
      "Epoch: 0 Sample: 35070000 / 53735682 Loss: 1.4532723714426505\n",
      "Epoch: 0 Sample: 35080000 / 53735682 Loss: 1.505429466298218\n",
      "Epoch: 0 Sample: 35090000 / 53735682 Loss: 1.4678688480823854\n",
      "Epoch: 0 Sample: 35100000 / 53735682 Loss: 1.4539206709136945\n",
      "Epoch: 0 Sample: 35110000 / 53735682 Loss: 1.47172659120858\n",
      "Epoch: 0 Sample: 35120000 / 53735682 Loss: 1.4801969857758284\n",
      "Epoch: 0 Sample: 35130000 / 53735682 Loss: 1.4961990220056989\n",
      "Epoch: 0 Sample: 35140000 / 53735682 Loss: 1.4714983910432888\n",
      "Epoch: 0 Sample: 35150000 / 53735682 Loss: 1.4700182729020153\n",
      "Epoch: 0 Sample: 35160000 / 53735682 Loss: 1.479441746486414\n",
      "Epoch: 0 Sample: 35170000 / 53735682 Loss: 1.4716548144453196\n",
      "Epoch: 0 Sample: 35180000 / 53735682 Loss: 1.4842981342831\n",
      "Epoch: 0 Sample: 35190000 / 53735682 Loss: 1.4600368611391465\n",
      "Epoch: 0 Sample: 35200000 / 53735682 Loss: 1.527724200699493\n",
      "Epoch: 0 Sample: 35210000 / 53735682 Loss: 1.5495145702364133\n",
      "Epoch: 0 Sample: 35220000 / 53735682 Loss: 1.4450952281382756\n",
      "Epoch: 0 Sample: 35230000 / 53735682 Loss: 1.571560058901839\n",
      "Epoch: 0 Sample: 35240000 / 53735682 Loss: 1.5187415061812004\n",
      "Epoch: 0 Sample: 35250000 / 53735682 Loss: 1.4526927639859615\n",
      "Epoch: 0 Sample: 35260000 / 53735682 Loss: 1.4647405663640547\n",
      "Epoch: 0 Sample: 35270000 / 53735682 Loss: 1.4320505806156263\n",
      "Epoch: 0 Sample: 35280000 / 53735682 Loss: 1.55772738791502\n",
      "Epoch: 0 Sample: 35290000 / 53735682 Loss: 1.5515626126016873\n",
      "Epoch: 0 Sample: 35300000 / 53735682 Loss: 1.5171807162291917\n",
      "Epoch: 0 Sample: 35310000 / 53735682 Loss: 1.4825324953639485\n",
      "Epoch: 0 Sample: 35320000 / 53735682 Loss: 1.4732750068177003\n",
      "Epoch: 0 Sample: 35330000 / 53735682 Loss: 1.4754126123805107\n",
      "Epoch: 0 Sample: 35340000 / 53735682 Loss: 1.437143805134371\n",
      "Epoch: 0 Sample: 35350000 / 53735682 Loss: 1.4489387567325214\n",
      "Epoch: 0 Sample: 35360000 / 53735682 Loss: 1.4070017508565091\n",
      "Epoch: 0 Sample: 35370000 / 53735682 Loss: 1.5164170577769784\n",
      "Epoch: 0 Sample: 35380000 / 53735682 Loss: 1.4760398569902504\n",
      "Epoch: 0 Sample: 35390000 / 53735682 Loss: 1.4309878681200863\n",
      "Epoch: 0 Sample: 35400000 / 53735682 Loss: 1.539891675155601\n",
      "Epoch: 0 Sample: 35410000 / 53735682 Loss: 1.5736113426986986\n",
      "Epoch: 0 Sample: 35420000 / 53735682 Loss: 1.4889538274667573\n",
      "Epoch: 0 Sample: 35430000 / 53735682 Loss: 1.4528878882117047\n",
      "Epoch: 0 Sample: 35440000 / 53735682 Loss: 1.4504551239367869\n",
      "Epoch: 0 Sample: 35450000 / 53735682 Loss: 1.4771034173896975\n",
      "Epoch: 0 Sample: 35460000 / 53735682 Loss: 1.5120710112300846\n",
      "Epoch: 0 Sample: 35470000 / 53735682 Loss: 1.5391019732397602\n",
      "Epoch: 0 Sample: 35480000 / 53735682 Loss: 1.446163147192336\n",
      "Epoch: 0 Sample: 35490000 / 53735682 Loss: 1.5422629255358578\n",
      "Epoch: 0 Sample: 35500000 / 53735682 Loss: 1.5474059707995358\n",
      "Epoch: 0 Sample: 35510000 / 53735682 Loss: 1.4602858254682443\n",
      "Epoch: 0 Sample: 35520000 / 53735682 Loss: 1.3925146209787758\n",
      "Epoch: 0 Sample: 35530000 / 53735682 Loss: 1.459166963475559\n",
      "Epoch: 0 Sample: 35540000 / 53735682 Loss: 1.4580520631702072\n",
      "Epoch: 0 Sample: 35550000 / 53735682 Loss: 1.4788086893617436\n",
      "Epoch: 0 Sample: 35560000 / 53735682 Loss: 1.505013746020741\n",
      "Epoch: 0 Sample: 35570000 / 53735682 Loss: 1.4993058839179154\n",
      "Epoch: 0 Sample: 35580000 / 53735682 Loss: 1.3848372942461533\n",
      "Epoch: 0 Sample: 35590000 / 53735682 Loss: 1.576480479968194\n",
      "Epoch: 0 Sample: 35600000 / 53735682 Loss: 1.4623143023900704\n",
      "Epoch: 0 Sample: 35610000 / 53735682 Loss: 1.4167153419907481\n",
      "Epoch: 0 Sample: 35620000 / 53735682 Loss: 1.487564300704383\n",
      "Epoch: 0 Sample: 35630000 / 53735682 Loss: 1.533523661016876\n",
      "Epoch: 0 Sample: 35640000 / 53735682 Loss: 1.5552303659873057\n",
      "Epoch: 0 Sample: 35650000 / 53735682 Loss: 1.4846686265795275\n",
      "Epoch: 0 Sample: 35660000 / 53735682 Loss: 1.5441221772430898\n",
      "Epoch: 0 Sample: 35670000 / 53735682 Loss: 1.469438415912932\n",
      "Epoch: 0 Sample: 35680000 / 53735682 Loss: 1.5340385652154918\n",
      "Epoch: 0 Sample: 35690000 / 53735682 Loss: 1.4110994309561264\n",
      "Epoch: 0 Sample: 35700000 / 53735682 Loss: 1.5838489368764783\n",
      "Epoch: 0 Sample: 35710000 / 53735682 Loss: 1.4252414636390673\n",
      "Epoch: 0 Sample: 35720000 / 53735682 Loss: 1.4553787919932883\n",
      "Epoch: 0 Sample: 35730000 / 53735682 Loss: 1.402744058737112\n",
      "Epoch: 0 Sample: 35740000 / 53735682 Loss: 1.5753374318744107\n",
      "Epoch: 0 Sample: 35750000 / 53735682 Loss: 1.4500247728260875\n",
      "Epoch: 0 Sample: 35760000 / 53735682 Loss: 1.3846122074965204\n",
      "Epoch: 0 Sample: 35770000 / 53735682 Loss: 1.4991040616336944\n",
      "Epoch: 0 Sample: 35780000 / 53735682 Loss: 1.429114801624542\n",
      "Epoch: 0 Sample: 35790000 / 53735682 Loss: 1.41904628543806\n",
      "Epoch: 0 Sample: 35800000 / 53735682 Loss: 1.5579962713133524\n",
      "Epoch: 0 Sample: 35810000 / 53735682 Loss: 1.5059837019199644\n",
      "Epoch: 0 Sample: 35820000 / 53735682 Loss: 1.5344247535368711\n",
      "Epoch: 0 Sample: 35830000 / 53735682 Loss: 1.5158392620151186\n",
      "Epoch: 0 Sample: 35840000 / 53735682 Loss: 1.5058154253349891\n",
      "Epoch: 0 Sample: 35850000 / 53735682 Loss: 1.4493315696126594\n",
      "Epoch: 0 Sample: 35860000 / 53735682 Loss: 1.5970811106940954\n",
      "Epoch: 0 Sample: 35870000 / 53735682 Loss: 1.5094300748269986\n",
      "Epoch: 0 Sample: 35880000 / 53735682 Loss: 1.4742046482379139\n",
      "Epoch: 0 Sample: 35890000 / 53735682 Loss: 1.5319983167266786\n",
      "Epoch: 0 Sample: 35900000 / 53735682 Loss: 1.4800453451948996\n",
      "Epoch: 0 Sample: 35910000 / 53735682 Loss: 1.4610901843391422\n",
      "Epoch: 0 Sample: 35920000 / 53735682 Loss: 1.4978684518197893\n",
      "Epoch: 0 Sample: 35930000 / 53735682 Loss: 1.4693250296209728\n",
      "Epoch: 0 Sample: 35940000 / 53735682 Loss: 1.4090134904215585\n",
      "Epoch: 0 Sample: 35950000 / 53735682 Loss: 1.4114397435063704\n",
      "Epoch: 0 Sample: 35960000 / 53735682 Loss: 1.46685654535094\n",
      "Epoch: 0 Sample: 35970000 / 53735682 Loss: 1.417085385567575\n",
      "Epoch: 0 Sample: 35980000 / 53735682 Loss: 1.5229215834090528\n",
      "Epoch: 0 Sample: 35990000 / 53735682 Loss: 1.47843891530888\n",
      "Epoch: 0 Sample: 36000000 / 53735682 Loss: 1.380433521009628\n",
      "Epoch: 0 Sample: 36010000 / 53735682 Loss: 1.4888252981931513\n",
      "Epoch: 0 Sample: 36020000 / 53735682 Loss: 1.417489192175179\n",
      "Epoch: 0 Sample: 36030000 / 53735682 Loss: 1.4899239478277178\n",
      "Epoch: 0 Sample: 36040000 / 53735682 Loss: 1.4777522157597776\n",
      "Epoch: 0 Sample: 36050000 / 53735682 Loss: 1.4245813111678438\n",
      "Epoch: 0 Sample: 36060000 / 53735682 Loss: 1.5096752847598087\n",
      "Epoch: 0 Sample: 36070000 / 53735682 Loss: 1.472739979064686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 36080000 / 53735682 Loss: 1.475531717376096\n",
      "Epoch: 0 Sample: 36090000 / 53735682 Loss: 1.556940338650648\n",
      "Epoch: 0 Sample: 36100000 / 53735682 Loss: 1.470376059355615\n",
      "Epoch: 0 Sample: 36110000 / 53735682 Loss: 1.4978669028273592\n",
      "Epoch: 0 Sample: 36120000 / 53735682 Loss: 1.5199683342984924\n",
      "Epoch: 0 Sample: 36130000 / 53735682 Loss: 1.487238919670612\n",
      "Epoch: 0 Sample: 36140000 / 53735682 Loss: 1.441188190331999\n",
      "Epoch: 0 Sample: 36150000 / 53735682 Loss: 1.517569262832005\n",
      "Epoch: 0 Sample: 36160000 / 53735682 Loss: 1.4415794771893635\n",
      "Epoch: 0 Sample: 36170000 / 53735682 Loss: 1.410409058680254\n",
      "Epoch: 0 Sample: 36180000 / 53735682 Loss: 1.5303777296206553\n",
      "Epoch: 0 Sample: 36190000 / 53735682 Loss: 1.5237813976134413\n",
      "Epoch: 0 Sample: 36200000 / 53735682 Loss: 1.5738324706243136\n",
      "Epoch: 0 Sample: 36210000 / 53735682 Loss: 1.5317893244044882\n",
      "Epoch: 0 Sample: 36220000 / 53735682 Loss: 1.5411519002247953\n",
      "Epoch: 0 Sample: 36230000 / 53735682 Loss: 1.493663934514009\n",
      "Epoch: 0 Sample: 36240000 / 53735682 Loss: 1.5295922039405636\n",
      "Epoch: 0 Sample: 36250000 / 53735682 Loss: 1.4657085994333756\n",
      "Epoch: 0 Sample: 36260000 / 53735682 Loss: 1.5283755393618446\n",
      "Epoch: 0 Sample: 36270000 / 53735682 Loss: 1.4840730189979554\n",
      "Epoch: 0 Sample: 36280000 / 53735682 Loss: 1.4871382504692852\n",
      "Epoch: 0 Sample: 36290000 / 53735682 Loss: 1.6312921672233236\n",
      "Epoch: 0 Sample: 36300000 / 53735682 Loss: 1.6121361555868294\n",
      "Epoch: 0 Sample: 36310000 / 53735682 Loss: 1.4916507109840613\n",
      "Epoch: 0 Sample: 36320000 / 53735682 Loss: 1.5217869953654652\n",
      "Epoch: 0 Sample: 36330000 / 53735682 Loss: 1.4701200564745955\n",
      "Epoch: 0 Sample: 36340000 / 53735682 Loss: 1.4640732422190226\n",
      "Epoch: 0 Sample: 36350000 / 53735682 Loss: 1.5162158059878719\n",
      "Epoch: 0 Sample: 36360000 / 53735682 Loss: 1.5385202374515332\n",
      "Epoch: 0 Sample: 36370000 / 53735682 Loss: 1.5685067308224123\n",
      "Epoch: 0 Sample: 36380000 / 53735682 Loss: 1.5421078033378315\n",
      "Epoch: 0 Sample: 36390000 / 53735682 Loss: 1.5450467073200236\n",
      "Epoch: 0 Sample: 36400000 / 53735682 Loss: 1.5216413048553263\n",
      "Epoch: 0 Sample: 36410000 / 53735682 Loss: 1.4856786189854636\n",
      "Epoch: 0 Sample: 36420000 / 53735682 Loss: 1.4820530907984069\n",
      "Epoch: 0 Sample: 36430000 / 53735682 Loss: 1.595207811910214\n",
      "Epoch: 0 Sample: 36440000 / 53735682 Loss: 1.4121187238451527\n",
      "Epoch: 0 Sample: 36450000 / 53735682 Loss: 1.5251928789850226\n",
      "Epoch: 0 Sample: 36460000 / 53735682 Loss: 1.504548778934975\n",
      "Epoch: 0 Sample: 36470000 / 53735682 Loss: 1.5254810575073203\n",
      "Epoch: 0 Sample: 36480000 / 53735682 Loss: 1.582119368830841\n",
      "Epoch: 0 Sample: 36490000 / 53735682 Loss: 1.564216499043396\n",
      "Epoch: 0 Sample: 36500000 / 53735682 Loss: 1.4943447728800114\n",
      "Epoch: 0 Sample: 36510000 / 53735682 Loss: 1.4763397547788046\n",
      "Epoch: 0 Sample: 36520000 / 53735682 Loss: 1.5430579144460537\n",
      "Epoch: 0 Sample: 36530000 / 53735682 Loss: 1.4576568761594206\n",
      "Epoch: 0 Sample: 36540000 / 53735682 Loss: 1.5702791496925914\n",
      "Epoch: 0 Sample: 36550000 / 53735682 Loss: 1.4811148790925577\n",
      "Epoch: 0 Sample: 36560000 / 53735682 Loss: 1.512919346506855\n",
      "Epoch: 0 Sample: 36570000 / 53735682 Loss: 1.4770406636492377\n",
      "Epoch: 0 Sample: 36580000 / 53735682 Loss: 1.5694622548341006\n",
      "Epoch: 0 Sample: 36590000 / 53735682 Loss: 1.4711518208826564\n",
      "Epoch: 0 Sample: 36600000 / 53735682 Loss: 1.5301623846391221\n",
      "Epoch: 0 Sample: 36610000 / 53735682 Loss: 1.462382726213474\n",
      "Epoch: 0 Sample: 36620000 / 53735682 Loss: 1.4754284449966852\n",
      "Epoch: 0 Sample: 36630000 / 53735682 Loss: 1.4541740122530182\n",
      "Epoch: 0 Sample: 36640000 / 53735682 Loss: 1.5079606743321783\n",
      "Epoch: 0 Sample: 36650000 / 53735682 Loss: 1.5031780661915515\n",
      "Epoch: 0 Sample: 36660000 / 53735682 Loss: 1.4148362627283044\n",
      "Epoch: 0 Sample: 36670000 / 53735682 Loss: 1.5017602197331608\n",
      "Epoch: 0 Sample: 36680000 / 53735682 Loss: 1.494607771129202\n",
      "Epoch: 0 Sample: 36690000 / 53735682 Loss: 1.530877851130528\n",
      "Epoch: 0 Sample: 36700000 / 53735682 Loss: 1.460716746540155\n",
      "Epoch: 0 Sample: 36710000 / 53735682 Loss: 1.4635223774690198\n",
      "Epoch: 0 Sample: 36720000 / 53735682 Loss: 1.4516434186394214\n",
      "Epoch: 0 Sample: 36730000 / 53735682 Loss: 1.4775763589464286\n",
      "Epoch: 0 Sample: 36740000 / 53735682 Loss: 1.440840533605726\n",
      "Epoch: 0 Sample: 36750000 / 53735682 Loss: 1.456883750415492\n",
      "Epoch: 0 Sample: 36760000 / 53735682 Loss: 1.4973172418784757\n",
      "Epoch: 0 Sample: 36770000 / 53735682 Loss: 1.5069879987212609\n",
      "Epoch: 0 Sample: 36780000 / 53735682 Loss: 1.5389703852316798\n",
      "Epoch: 0 Sample: 36790000 / 53735682 Loss: 1.4182886527776157\n",
      "Epoch: 0 Sample: 36800000 / 53735682 Loss: 1.4816735424827778\n",
      "Epoch: 0 Sample: 36810000 / 53735682 Loss: 1.4364949257397388\n",
      "Epoch: 0 Sample: 36820000 / 53735682 Loss: 1.4496587012989997\n",
      "Epoch: 0 Sample: 36830000 / 53735682 Loss: 1.4567658061498663\n",
      "Epoch: 0 Sample: 36840000 / 53735682 Loss: 1.4470855303199304\n",
      "Epoch: 0 Sample: 36850000 / 53735682 Loss: 1.5211764125144402\n",
      "Epoch: 0 Sample: 36860000 / 53735682 Loss: 1.5204751392077906\n",
      "Epoch: 0 Sample: 36870000 / 53735682 Loss: 1.535809886077772\n",
      "Epoch: 0 Sample: 36880000 / 53735682 Loss: 1.5072610178110115\n",
      "Epoch: 0 Sample: 36890000 / 53735682 Loss: 1.347184304777343\n",
      "Epoch: 0 Sample: 36900000 / 53735682 Loss: 1.4396470782649948\n",
      "Epoch: 0 Sample: 36910000 / 53735682 Loss: 1.4670205778514371\n",
      "Epoch: 0 Sample: 36920000 / 53735682 Loss: 1.4525976895755566\n",
      "Epoch: 0 Sample: 36930000 / 53735682 Loss: 1.5274771441123747\n",
      "Epoch: 0 Sample: 36940000 / 53735682 Loss: 1.500606429062068\n",
      "Epoch: 0 Sample: 36950000 / 53735682 Loss: 1.4952445522702518\n",
      "Epoch: 0 Sample: 36960000 / 53735682 Loss: 1.4310798148992152\n",
      "Epoch: 0 Sample: 36970000 / 53735682 Loss: 1.4346613193966524\n",
      "Epoch: 0 Sample: 36980000 / 53735682 Loss: 1.483666296616215\n",
      "Epoch: 0 Sample: 36990000 / 53735682 Loss: 1.4501241267677734\n",
      "Epoch: 0 Sample: 37000000 / 53735682 Loss: 1.5071539652403394\n",
      "Epoch: 0 Sample: 37010000 / 53735682 Loss: 1.5886784739589581\n",
      "Epoch: 0 Sample: 37020000 / 53735682 Loss: 1.5296279531414845\n",
      "Epoch: 0 Sample: 37030000 / 53735682 Loss: 1.5782535067381733\n",
      "Epoch: 0 Sample: 37040000 / 53735682 Loss: 1.4402795806078474\n",
      "Epoch: 0 Sample: 37050000 / 53735682 Loss: 1.548040220128991\n",
      "Epoch: 0 Sample: 37060000 / 53735682 Loss: 1.472383578501121\n",
      "Epoch: 0 Sample: 37070000 / 53735682 Loss: 1.4437408684045328\n",
      "Epoch: 0 Sample: 37080000 / 53735682 Loss: 1.508679088419817\n",
      "Epoch: 0 Sample: 37090000 / 53735682 Loss: 1.5575672835538894\n",
      "Epoch: 0 Sample: 37100000 / 53735682 Loss: 1.564410967428197\n",
      "Epoch: 0 Sample: 37110000 / 53735682 Loss: 1.407470226018916\n",
      "Epoch: 0 Sample: 37120000 / 53735682 Loss: 1.505271265237932\n",
      "Epoch: 0 Sample: 37130000 / 53735682 Loss: 1.5027114599429012\n",
      "Epoch: 0 Sample: 37140000 / 53735682 Loss: 1.3976837940914595\n",
      "Epoch: 0 Sample: 37150000 / 53735682 Loss: 1.4217487363601662\n",
      "Epoch: 0 Sample: 37160000 / 53735682 Loss: 1.4690510642294308\n",
      "Epoch: 0 Sample: 37170000 / 53735682 Loss: 1.4595839106599255\n",
      "Epoch: 0 Sample: 37180000 / 53735682 Loss: 1.4916094444392107\n",
      "Epoch: 0 Sample: 37190000 / 53735682 Loss: 1.4764224809252364\n",
      "Epoch: 0 Sample: 37200000 / 53735682 Loss: 1.4657046370291376\n",
      "Epoch: 0 Sample: 37210000 / 53735682 Loss: 1.5122048987538754\n",
      "Epoch: 0 Sample: 37220000 / 53735682 Loss: 1.4812690817887832\n",
      "Epoch: 0 Sample: 37230000 / 53735682 Loss: 1.392426034447987\n",
      "Epoch: 0 Sample: 37240000 / 53735682 Loss: 1.5115599547158376\n",
      "Epoch: 0 Sample: 37250000 / 53735682 Loss: 1.4341171239452846\n",
      "Epoch: 0 Sample: 37260000 / 53735682 Loss: 1.4534745260130222\n",
      "Epoch: 0 Sample: 37270000 / 53735682 Loss: 1.4738585530720403\n",
      "Epoch: 0 Sample: 37280000 / 53735682 Loss: 1.526508992629604\n",
      "Epoch: 0 Sample: 37290000 / 53735682 Loss: 1.4722949598760307\n",
      "Epoch: 0 Sample: 37300000 / 53735682 Loss: 1.5095612153234428\n",
      "Epoch: 0 Sample: 37310000 / 53735682 Loss: 1.50407625003371\n",
      "Epoch: 0 Sample: 37320000 / 53735682 Loss: 1.5429601095609593\n",
      "Epoch: 0 Sample: 37330000 / 53735682 Loss: 1.4269482187504279\n",
      "Epoch: 0 Sample: 37340000 / 53735682 Loss: 1.5172623303381099\n",
      "Epoch: 0 Sample: 37350000 / 53735682 Loss: 1.479233954286709\n",
      "Epoch: 0 Sample: 37360000 / 53735682 Loss: 1.4768147581788034\n",
      "Epoch: 0 Sample: 37370000 / 53735682 Loss: 1.4135592035928604\n",
      "Epoch: 0 Sample: 37380000 / 53735682 Loss: 1.4577164057068408\n",
      "Epoch: 0 Sample: 37390000 / 53735682 Loss: 1.4663259890131757\n",
      "Epoch: 0 Sample: 37400000 / 53735682 Loss: 1.4738415022156284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 37410000 / 53735682 Loss: 1.4657787060030736\n",
      "Epoch: 0 Sample: 37420000 / 53735682 Loss: 1.527227101356952\n",
      "Epoch: 0 Sample: 37430000 / 53735682 Loss: 1.4021273560100884\n",
      "Epoch: 0 Sample: 37440000 / 53735682 Loss: 1.4542782453607297\n",
      "Epoch: 0 Sample: 37450000 / 53735682 Loss: 1.5573149986514556\n",
      "Epoch: 0 Sample: 37460000 / 53735682 Loss: 1.4379681223080603\n",
      "Epoch: 0 Sample: 37470000 / 53735682 Loss: 1.4577060742663153\n",
      "Epoch: 0 Sample: 37480000 / 53735682 Loss: 1.5190048459455183\n",
      "Epoch: 0 Sample: 37490000 / 53735682 Loss: 1.4993295225220822\n",
      "Epoch: 0 Sample: 37500000 / 53735682 Loss: 1.5162606582892848\n",
      "Epoch: 0 Sample: 37510000 / 53735682 Loss: 1.619019453128719\n",
      "Epoch: 0 Sample: 37520000 / 53735682 Loss: 1.5060644429286834\n",
      "Epoch: 0 Sample: 37530000 / 53735682 Loss: 1.350951291068633\n",
      "Epoch: 0 Sample: 37540000 / 53735682 Loss: 1.470276488804495\n",
      "Epoch: 0 Sample: 37550000 / 53735682 Loss: 1.3919075787758963\n",
      "Epoch: 0 Sample: 37560000 / 53735682 Loss: 1.4353580285061853\n",
      "Epoch: 0 Sample: 37570000 / 53735682 Loss: 1.468953331125697\n",
      "Epoch: 0 Sample: 37580000 / 53735682 Loss: 1.5418163432093346\n",
      "Epoch: 0 Sample: 37590000 / 53735682 Loss: 1.5283707478528277\n",
      "Epoch: 0 Sample: 37600000 / 53735682 Loss: 1.4122962904037388\n",
      "Epoch: 0 Sample: 37610000 / 53735682 Loss: 1.5419121260638384\n",
      "Epoch: 0 Sample: 37620000 / 53735682 Loss: 1.5264321013691284\n",
      "Epoch: 0 Sample: 37630000 / 53735682 Loss: 1.4584362142758065\n",
      "Epoch: 0 Sample: 37640000 / 53735682 Loss: 1.4460837625635756\n",
      "Epoch: 0 Sample: 37650000 / 53735682 Loss: 1.3900525132867945\n",
      "Epoch: 0 Sample: 37660000 / 53735682 Loss: 1.465447541413007\n",
      "Epoch: 0 Sample: 37670000 / 53735682 Loss: 1.4170333481166988\n",
      "Epoch: 0 Sample: 37680000 / 53735682 Loss: 1.4130168434401127\n",
      "Epoch: 0 Sample: 37690000 / 53735682 Loss: 1.5068732036453536\n",
      "Epoch: 0 Sample: 37700000 / 53735682 Loss: 1.4568518109960302\n",
      "Epoch: 0 Sample: 37710000 / 53735682 Loss: 1.5193552299573776\n",
      "Epoch: 0 Sample: 37720000 / 53735682 Loss: 1.4417023664496558\n",
      "Epoch: 0 Sample: 37730000 / 53735682 Loss: 1.5174925269011084\n",
      "Epoch: 0 Sample: 37740000 / 53735682 Loss: 1.5054941027439368\n",
      "Epoch: 0 Sample: 37750000 / 53735682 Loss: 1.4668268436596987\n",
      "Epoch: 0 Sample: 37760000 / 53735682 Loss: 1.4764725470057773\n",
      "Epoch: 0 Sample: 37770000 / 53735682 Loss: 1.462495434128368\n",
      "Epoch: 0 Sample: 37780000 / 53735682 Loss: 1.500635565470904\n",
      "Epoch: 0 Sample: 37790000 / 53735682 Loss: 1.5399832689800241\n",
      "Epoch: 0 Sample: 37800000 / 53735682 Loss: 1.5230338877540275\n",
      "Epoch: 0 Sample: 37810000 / 53735682 Loss: 1.4736719378719114\n",
      "Epoch: 0 Sample: 37820000 / 53735682 Loss: 1.5014517372694303\n",
      "Epoch: 0 Sample: 37830000 / 53735682 Loss: 1.5042373374566056\n",
      "Epoch: 0 Sample: 37840000 / 53735682 Loss: 1.5147837102505872\n",
      "Epoch: 0 Sample: 37850000 / 53735682 Loss: 1.5897050019383516\n",
      "Epoch: 0 Sample: 37860000 / 53735682 Loss: 1.5253913455157337\n",
      "Epoch: 0 Sample: 37870000 / 53735682 Loss: 1.517212212966824\n",
      "Epoch: 0 Sample: 37880000 / 53735682 Loss: 1.3492252934006268\n",
      "Epoch: 0 Sample: 37890000 / 53735682 Loss: 1.5290632611705997\n",
      "Epoch: 0 Sample: 37900000 / 53735682 Loss: 1.495668674588392\n",
      "Epoch: 0 Sample: 37910000 / 53735682 Loss: 1.5248839706840058\n",
      "Epoch: 0 Sample: 37920000 / 53735682 Loss: 1.5031030147710465\n",
      "Epoch: 0 Sample: 37930000 / 53735682 Loss: 1.4531100978189628\n",
      "Epoch: 0 Sample: 37940000 / 53735682 Loss: 1.4949230804877391\n",
      "Epoch: 0 Sample: 37950000 / 53735682 Loss: 1.469336097197619\n",
      "Epoch: 0 Sample: 37960000 / 53735682 Loss: 1.5413471791670261\n",
      "Epoch: 0 Sample: 37970000 / 53735682 Loss: 1.5842866885448639\n",
      "Epoch: 0 Sample: 37980000 / 53735682 Loss: 1.539537909920981\n",
      "Epoch: 0 Sample: 37990000 / 53735682 Loss: 1.4657653882310222\n",
      "Epoch: 0 Sample: 38000000 / 53735682 Loss: 1.4734424751738144\n",
      "Epoch: 0 Sample: 38010000 / 53735682 Loss: 1.417696147542169\n",
      "Epoch: 0 Sample: 38020000 / 53735682 Loss: 1.4620150210726113\n",
      "Epoch: 0 Sample: 38030000 / 53735682 Loss: 1.4300747415351704\n",
      "Epoch: 0 Sample: 38040000 / 53735682 Loss: 1.5317469665557186\n",
      "Epoch: 0 Sample: 38050000 / 53735682 Loss: 1.4741006746570697\n",
      "Epoch: 0 Sample: 38060000 / 53735682 Loss: 1.5014615532066171\n",
      "Epoch: 0 Sample: 38070000 / 53735682 Loss: 1.4670971271282744\n",
      "Epoch: 0 Sample: 38080000 / 53735682 Loss: 1.5347642078628154\n",
      "Epoch: 0 Sample: 38090000 / 53735682 Loss: 1.4960842387177853\n",
      "Epoch: 0 Sample: 38100000 / 53735682 Loss: 1.4847364962339364\n",
      "Epoch: 0 Sample: 38110000 / 53735682 Loss: 1.5237918341303214\n",
      "Epoch: 0 Sample: 38120000 / 53735682 Loss: 1.4691268858362174\n",
      "Epoch: 0 Sample: 38130000 / 53735682 Loss: 1.489905579630963\n",
      "Epoch: 0 Sample: 38140000 / 53735682 Loss: 1.442194620275794\n",
      "Epoch: 0 Sample: 38150000 / 53735682 Loss: 1.485845513515277\n",
      "Epoch: 0 Sample: 38160000 / 53735682 Loss: 1.4396522767647204\n",
      "Epoch: 0 Sample: 38170000 / 53735682 Loss: 1.5185481315549942\n",
      "Epoch: 0 Sample: 38180000 / 53735682 Loss: 1.5420296495910362\n",
      "Epoch: 0 Sample: 38190000 / 53735682 Loss: 1.61534490966102\n",
      "Epoch: 0 Sample: 38200000 / 53735682 Loss: 1.443270518465944\n",
      "Epoch: 0 Sample: 38210000 / 53735682 Loss: 1.516410326204127\n",
      "Epoch: 0 Sample: 38220000 / 53735682 Loss: 1.4266357873731335\n",
      "Epoch: 0 Sample: 38230000 / 53735682 Loss: 1.4638408185131602\n",
      "Epoch: 0 Sample: 38240000 / 53735682 Loss: 1.4575858824118186\n",
      "Epoch: 0 Sample: 38250000 / 53735682 Loss: 1.525624676030259\n",
      "Epoch: 0 Sample: 38260000 / 53735682 Loss: 1.519390036552409\n",
      "Epoch: 0 Sample: 38270000 / 53735682 Loss: 1.512207916230638\n",
      "Epoch: 0 Sample: 38280000 / 53735682 Loss: 1.4630790877874582\n",
      "Epoch: 0 Sample: 38290000 / 53735682 Loss: 1.5210762807537819\n",
      "Epoch: 0 Sample: 38300000 / 53735682 Loss: 1.4943801723141332\n",
      "Epoch: 0 Sample: 38310000 / 53735682 Loss: 1.4591603120196952\n",
      "Epoch: 0 Sample: 38320000 / 53735682 Loss: 1.4988792585835058\n",
      "Epoch: 0 Sample: 38330000 / 53735682 Loss: 1.5383048920916602\n",
      "Epoch: 0 Sample: 38340000 / 53735682 Loss: 1.6069588530656662\n",
      "Epoch: 0 Sample: 38350000 / 53735682 Loss: 1.4698199100101776\n",
      "Epoch: 0 Sample: 38360000 / 53735682 Loss: 1.494819941905491\n",
      "Epoch: 0 Sample: 38370000 / 53735682 Loss: 1.504918378308095\n",
      "Epoch: 0 Sample: 38380000 / 53735682 Loss: 1.5344038275135525\n",
      "Epoch: 0 Sample: 38390000 / 53735682 Loss: 1.4907752896309736\n",
      "Epoch: 0 Sample: 38400000 / 53735682 Loss: 1.5142250133064636\n",
      "Epoch: 0 Sample: 38410000 / 53735682 Loss: 1.5641442180149356\n",
      "Epoch: 0 Sample: 38420000 / 53735682 Loss: 1.4993304653801833\n",
      "Epoch: 0 Sample: 38430000 / 53735682 Loss: 1.460429087458506\n",
      "Epoch: 0 Sample: 38440000 / 53735682 Loss: 1.577055842939442\n",
      "Epoch: 0 Sample: 38450000 / 53735682 Loss: 1.4805719119839411\n",
      "Epoch: 0 Sample: 38460000 / 53735682 Loss: 1.4513387044890103\n",
      "Epoch: 0 Sample: 38470000 / 53735682 Loss: 1.4796017072135754\n",
      "Epoch: 0 Sample: 38480000 / 53735682 Loss: 1.5144986944791414\n",
      "Epoch: 0 Sample: 38490000 / 53735682 Loss: 1.5603492156274217\n",
      "Epoch: 0 Sample: 38500000 / 53735682 Loss: 1.460734131846926\n",
      "Epoch: 0 Sample: 38510000 / 53735682 Loss: 1.4873667370987445\n",
      "Epoch: 0 Sample: 38520000 / 53735682 Loss: 1.552369096975001\n",
      "Epoch: 0 Sample: 38530000 / 53735682 Loss: 1.5163643011938333\n",
      "Epoch: 0 Sample: 38540000 / 53735682 Loss: 1.4513014366416719\n",
      "Epoch: 0 Sample: 38550000 / 53735682 Loss: 1.4711570138436534\n",
      "Epoch: 0 Sample: 38560000 / 53735682 Loss: 1.5360688680683232\n",
      "Epoch: 0 Sample: 38570000 / 53735682 Loss: 1.4278433500743837\n",
      "Epoch: 0 Sample: 38580000 / 53735682 Loss: 1.4290694997541533\n",
      "Epoch: 0 Sample: 38590000 / 53735682 Loss: 1.4753129727181777\n",
      "Epoch: 0 Sample: 38600000 / 53735682 Loss: 1.464762082849019\n",
      "Epoch: 0 Sample: 38610000 / 53735682 Loss: 1.5158631380282628\n",
      "Epoch: 0 Sample: 38620000 / 53735682 Loss: 1.53166855226604\n",
      "Epoch: 0 Sample: 38630000 / 53735682 Loss: 1.5098761880104608\n",
      "Epoch: 0 Sample: 38640000 / 53735682 Loss: 1.428606438122428\n",
      "Epoch: 0 Sample: 38650000 / 53735682 Loss: 1.4545270074425405\n",
      "Epoch: 0 Sample: 38660000 / 53735682 Loss: 1.4557913290447078\n",
      "Epoch: 0 Sample: 38670000 / 53735682 Loss: 1.4517869798687055\n",
      "Epoch: 0 Sample: 38680000 / 53735682 Loss: 1.398527644873552\n",
      "Epoch: 0 Sample: 38690000 / 53735682 Loss: 1.5727172540803893\n",
      "Epoch: 0 Sample: 38700000 / 53735682 Loss: 1.4449555137762156\n",
      "Epoch: 0 Sample: 38710000 / 53735682 Loss: 1.410325252493574\n",
      "Epoch: 0 Sample: 38720000 / 53735682 Loss: 1.5031584145648538\n",
      "Epoch: 0 Sample: 38730000 / 53735682 Loss: 1.4904758607378674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 38740000 / 53735682 Loss: 1.5881431428022386\n",
      "Epoch: 0 Sample: 38750000 / 53735682 Loss: 1.531516822107598\n",
      "Epoch: 0 Sample: 38760000 / 53735682 Loss: 1.5116916177292845\n",
      "Epoch: 0 Sample: 38770000 / 53735682 Loss: 1.5362601375556744\n",
      "Epoch: 0 Sample: 38780000 / 53735682 Loss: 1.448398048252932\n",
      "Epoch: 0 Sample: 38790000 / 53735682 Loss: 1.5555652517722054\n",
      "Epoch: 0 Sample: 38800000 / 53735682 Loss: 1.5614404838092808\n",
      "Epoch: 0 Sample: 38810000 / 53735682 Loss: 1.3862033217313732\n",
      "Epoch: 0 Sample: 38820000 / 53735682 Loss: 1.4497400963125968\n",
      "Epoch: 0 Sample: 38830000 / 53735682 Loss: 1.4931815429697943\n",
      "Epoch: 0 Sample: 38840000 / 53735682 Loss: 1.4963828299514192\n",
      "Epoch: 0 Sample: 38850000 / 53735682 Loss: 1.4147732649342784\n",
      "Epoch: 0 Sample: 38860000 / 53735682 Loss: 1.4593344766880247\n",
      "Epoch: 0 Sample: 38870000 / 53735682 Loss: 1.5112963197929936\n",
      "Epoch: 0 Sample: 38880000 / 53735682 Loss: 1.4165343487003117\n",
      "Epoch: 0 Sample: 38890000 / 53735682 Loss: 1.488281902926094\n",
      "Epoch: 0 Sample: 38900000 / 53735682 Loss: 1.5600863377496574\n",
      "Epoch: 0 Sample: 38910000 / 53735682 Loss: 1.4859309953186064\n",
      "Epoch: 0 Sample: 38920000 / 53735682 Loss: 1.4077152027586284\n",
      "Epoch: 0 Sample: 38930000 / 53735682 Loss: 1.4616496798133674\n",
      "Epoch: 0 Sample: 38940000 / 53735682 Loss: 1.4334260845654057\n",
      "Epoch: 0 Sample: 38950000 / 53735682 Loss: 1.4828043952485617\n",
      "Epoch: 0 Sample: 38960000 / 53735682 Loss: 1.4993572237361372\n",
      "Epoch: 0 Sample: 38970000 / 53735682 Loss: 1.6254288608012537\n",
      "Epoch: 0 Sample: 38980000 / 53735682 Loss: 1.515770655280107\n",
      "Epoch: 0 Sample: 38990000 / 53735682 Loss: 1.3975874411429798\n",
      "Epoch: 0 Sample: 39000000 / 53735682 Loss: 1.4866158467773407\n",
      "Epoch: 0 Sample: 39010000 / 53735682 Loss: 1.489440692272355\n",
      "Epoch: 0 Sample: 39020000 / 53735682 Loss: 1.548035112711842\n",
      "Epoch: 0 Sample: 39030000 / 53735682 Loss: 1.5126859066358564\n",
      "Epoch: 0 Sample: 39040000 / 53735682 Loss: 1.518773557328185\n",
      "Epoch: 0 Sample: 39050000 / 53735682 Loss: 1.4755022607177855\n",
      "Epoch: 0 Sample: 39060000 / 53735682 Loss: 1.4769573252862482\n",
      "Epoch: 0 Sample: 39070000 / 53735682 Loss: 1.5316954449477134\n",
      "Epoch: 0 Sample: 39080000 / 53735682 Loss: 1.5435881778324445\n",
      "Epoch: 0 Sample: 39090000 / 53735682 Loss: 1.4518767109858333\n",
      "Epoch: 0 Sample: 39100000 / 53735682 Loss: 1.5123294299119796\n",
      "Epoch: 0 Sample: 39110000 / 53735682 Loss: 1.4051777754564587\n",
      "Epoch: 0 Sample: 39120000 / 53735682 Loss: 1.5159102914334763\n",
      "Epoch: 0 Sample: 39130000 / 53735682 Loss: 1.4130084486201913\n",
      "Epoch: 0 Sample: 39140000 / 53735682 Loss: 1.4684222404437128\n",
      "Epoch: 0 Sample: 39150000 / 53735682 Loss: 1.5163761919773517\n",
      "Epoch: 0 Sample: 39160000 / 53735682 Loss: 1.5164080639217885\n",
      "Epoch: 0 Sample: 39170000 / 53735682 Loss: 1.4523316714039622\n",
      "Epoch: 0 Sample: 39180000 / 53735682 Loss: 1.4812023031532622\n",
      "Epoch: 0 Sample: 39190000 / 53735682 Loss: 1.4197476200231072\n",
      "Epoch: 0 Sample: 39200000 / 53735682 Loss: 1.551351833056891\n",
      "Epoch: 0 Sample: 39210000 / 53735682 Loss: 1.4817056139756568\n",
      "Epoch: 0 Sample: 39220000 / 53735682 Loss: 1.5166676862517994\n",
      "Epoch: 0 Sample: 39230000 / 53735682 Loss: 1.527125199013838\n",
      "Epoch: 0 Sample: 39240000 / 53735682 Loss: 1.4987086699849326\n",
      "Epoch: 0 Sample: 39250000 / 53735682 Loss: 1.390322491850846\n",
      "Epoch: 0 Sample: 39260000 / 53735682 Loss: 1.4654667097346614\n",
      "Epoch: 0 Sample: 39270000 / 53735682 Loss: 1.3664083591935894\n",
      "Epoch: 0 Sample: 39280000 / 53735682 Loss: 1.4457290112916406\n",
      "Epoch: 0 Sample: 39290000 / 53735682 Loss: 1.5009973351526802\n",
      "Epoch: 0 Sample: 39300000 / 53735682 Loss: 1.5341109545595697\n",
      "Epoch: 0 Sample: 39310000 / 53735682 Loss: 1.524896999165117\n",
      "Epoch: 0 Sample: 39320000 / 53735682 Loss: 1.4970942147944357\n",
      "Epoch: 0 Sample: 39330000 / 53735682 Loss: 1.5881321953102585\n",
      "Epoch: 0 Sample: 39340000 / 53735682 Loss: 1.472811711908344\n",
      "Epoch: 0 Sample: 39350000 / 53735682 Loss: 1.4822065822640291\n",
      "Epoch: 0 Sample: 39360000 / 53735682 Loss: 1.4873020100092913\n",
      "Epoch: 0 Sample: 39370000 / 53735682 Loss: 1.5492796458445794\n",
      "Epoch: 0 Sample: 39380000 / 53735682 Loss: 1.4934838057749116\n",
      "Epoch: 0 Sample: 39390000 / 53735682 Loss: 1.5441195288571874\n",
      "Epoch: 0 Sample: 39400000 / 53735682 Loss: 1.608323479216237\n",
      "Epoch: 0 Sample: 39410000 / 53735682 Loss: 1.4884688421722945\n",
      "Epoch: 0 Sample: 39420000 / 53735682 Loss: 1.5603612145723829\n",
      "Epoch: 0 Sample: 39430000 / 53735682 Loss: 1.5095542951593783\n",
      "Epoch: 0 Sample: 39440000 / 53735682 Loss: 1.4379726047612702\n",
      "Epoch: 0 Sample: 39450000 / 53735682 Loss: 1.4600779435907263\n",
      "Epoch: 0 Sample: 39460000 / 53735682 Loss: 1.5271782424912135\n",
      "Epoch: 0 Sample: 39470000 / 53735682 Loss: 1.4682744895746138\n",
      "Epoch: 0 Sample: 39480000 / 53735682 Loss: 1.5192698116084218\n",
      "Epoch: 0 Sample: 39490000 / 53735682 Loss: 1.538570933005985\n",
      "Epoch: 0 Sample: 39500000 / 53735682 Loss: 1.4974399674297527\n",
      "Epoch: 0 Sample: 39510000 / 53735682 Loss: 1.461670090962128\n",
      "Epoch: 0 Sample: 39520000 / 53735682 Loss: 1.46609523732673\n",
      "Epoch: 0 Sample: 39530000 / 53735682 Loss: 1.4467941446926416\n",
      "Epoch: 0 Sample: 39540000 / 53735682 Loss: 1.4683914828958478\n",
      "Epoch: 0 Sample: 39550000 / 53735682 Loss: 1.5215760259192002\n",
      "Epoch: 0 Sample: 39560000 / 53735682 Loss: 1.438416558918933\n",
      "Epoch: 0 Sample: 39570000 / 53735682 Loss: 1.4844896567205546\n",
      "Epoch: 0 Sample: 39580000 / 53735682 Loss: 1.514582549340214\n",
      "Epoch: 0 Sample: 39590000 / 53735682 Loss: 1.4614779768771373\n",
      "Epoch: 0 Sample: 39600000 / 53735682 Loss: 1.5003960136593588\n",
      "Epoch: 0 Sample: 39610000 / 53735682 Loss: 1.5277271099833027\n",
      "Epoch: 0 Sample: 39620000 / 53735682 Loss: 1.4763305644022169\n",
      "Epoch: 0 Sample: 39630000 / 53735682 Loss: 1.48498124077196\n",
      "Epoch: 0 Sample: 39640000 / 53735682 Loss: 1.493515281212836\n",
      "Epoch: 0 Sample: 39650000 / 53735682 Loss: 1.4250451771197978\n",
      "Epoch: 0 Sample: 39660000 / 53735682 Loss: 1.5034499480191026\n",
      "Epoch: 0 Sample: 39670000 / 53735682 Loss: 1.507400886052553\n",
      "Epoch: 0 Sample: 39680000 / 53735682 Loss: 1.5691467078251538\n",
      "Epoch: 0 Sample: 39690000 / 53735682 Loss: 1.479474291048862\n",
      "Epoch: 0 Sample: 39700000 / 53735682 Loss: 1.430227699065092\n",
      "Epoch: 0 Sample: 39710000 / 53735682 Loss: 1.490748947882056\n",
      "Epoch: 0 Sample: 39720000 / 53735682 Loss: 1.492405697639584\n",
      "Epoch: 0 Sample: 39730000 / 53735682 Loss: 1.4782448318435855\n",
      "Epoch: 0 Sample: 39740000 / 53735682 Loss: 1.4605150557235849\n",
      "Epoch: 0 Sample: 39750000 / 53735682 Loss: 1.414323211115367\n",
      "Epoch: 0 Sample: 39760000 / 53735682 Loss: 1.4448854346816553\n",
      "Epoch: 0 Sample: 39770000 / 53735682 Loss: 1.4624443973619579\n",
      "Epoch: 0 Sample: 39780000 / 53735682 Loss: 1.523470636636139\n",
      "Epoch: 0 Sample: 39790000 / 53735682 Loss: 1.4961452699562146\n",
      "Epoch: 0 Sample: 39800000 / 53735682 Loss: 1.3899299058099202\n",
      "Epoch: 0 Sample: 39810000 / 53735682 Loss: 1.547755011467495\n",
      "Epoch: 0 Sample: 39820000 / 53735682 Loss: 1.4611856252572126\n",
      "Epoch: 0 Sample: 39830000 / 53735682 Loss: 1.5392457236132215\n",
      "Epoch: 0 Sample: 39840000 / 53735682 Loss: 1.5305634150715188\n",
      "Epoch: 0 Sample: 39850000 / 53735682 Loss: 1.5090014370333353\n",
      "Epoch: 0 Sample: 39860000 / 53735682 Loss: 1.5343126871593433\n",
      "Epoch: 0 Sample: 39870000 / 53735682 Loss: 1.4820325804726617\n",
      "Epoch: 0 Sample: 39880000 / 53735682 Loss: 1.4513856322034502\n",
      "Epoch: 0 Sample: 39890000 / 53735682 Loss: 1.3880692779904802\n",
      "Epoch: 0 Sample: 39900000 / 53735682 Loss: 1.5214634927368533\n",
      "Epoch: 0 Sample: 39910000 / 53735682 Loss: 1.476899758635596\n",
      "Epoch: 0 Sample: 39920000 / 53735682 Loss: 1.4196900961985852\n",
      "Epoch: 0 Sample: 39930000 / 53735682 Loss: 1.5080884833306802\n",
      "Epoch: 0 Sample: 39940000 / 53735682 Loss: 1.393659300328308\n",
      "Epoch: 0 Sample: 39950000 / 53735682 Loss: 1.4856014677845866\n",
      "Epoch: 0 Sample: 39960000 / 53735682 Loss: 1.5132849306892395\n",
      "Epoch: 0 Sample: 39970000 / 53735682 Loss: 1.5075986622987383\n",
      "Epoch: 0 Sample: 39980000 / 53735682 Loss: 1.5331196651078831\n",
      "Epoch: 0 Sample: 39990000 / 53735682 Loss: 1.458077655155427\n",
      "Epoch: 0 Sample: 40000000 / 53735682 Loss: 1.5104715307589727\n",
      "Epoch: 0 Sample: 40010000 / 53735682 Loss: 1.4941702201229863\n",
      "Epoch: 0 Sample: 40020000 / 53735682 Loss: 1.4944692457451259\n",
      "Epoch: 0 Sample: 40030000 / 53735682 Loss: 1.48199248316139\n",
      "Epoch: 0 Sample: 40040000 / 53735682 Loss: 1.4964211153073164\n",
      "Epoch: 0 Sample: 40050000 / 53735682 Loss: 1.4674219552503218\n",
      "Epoch: 0 Sample: 40060000 / 53735682 Loss: 1.4220631689672567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 40070000 / 53735682 Loss: 1.4565028631877186\n",
      "Epoch: 0 Sample: 40080000 / 53735682 Loss: 1.464348626307993\n",
      "Epoch: 0 Sample: 40090000 / 53735682 Loss: 1.4823902451182143\n",
      "Epoch: 0 Sample: 40100000 / 53735682 Loss: 1.3702891291266464\n",
      "Epoch: 0 Sample: 40110000 / 53735682 Loss: 1.44943465321596\n",
      "Epoch: 0 Sample: 40120000 / 53735682 Loss: 1.4732733584797995\n",
      "Epoch: 0 Sample: 40130000 / 53735682 Loss: 1.4888614396855255\n",
      "Epoch: 0 Sample: 40140000 / 53735682 Loss: 1.4431684037752595\n",
      "Epoch: 0 Sample: 40150000 / 53735682 Loss: 1.5164557133978458\n",
      "Epoch: 0 Sample: 40160000 / 53735682 Loss: 1.4169756277812189\n",
      "Epoch: 0 Sample: 40170000 / 53735682 Loss: 1.561028613148224\n",
      "Epoch: 0 Sample: 40180000 / 53735682 Loss: 1.3883309412699711\n",
      "Epoch: 0 Sample: 40190000 / 53735682 Loss: 1.488897720114824\n",
      "Epoch: 0 Sample: 40200000 / 53735682 Loss: 1.4546745772002245\n",
      "Epoch: 0 Sample: 40210000 / 53735682 Loss: 1.5000740513634123\n",
      "Epoch: 0 Sample: 40220000 / 53735682 Loss: 1.5339152731487744\n",
      "Epoch: 0 Sample: 40230000 / 53735682 Loss: 1.4646784041912215\n",
      "Epoch: 0 Sample: 40240000 / 53735682 Loss: 1.4051380963564974\n",
      "Epoch: 0 Sample: 40250000 / 53735682 Loss: 1.4562764560527768\n",
      "Epoch: 0 Sample: 40260000 / 53735682 Loss: 1.41992091868896\n",
      "Epoch: 0 Sample: 40270000 / 53735682 Loss: 1.4483715735766896\n",
      "Epoch: 0 Sample: 40280000 / 53735682 Loss: 1.4730621065658087\n",
      "Epoch: 0 Sample: 40290000 / 53735682 Loss: 1.4518172338162323\n",
      "Epoch: 0 Sample: 40300000 / 53735682 Loss: 1.4743046981226706\n",
      "Epoch: 0 Sample: 40310000 / 53735682 Loss: 1.3870347848976639\n",
      "Epoch: 0 Sample: 40320000 / 53735682 Loss: 1.3733693228758657\n",
      "Epoch: 0 Sample: 40330000 / 53735682 Loss: 1.4156418254689491\n",
      "Epoch: 0 Sample: 40340000 / 53735682 Loss: 1.4236808343403213\n",
      "Epoch: 0 Sample: 40350000 / 53735682 Loss: 1.4301927948643776\n",
      "Epoch: 0 Sample: 40360000 / 53735682 Loss: 1.499729138389029\n",
      "Epoch: 0 Sample: 40370000 / 53735682 Loss: 1.3961081167380334\n",
      "Epoch: 0 Sample: 40380000 / 53735682 Loss: 1.4510005119648413\n",
      "Epoch: 0 Sample: 40390000 / 53735682 Loss: 1.4132142121745788\n",
      "Epoch: 0 Sample: 40400000 / 53735682 Loss: 1.5024057301801204\n",
      "Epoch: 0 Sample: 40410000 / 53735682 Loss: 1.5606847428766883\n",
      "Epoch: 0 Sample: 40420000 / 53735682 Loss: 1.5470392455237976\n",
      "Epoch: 0 Sample: 40430000 / 53735682 Loss: 1.4421985872103362\n",
      "Epoch: 0 Sample: 40440000 / 53735682 Loss: 1.5246566609469645\n",
      "Epoch: 0 Sample: 40450000 / 53735682 Loss: 1.4560689516298577\n",
      "Epoch: 0 Sample: 40460000 / 53735682 Loss: 1.4566909933900392\n",
      "Epoch: 0 Sample: 40470000 / 53735682 Loss: 1.516981089212406\n",
      "Epoch: 0 Sample: 40480000 / 53735682 Loss: 1.475558019836777\n",
      "Epoch: 0 Sample: 40490000 / 53735682 Loss: 1.4426226526647978\n",
      "Epoch: 0 Sample: 40500000 / 53735682 Loss: 1.5568808845008473\n",
      "Epoch: 0 Sample: 40510000 / 53735682 Loss: 1.560282478247339\n",
      "Epoch: 0 Sample: 40520000 / 53735682 Loss: 1.472586563689231\n",
      "Epoch: 0 Sample: 40530000 / 53735682 Loss: 1.4620424402250762\n",
      "Epoch: 0 Sample: 40540000 / 53735682 Loss: 1.5052637450802926\n",
      "Epoch: 0 Sample: 40550000 / 53735682 Loss: 1.5115451308317587\n",
      "Epoch: 0 Sample: 40560000 / 53735682 Loss: 1.4958547005135832\n",
      "Epoch: 0 Sample: 40570000 / 53735682 Loss: 1.5301396305150803\n",
      "Epoch: 0 Sample: 40580000 / 53735682 Loss: 1.4675199398059742\n",
      "Epoch: 0 Sample: 40590000 / 53735682 Loss: 1.537162118199693\n",
      "Epoch: 0 Sample: 40600000 / 53735682 Loss: 1.5124297853727275\n",
      "Epoch: 0 Sample: 40610000 / 53735682 Loss: 1.5493585518642088\n",
      "Epoch: 0 Sample: 40620000 / 53735682 Loss: 1.4637427019064804\n",
      "Epoch: 0 Sample: 40630000 / 53735682 Loss: 1.3981581305803092\n",
      "Epoch: 0 Sample: 40640000 / 53735682 Loss: 1.5505396627494132\n",
      "Epoch: 0 Sample: 40650000 / 53735682 Loss: 1.4416982774827856\n",
      "Epoch: 0 Sample: 40660000 / 53735682 Loss: 1.4864657331496949\n",
      "Epoch: 0 Sample: 40670000 / 53735682 Loss: 1.4764187300678024\n",
      "Epoch: 0 Sample: 40680000 / 53735682 Loss: 1.3614830455392783\n",
      "Epoch: 0 Sample: 40690000 / 53735682 Loss: 1.4367543196099177\n",
      "Epoch: 0 Sample: 40700000 / 53735682 Loss: 1.4842623294630237\n",
      "Epoch: 0 Sample: 40710000 / 53735682 Loss: 1.5574551031819261\n",
      "Epoch: 0 Sample: 40720000 / 53735682 Loss: 1.386319101268663\n",
      "Epoch: 0 Sample: 40730000 / 53735682 Loss: 1.4815697536322627\n",
      "Epoch: 0 Sample: 40740000 / 53735682 Loss: 1.494103489279524\n",
      "Epoch: 0 Sample: 40750000 / 53735682 Loss: 1.470260090525171\n",
      "Epoch: 0 Sample: 40760000 / 53735682 Loss: 1.4738694660865712\n",
      "Epoch: 0 Sample: 40770000 / 53735682 Loss: 1.469342591203458\n",
      "Epoch: 0 Sample: 40780000 / 53735682 Loss: 1.5215734494587911\n",
      "Epoch: 0 Sample: 40790000 / 53735682 Loss: 1.4298251125561354\n",
      "Epoch: 0 Sample: 40800000 / 53735682 Loss: 1.5535859011592157\n",
      "Epoch: 0 Sample: 40810000 / 53735682 Loss: 1.5717418790486808\n",
      "Epoch: 0 Sample: 40820000 / 53735682 Loss: 1.529163627824516\n",
      "Epoch: 0 Sample: 40830000 / 53735682 Loss: 1.4931177399182456\n",
      "Epoch: 0 Sample: 40840000 / 53735682 Loss: 1.5005402910711758\n",
      "Epoch: 0 Sample: 40850000 / 53735682 Loss: 1.5065979178114204\n",
      "Epoch: 0 Sample: 40860000 / 53735682 Loss: 1.4799071973252567\n",
      "Epoch: 0 Sample: 40870000 / 53735682 Loss: 1.462506066070161\n",
      "Epoch: 0 Sample: 40880000 / 53735682 Loss: 1.508991065622661\n",
      "Epoch: 0 Sample: 40890000 / 53735682 Loss: 1.5108319364134717\n",
      "Epoch: 0 Sample: 40900000 / 53735682 Loss: 1.4292258364920576\n",
      "Epoch: 0 Sample: 40910000 / 53735682 Loss: 1.3711799579273278\n",
      "Epoch: 0 Sample: 40920000 / 53735682 Loss: 1.4398192861200396\n",
      "Epoch: 0 Sample: 40930000 / 53735682 Loss: 1.5515300473778844\n",
      "Epoch: 0 Sample: 40940000 / 53735682 Loss: 1.4986596214805172\n",
      "Epoch: 0 Sample: 40950000 / 53735682 Loss: 1.5008630619719328\n",
      "Epoch: 0 Sample: 40960000 / 53735682 Loss: 1.423737475183675\n",
      "Epoch: 0 Sample: 40970000 / 53735682 Loss: 1.5494733963094158\n",
      "Epoch: 0 Sample: 40980000 / 53735682 Loss: 1.4395709235527683\n",
      "Epoch: 0 Sample: 40990000 / 53735682 Loss: 1.4694081325536683\n",
      "Epoch: 0 Sample: 41000000 / 53735682 Loss: 1.5003074106791505\n",
      "Epoch: 0 Sample: 41010000 / 53735682 Loss: 1.4050727216705203\n",
      "Epoch: 0 Sample: 41020000 / 53735682 Loss: 1.4528849202070715\n",
      "Epoch: 0 Sample: 41030000 / 53735682 Loss: 1.4387429027831906\n",
      "Epoch: 0 Sample: 41040000 / 53735682 Loss: 1.4788015992606032\n",
      "Epoch: 0 Sample: 41050000 / 53735682 Loss: 1.4985769128822333\n",
      "Epoch: 0 Sample: 41060000 / 53735682 Loss: 1.526408650899786\n",
      "Epoch: 0 Sample: 41070000 / 53735682 Loss: 1.5635375601153871\n",
      "Epoch: 0 Sample: 41080000 / 53735682 Loss: 1.4096862187298866\n",
      "Epoch: 0 Sample: 41090000 / 53735682 Loss: 1.490671166637116\n",
      "Epoch: 0 Sample: 41100000 / 53735682 Loss: 1.5258779200961206\n",
      "Epoch: 0 Sample: 41110000 / 53735682 Loss: 1.4832978108049524\n",
      "Epoch: 0 Sample: 41120000 / 53735682 Loss: 1.4121685016284973\n",
      "Epoch: 0 Sample: 41130000 / 53735682 Loss: 1.5390085467917292\n",
      "Epoch: 0 Sample: 41140000 / 53735682 Loss: 1.5299241194640991\n",
      "Epoch: 0 Sample: 41150000 / 53735682 Loss: 1.522940366315758\n",
      "Epoch: 0 Sample: 41160000 / 53735682 Loss: 1.372086709806383\n",
      "Epoch: 0 Sample: 41170000 / 53735682 Loss: 1.4992789571392047\n",
      "Epoch: 0 Sample: 41180000 / 53735682 Loss: 1.4935306118862972\n",
      "Epoch: 0 Sample: 41190000 / 53735682 Loss: 1.510094045954618\n",
      "Epoch: 0 Sample: 41200000 / 53735682 Loss: 1.4679231804678876\n",
      "Epoch: 0 Sample: 41210000 / 53735682 Loss: 1.4982425117026223\n",
      "Epoch: 0 Sample: 41220000 / 53735682 Loss: 1.59440399058761\n",
      "Epoch: 0 Sample: 41230000 / 53735682 Loss: 1.5020793261980787\n",
      "Epoch: 0 Sample: 41240000 / 53735682 Loss: 1.4653863377043974\n",
      "Epoch: 0 Sample: 41250000 / 53735682 Loss: 1.429876138253194\n",
      "Epoch: 0 Sample: 41260000 / 53735682 Loss: 1.4979184946082882\n",
      "Epoch: 0 Sample: 41270000 / 53735682 Loss: 1.6094197537666208\n",
      "Epoch: 0 Sample: 41280000 / 53735682 Loss: 1.533793910887609\n",
      "Epoch: 0 Sample: 41290000 / 53735682 Loss: 1.4724227970105115\n",
      "Epoch: 0 Sample: 41300000 / 53735682 Loss: 1.4459467347703368\n",
      "Epoch: 0 Sample: 41310000 / 53735682 Loss: 1.4928966480008703\n",
      "Epoch: 0 Sample: 41320000 / 53735682 Loss: 1.5033116134641362\n",
      "Epoch: 0 Sample: 41330000 / 53735682 Loss: 1.5805088062953643\n",
      "Epoch: 0 Sample: 41340000 / 53735682 Loss: 1.541068518833074\n",
      "Epoch: 0 Sample: 41350000 / 53735682 Loss: 1.4940920608334531\n",
      "Epoch: 0 Sample: 41360000 / 53735682 Loss: 1.5000589187652185\n",
      "Epoch: 0 Sample: 41370000 / 53735682 Loss: 1.4872159941665837\n",
      "Epoch: 0 Sample: 41380000 / 53735682 Loss: 1.3944759698707436\n",
      "Epoch: 0 Sample: 41390000 / 53735682 Loss: 1.4307953570992322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 41400000 / 53735682 Loss: 1.511994272393911\n",
      "Epoch: 0 Sample: 41410000 / 53735682 Loss: 1.546345940578826\n",
      "Epoch: 0 Sample: 41420000 / 53735682 Loss: 1.4369403602954034\n",
      "Epoch: 0 Sample: 41430000 / 53735682 Loss: 1.51181988309681\n",
      "Epoch: 0 Sample: 41440000 / 53735682 Loss: 1.4820614622636634\n",
      "Epoch: 0 Sample: 41450000 / 53735682 Loss: 1.407976774964237\n",
      "Epoch: 0 Sample: 41460000 / 53735682 Loss: 1.470227268413904\n",
      "Epoch: 0 Sample: 41470000 / 53735682 Loss: 1.3776564394564952\n",
      "Epoch: 0 Sample: 41480000 / 53735682 Loss: 1.3713467780785114\n",
      "Epoch: 0 Sample: 41490000 / 53735682 Loss: 1.3952354699710097\n",
      "Epoch: 0 Sample: 41500000 / 53735682 Loss: 1.464496442116467\n",
      "Epoch: 0 Sample: 41510000 / 53735682 Loss: 1.5054742174136189\n",
      "Epoch: 0 Sample: 41520000 / 53735682 Loss: 1.446238735014145\n",
      "Epoch: 0 Sample: 41530000 / 53735682 Loss: 1.380309757825974\n",
      "Epoch: 0 Sample: 41540000 / 53735682 Loss: 1.4515210224923734\n",
      "Epoch: 0 Sample: 41550000 / 53735682 Loss: 1.4484643804973196\n",
      "Epoch: 0 Sample: 41560000 / 53735682 Loss: 1.4859256633971079\n",
      "Epoch: 0 Sample: 41570000 / 53735682 Loss: 1.4129694041092282\n",
      "Epoch: 0 Sample: 41580000 / 53735682 Loss: 1.5375771188703158\n",
      "Epoch: 0 Sample: 41590000 / 53735682 Loss: 1.4727529581364451\n",
      "Epoch: 0 Sample: 41600000 / 53735682 Loss: 1.4288265934474067\n",
      "Epoch: 0 Sample: 41610000 / 53735682 Loss: 1.3888308766346136\n",
      "Epoch: 0 Sample: 41620000 / 53735682 Loss: 1.4153120727499253\n",
      "Epoch: 0 Sample: 41630000 / 53735682 Loss: 1.4436558345161052\n",
      "Epoch: 0 Sample: 41640000 / 53735682 Loss: 1.528315361867893\n",
      "Epoch: 0 Sample: 41650000 / 53735682 Loss: 1.4496377180183853\n",
      "Epoch: 0 Sample: 41660000 / 53735682 Loss: 1.4591560025360564\n",
      "Epoch: 0 Sample: 41670000 / 53735682 Loss: 1.4735615050126414\n",
      "Epoch: 0 Sample: 41680000 / 53735682 Loss: 1.4319499760629903\n",
      "Epoch: 0 Sample: 41690000 / 53735682 Loss: 1.5290668366090303\n",
      "Epoch: 0 Sample: 41700000 / 53735682 Loss: 1.4675483585792715\n",
      "Epoch: 0 Sample: 41710000 / 53735682 Loss: 1.5082784950739019\n",
      "Epoch: 0 Sample: 41720000 / 53735682 Loss: 1.4665135134342306\n",
      "Epoch: 0 Sample: 41730000 / 53735682 Loss: 1.448684770645898\n",
      "Epoch: 0 Sample: 41740000 / 53735682 Loss: 1.452842344633859\n",
      "Epoch: 0 Sample: 41750000 / 53735682 Loss: 1.419598085994556\n",
      "Epoch: 0 Sample: 41760000 / 53735682 Loss: 1.4500228315777686\n",
      "Epoch: 0 Sample: 41770000 / 53735682 Loss: 1.4690344104713502\n",
      "Epoch: 0 Sample: 41780000 / 53735682 Loss: 1.5306493822934917\n",
      "Epoch: 0 Sample: 41790000 / 53735682 Loss: 1.4817494495813468\n",
      "Epoch: 0 Sample: 41800000 / 53735682 Loss: 1.4397361759543577\n",
      "Epoch: 0 Sample: 41810000 / 53735682 Loss: 1.4312487928411228\n",
      "Epoch: 0 Sample: 41820000 / 53735682 Loss: 1.5108275544804983\n",
      "Epoch: 0 Sample: 41830000 / 53735682 Loss: 1.4705968023091962\n",
      "Epoch: 0 Sample: 41840000 / 53735682 Loss: 1.4722917690928317\n",
      "Epoch: 0 Sample: 41850000 / 53735682 Loss: 1.3911381911213117\n",
      "Epoch: 0 Sample: 41860000 / 53735682 Loss: 1.4480188208200366\n",
      "Epoch: 0 Sample: 41870000 / 53735682 Loss: 1.450635016106354\n",
      "Epoch: 0 Sample: 41880000 / 53735682 Loss: 1.4788899204022194\n",
      "Epoch: 0 Sample: 41890000 / 53735682 Loss: 1.4969045301604083\n",
      "Epoch: 0 Sample: 41900000 / 53735682 Loss: 1.4351733601859809\n",
      "Epoch: 0 Sample: 41910000 / 53735682 Loss: 1.422589023350773\n",
      "Epoch: 0 Sample: 41920000 / 53735682 Loss: 1.412355834071318\n",
      "Epoch: 0 Sample: 41930000 / 53735682 Loss: 1.5316961052949911\n",
      "Epoch: 0 Sample: 41940000 / 53735682 Loss: 1.4171605429047704\n",
      "Epoch: 0 Sample: 41950000 / 53735682 Loss: 1.4688145426443486\n",
      "Epoch: 0 Sample: 41960000 / 53735682 Loss: 1.4826449420965806\n",
      "Epoch: 0 Sample: 41970000 / 53735682 Loss: 1.3790929770270324\n",
      "Epoch: 0 Sample: 41980000 / 53735682 Loss: 1.5154201507721317\n",
      "Epoch: 0 Sample: 41990000 / 53735682 Loss: 1.4304331336168583\n",
      "Epoch: 0 Sample: 42000000 / 53735682 Loss: 1.3546280286479648\n",
      "Epoch: 0 Sample: 42010000 / 53735682 Loss: 1.454792754930701\n",
      "Epoch: 0 Sample: 42020000 / 53735682 Loss: 1.4570931960173852\n",
      "Epoch: 0 Sample: 42030000 / 53735682 Loss: 1.4481932763308973\n",
      "Epoch: 0 Sample: 42040000 / 53735682 Loss: 1.5281378843162832\n",
      "Epoch: 0 Sample: 42050000 / 53735682 Loss: 1.4020006996082715\n",
      "Epoch: 0 Sample: 42060000 / 53735682 Loss: 1.5172442530989778\n",
      "Epoch: 0 Sample: 42070000 / 53735682 Loss: 1.4966472158809\n",
      "Epoch: 0 Sample: 42080000 / 53735682 Loss: 1.4979423151390319\n",
      "Epoch: 0 Sample: 42090000 / 53735682 Loss: 1.5211703271249692\n",
      "Epoch: 0 Sample: 42100000 / 53735682 Loss: 1.4479258209149637\n",
      "Epoch: 0 Sample: 42110000 / 53735682 Loss: 1.479700740403253\n",
      "Epoch: 0 Sample: 42120000 / 53735682 Loss: 1.4630641943576883\n",
      "Epoch: 0 Sample: 42130000 / 53735682 Loss: 1.4526035891470177\n",
      "Epoch: 0 Sample: 42140000 / 53735682 Loss: 1.4956847087423153\n",
      "Epoch: 0 Sample: 42150000 / 53735682 Loss: 1.3960615981556446\n",
      "Epoch: 0 Sample: 42160000 / 53735682 Loss: 1.4412144618290104\n",
      "Epoch: 0 Sample: 42170000 / 53735682 Loss: 1.4934135939087785\n",
      "Epoch: 0 Sample: 42180000 / 53735682 Loss: 1.5764637181875574\n",
      "Epoch: 0 Sample: 42190000 / 53735682 Loss: 1.450675561913291\n",
      "Epoch: 0 Sample: 42200000 / 53735682 Loss: 1.4282375514453227\n",
      "Epoch: 0 Sample: 42210000 / 53735682 Loss: 1.4154348131851036\n",
      "Epoch: 0 Sample: 42220000 / 53735682 Loss: 1.4302859985434215\n",
      "Epoch: 0 Sample: 42230000 / 53735682 Loss: 1.498374882471396\n",
      "Epoch: 0 Sample: 42240000 / 53735682 Loss: 1.551405462805458\n",
      "Epoch: 0 Sample: 42250000 / 53735682 Loss: 1.4930509248435127\n",
      "Epoch: 0 Sample: 42260000 / 53735682 Loss: 1.445390714185554\n",
      "Epoch: 0 Sample: 42270000 / 53735682 Loss: 1.4918422383710785\n",
      "Epoch: 0 Sample: 42280000 / 53735682 Loss: 1.4120289433238071\n",
      "Epoch: 0 Sample: 42290000 / 53735682 Loss: 1.5241737659484802\n",
      "Epoch: 0 Sample: 42300000 / 53735682 Loss: 1.3929518943813888\n",
      "Epoch: 0 Sample: 42310000 / 53735682 Loss: 1.40688701733437\n",
      "Epoch: 0 Sample: 42320000 / 53735682 Loss: 1.4872520823386557\n",
      "Epoch: 0 Sample: 42330000 / 53735682 Loss: 1.5223928890575547\n",
      "Epoch: 0 Sample: 42340000 / 53735682 Loss: 1.5274194196209863\n",
      "Epoch: 0 Sample: 42350000 / 53735682 Loss: 1.462297069335569\n",
      "Epoch: 0 Sample: 42360000 / 53735682 Loss: 1.4257725649550959\n",
      "Epoch: 0 Sample: 42370000 / 53735682 Loss: 1.49823391568713\n",
      "Epoch: 0 Sample: 42380000 / 53735682 Loss: 1.4118900675976462\n",
      "Epoch: 0 Sample: 42390000 / 53735682 Loss: 1.4826325265625908\n",
      "Epoch: 0 Sample: 42400000 / 53735682 Loss: 1.4441249229162083\n",
      "Epoch: 0 Sample: 42410000 / 53735682 Loss: 1.4787345967978092\n",
      "Epoch: 0 Sample: 42420000 / 53735682 Loss: 1.4001069217561812\n",
      "Epoch: 0 Sample: 42430000 / 53735682 Loss: 1.5380092529805267\n",
      "Epoch: 0 Sample: 42440000 / 53735682 Loss: 1.4180425523058064\n",
      "Epoch: 0 Sample: 42450000 / 53735682 Loss: 1.5067064494016793\n",
      "Epoch: 0 Sample: 42460000 / 53735682 Loss: 1.5613452736034175\n",
      "Epoch: 0 Sample: 42470000 / 53735682 Loss: 1.4411297760904307\n",
      "Epoch: 0 Sample: 42480000 / 53735682 Loss: 1.5157096846205835\n",
      "Epoch: 0 Sample: 42490000 / 53735682 Loss: 1.4681259464943919\n",
      "Epoch: 0 Sample: 42500000 / 53735682 Loss: 1.4688901191092136\n",
      "Epoch: 0 Sample: 42510000 / 53735682 Loss: 1.52260959129946\n",
      "Epoch: 0 Sample: 42520000 / 53735682 Loss: 1.4436111055214342\n",
      "Epoch: 0 Sample: 42530000 / 53735682 Loss: 1.4605216297297583\n",
      "Epoch: 0 Sample: 42540000 / 53735682 Loss: 1.4981489714870266\n",
      "Epoch: 0 Sample: 42550000 / 53735682 Loss: 1.385679908193316\n",
      "Epoch: 0 Sample: 42560000 / 53735682 Loss: 1.4801941393068034\n",
      "Epoch: 0 Sample: 42570000 / 53735682 Loss: 1.3718275838493068\n",
      "Epoch: 0 Sample: 42580000 / 53735682 Loss: 1.4384406524862854\n",
      "Epoch: 0 Sample: 42590000 / 53735682 Loss: 1.4578021528572926\n",
      "Epoch: 0 Sample: 42600000 / 53735682 Loss: 1.4203229047671253\n",
      "Epoch: 0 Sample: 42610000 / 53735682 Loss: 1.4637815052707936\n",
      "Epoch: 0 Sample: 42620000 / 53735682 Loss: 1.4854257695465605\n",
      "Epoch: 0 Sample: 42630000 / 53735682 Loss: 1.4229704321211731\n",
      "Epoch: 0 Sample: 42640000 / 53735682 Loss: 1.542244707403513\n",
      "Epoch: 0 Sample: 42650000 / 53735682 Loss: 1.4946915851984595\n",
      "Epoch: 0 Sample: 42660000 / 53735682 Loss: 1.4650913148808125\n",
      "Epoch: 0 Sample: 42670000 / 53735682 Loss: 1.3930989314704256\n",
      "Epoch: 0 Sample: 42680000 / 53735682 Loss: 1.4674638791730792\n",
      "Epoch: 0 Sample: 42690000 / 53735682 Loss: 1.5229570823785334\n",
      "Epoch: 0 Sample: 42700000 / 53735682 Loss: 1.4545208643338008\n",
      "Epoch: 0 Sample: 42710000 / 53735682 Loss: 1.4233164032262686\n",
      "Epoch: 0 Sample: 42720000 / 53735682 Loss: 1.4447593412869078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 42730000 / 53735682 Loss: 1.4478934413708417\n",
      "Epoch: 0 Sample: 42740000 / 53735682 Loss: 1.453960867607291\n",
      "Epoch: 0 Sample: 42750000 / 53735682 Loss: 1.5096928385331643\n",
      "Epoch: 0 Sample: 42760000 / 53735682 Loss: 1.4542757909519337\n",
      "Epoch: 0 Sample: 42770000 / 53735682 Loss: 1.3932060999624754\n",
      "Epoch: 0 Sample: 42780000 / 53735682 Loss: 1.6291828165937345\n",
      "Epoch: 0 Sample: 42790000 / 53735682 Loss: 1.4498336024711957\n",
      "Epoch: 0 Sample: 42800000 / 53735682 Loss: 1.4612339112495176\n",
      "Epoch: 0 Sample: 42810000 / 53735682 Loss: 1.5605336864682522\n",
      "Epoch: 0 Sample: 42820000 / 53735682 Loss: 1.507800353086619\n",
      "Epoch: 0 Sample: 42830000 / 53735682 Loss: 1.5143758009959805\n",
      "Epoch: 0 Sample: 42840000 / 53735682 Loss: 1.4723073190386127\n",
      "Epoch: 0 Sample: 42850000 / 53735682 Loss: 1.4987702086325\n",
      "Epoch: 0 Sample: 42860000 / 53735682 Loss: 1.4052519189116472\n",
      "Epoch: 0 Sample: 42870000 / 53735682 Loss: 1.4552957978016643\n",
      "Epoch: 0 Sample: 42880000 / 53735682 Loss: 1.5057999172857461\n",
      "Epoch: 0 Sample: 42890000 / 53735682 Loss: 1.4670274820836378\n",
      "Epoch: 0 Sample: 42900000 / 53735682 Loss: 1.51302920149205\n",
      "Epoch: 0 Sample: 42910000 / 53735682 Loss: 1.4948473984897248\n",
      "Epoch: 0 Sample: 42920000 / 53735682 Loss: 1.5157878416811505\n",
      "Epoch: 0 Sample: 42930000 / 53735682 Loss: 1.4858168672077945\n",
      "Epoch: 0 Sample: 42940000 / 53735682 Loss: 1.5137103205628764\n",
      "Epoch: 0 Sample: 42950000 / 53735682 Loss: 1.5391093846909791\n",
      "Epoch: 0 Sample: 42960000 / 53735682 Loss: 1.4308762202950753\n",
      "Epoch: 0 Sample: 42970000 / 53735682 Loss: 1.431659382808058\n",
      "Epoch: 0 Sample: 42980000 / 53735682 Loss: 1.428675548858913\n",
      "Epoch: 0 Sample: 42990000 / 53735682 Loss: 1.482350392733275\n",
      "Epoch: 0 Sample: 43000000 / 53735682 Loss: 1.4672397572249862\n",
      "Epoch: 0 Sample: 43010000 / 53735682 Loss: 1.4775808314736314\n",
      "Epoch: 0 Sample: 43020000 / 53735682 Loss: 1.415151311836953\n",
      "Epoch: 0 Sample: 43030000 / 53735682 Loss: 1.4392807434736703\n",
      "Epoch: 0 Sample: 43040000 / 53735682 Loss: 1.4806669138311532\n",
      "Epoch: 0 Sample: 43050000 / 53735682 Loss: 1.4472521753632877\n",
      "Epoch: 0 Sample: 43060000 / 53735682 Loss: 1.4534479835211593\n",
      "Epoch: 0 Sample: 43070000 / 53735682 Loss: 1.5065507479627929\n",
      "Epoch: 0 Sample: 43080000 / 53735682 Loss: 1.4834697419621548\n",
      "Epoch: 0 Sample: 43090000 / 53735682 Loss: 1.4873497725908043\n",
      "Epoch: 0 Sample: 43100000 / 53735682 Loss: 1.442444371844383\n",
      "Epoch: 0 Sample: 43110000 / 53735682 Loss: 1.4403405186639475\n",
      "Epoch: 0 Sample: 43120000 / 53735682 Loss: 1.5722840725419156\n",
      "Epoch: 0 Sample: 43130000 / 53735682 Loss: 1.4926865207792073\n",
      "Epoch: 0 Sample: 43140000 / 53735682 Loss: 1.4491238989155615\n",
      "Epoch: 0 Sample: 43150000 / 53735682 Loss: 1.425680062555342\n",
      "Epoch: 0 Sample: 43160000 / 53735682 Loss: 1.482608538443909\n",
      "Epoch: 0 Sample: 43170000 / 53735682 Loss: 1.4826703596726318\n",
      "Epoch: 0 Sample: 43180000 / 53735682 Loss: 1.4805429204156593\n",
      "Epoch: 0 Sample: 43190000 / 53735682 Loss: 1.4315398950764207\n",
      "Epoch: 0 Sample: 43200000 / 53735682 Loss: 1.439856228935285\n",
      "Epoch: 0 Sample: 43210000 / 53735682 Loss: 1.4856525295249166\n",
      "Epoch: 0 Sample: 43220000 / 53735682 Loss: 1.4171038086216792\n",
      "Epoch: 0 Sample: 43230000 / 53735682 Loss: 1.557835438899772\n",
      "Epoch: 0 Sample: 43240000 / 53735682 Loss: 1.496475220300788\n",
      "Epoch: 0 Sample: 43250000 / 53735682 Loss: 1.4350771495774852\n",
      "Epoch: 0 Sample: 43260000 / 53735682 Loss: 1.362252046202562\n",
      "Epoch: 0 Sample: 43270000 / 53735682 Loss: 1.4852597923331303\n",
      "Epoch: 0 Sample: 43280000 / 53735682 Loss: 1.4610758089874434\n",
      "Epoch: 0 Sample: 43290000 / 53735682 Loss: 1.4158779915108628\n",
      "Epoch: 0 Sample: 43300000 / 53735682 Loss: 1.489776919569394\n",
      "Epoch: 0 Sample: 43310000 / 53735682 Loss: 1.4200026941384696\n",
      "Epoch: 0 Sample: 43320000 / 53735682 Loss: 1.4797376117317955\n",
      "Epoch: 0 Sample: 43330000 / 53735682 Loss: 1.535457788968186\n",
      "Epoch: 0 Sample: 43340000 / 53735682 Loss: 1.5121696945889076\n",
      "Epoch: 0 Sample: 43350000 / 53735682 Loss: 1.4296888894173856\n",
      "Epoch: 0 Sample: 43360000 / 53735682 Loss: 1.4131405210654606\n",
      "Epoch: 0 Sample: 43370000 / 53735682 Loss: 1.4215943740689272\n",
      "Epoch: 0 Sample: 43380000 / 53735682 Loss: 1.5237658147656243\n",
      "Epoch: 0 Sample: 43390000 / 53735682 Loss: 1.5841090877155448\n",
      "Epoch: 0 Sample: 43400000 / 53735682 Loss: 1.437180505102816\n",
      "Epoch: 0 Sample: 43410000 / 53735682 Loss: 1.5019351424778673\n",
      "Epoch: 0 Sample: 43420000 / 53735682 Loss: 1.3992522444519562\n",
      "Epoch: 0 Sample: 43430000 / 53735682 Loss: 1.4939730752582787\n",
      "Epoch: 0 Sample: 43440000 / 53735682 Loss: 1.3919105395800162\n",
      "Epoch: 0 Sample: 43450000 / 53735682 Loss: 1.5011491940605708\n",
      "Epoch: 0 Sample: 43460000 / 53735682 Loss: 1.4008630712645889\n",
      "Epoch: 0 Sample: 43470000 / 53735682 Loss: 1.4535816842055211\n",
      "Epoch: 0 Sample: 43480000 / 53735682 Loss: 1.4967934211481961\n",
      "Epoch: 0 Sample: 43490000 / 53735682 Loss: 1.4884858080003398\n",
      "Epoch: 0 Sample: 43500000 / 53735682 Loss: 1.3926223556457513\n",
      "Epoch: 0 Sample: 43510000 / 53735682 Loss: 1.4029658210487765\n",
      "Epoch: 0 Sample: 43520000 / 53735682 Loss: 1.4268904939394509\n",
      "Epoch: 0 Sample: 43530000 / 53735682 Loss: 1.5173519889502078\n",
      "Epoch: 0 Sample: 43540000 / 53735682 Loss: 1.5233130841225193\n",
      "Epoch: 0 Sample: 43550000 / 53735682 Loss: 1.4455022223027574\n",
      "Epoch: 0 Sample: 43560000 / 53735682 Loss: 1.4351584805327149\n",
      "Epoch: 0 Sample: 43570000 / 53735682 Loss: 1.498499323875215\n",
      "Epoch: 0 Sample: 43580000 / 53735682 Loss: 1.4601752118421074\n",
      "Epoch: 0 Sample: 43590000 / 53735682 Loss: 1.4463166930016744\n",
      "Epoch: 0 Sample: 43600000 / 53735682 Loss: 1.4243308167732227\n",
      "Epoch: 0 Sample: 43610000 / 53735682 Loss: 1.5194638219140204\n",
      "Epoch: 0 Sample: 43620000 / 53735682 Loss: 1.557342705933414\n",
      "Epoch: 0 Sample: 43630000 / 53735682 Loss: 1.4180356782990076\n",
      "Epoch: 0 Sample: 43640000 / 53735682 Loss: 1.5136697148136715\n",
      "Epoch: 0 Sample: 43650000 / 53735682 Loss: 1.4462650698597628\n",
      "Epoch: 0 Sample: 43660000 / 53735682 Loss: 1.4442517409462092\n",
      "Epoch: 0 Sample: 43670000 / 53735682 Loss: 1.5282634256363063\n",
      "Epoch: 0 Sample: 43680000 / 53735682 Loss: 1.4172491837759202\n",
      "Epoch: 0 Sample: 43690000 / 53735682 Loss: 1.5752584537350889\n",
      "Epoch: 0 Sample: 43700000 / 53735682 Loss: 1.5273582274642976\n",
      "Epoch: 0 Sample: 43710000 / 53735682 Loss: 1.4311360006392944\n",
      "Epoch: 0 Sample: 43720000 / 53735682 Loss: 1.4039547500735177\n",
      "Epoch: 0 Sample: 43730000 / 53735682 Loss: 1.494122574220503\n",
      "Epoch: 0 Sample: 43740000 / 53735682 Loss: 1.3767820407370963\n",
      "Epoch: 0 Sample: 43750000 / 53735682 Loss: 1.5760116441972478\n",
      "Epoch: 0 Sample: 43760000 / 53735682 Loss: 1.3785516165732465\n",
      "Epoch: 0 Sample: 43770000 / 53735682 Loss: 1.5142218678986956\n",
      "Epoch: 0 Sample: 43780000 / 53735682 Loss: 1.4446425320339613\n",
      "Epoch: 0 Sample: 43790000 / 53735682 Loss: 1.4570781492016716\n",
      "Epoch: 0 Sample: 43800000 / 53735682 Loss: 1.444059354665442\n",
      "Epoch: 0 Sample: 43810000 / 53735682 Loss: 1.450326096921683\n",
      "Epoch: 0 Sample: 43820000 / 53735682 Loss: 1.461979749060479\n",
      "Epoch: 0 Sample: 43830000 / 53735682 Loss: 1.4622864943874863\n",
      "Epoch: 0 Sample: 43840000 / 53735682 Loss: 1.5378801554630346\n",
      "Epoch: 0 Sample: 43850000 / 53735682 Loss: 1.558903771870049\n",
      "Epoch: 0 Sample: 43860000 / 53735682 Loss: 1.4908169287666482\n",
      "Epoch: 0 Sample: 43870000 / 53735682 Loss: 1.4511443704024485\n",
      "Epoch: 0 Sample: 43880000 / 53735682 Loss: 1.4812237088469142\n",
      "Epoch: 0 Sample: 43890000 / 53735682 Loss: 1.4350820106965854\n",
      "Epoch: 0 Sample: 43900000 / 53735682 Loss: 1.442517528944693\n",
      "Epoch: 0 Sample: 43910000 / 53735682 Loss: 1.4327670390150606\n",
      "Epoch: 0 Sample: 43920000 / 53735682 Loss: 1.4645396918961993\n",
      "Epoch: 0 Sample: 43930000 / 53735682 Loss: 1.4741849820646937\n",
      "Epoch: 0 Sample: 43940000 / 53735682 Loss: 1.4677836396999537\n",
      "Epoch: 0 Sample: 43950000 / 53735682 Loss: 1.4746327836355917\n",
      "Epoch: 0 Sample: 43960000 / 53735682 Loss: 1.5666355221545494\n",
      "Epoch: 0 Sample: 43970000 / 53735682 Loss: 1.526120821098214\n",
      "Epoch: 0 Sample: 43980000 / 53735682 Loss: 1.4759798111144184\n",
      "Epoch: 0 Sample: 43990000 / 53735682 Loss: 1.453472889029465\n",
      "Epoch: 0 Sample: 44000000 / 53735682 Loss: 1.4968487093531078\n",
      "Epoch: 0 Sample: 44010000 / 53735682 Loss: 1.501085531707624\n",
      "Epoch: 0 Sample: 44020000 / 53735682 Loss: 1.5303090580905299\n",
      "Epoch: 0 Sample: 44030000 / 53735682 Loss: 1.4270231684109715\n",
      "Epoch: 0 Sample: 44040000 / 53735682 Loss: 1.482245588668904\n",
      "Epoch: 0 Sample: 44050000 / 53735682 Loss: 1.4906570408501585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 44060000 / 53735682 Loss: 1.5470849285958488\n",
      "Epoch: 0 Sample: 44070000 / 53735682 Loss: 1.5351538145222747\n",
      "Epoch: 0 Sample: 44080000 / 53735682 Loss: 1.4699825685106584\n",
      "Epoch: 0 Sample: 44090000 / 53735682 Loss: 1.421954404806385\n",
      "Epoch: 0 Sample: 44100000 / 53735682 Loss: 1.5482986007866377\n",
      "Epoch: 0 Sample: 44110000 / 53735682 Loss: 1.4613551730540202\n",
      "Epoch: 0 Sample: 44120000 / 53735682 Loss: 1.4893502030370915\n",
      "Epoch: 0 Sample: 44130000 / 53735682 Loss: 1.489147470273669\n",
      "Epoch: 0 Sample: 44140000 / 53735682 Loss: 1.5425894990911833\n",
      "Epoch: 0 Sample: 44150000 / 53735682 Loss: 1.4509715438651913\n",
      "Epoch: 0 Sample: 44160000 / 53735682 Loss: 1.4924197852302856\n",
      "Epoch: 0 Sample: 44170000 / 53735682 Loss: 1.5375027710975058\n",
      "Epoch: 0 Sample: 44180000 / 53735682 Loss: 1.5232260312941983\n",
      "Epoch: 0 Sample: 44190000 / 53735682 Loss: 1.508365128963808\n",
      "Epoch: 0 Sample: 44200000 / 53735682 Loss: 1.4617090880445878\n",
      "Epoch: 0 Sample: 44210000 / 53735682 Loss: 1.451166076745722\n",
      "Epoch: 0 Sample: 44220000 / 53735682 Loss: 1.4767930028375078\n",
      "Epoch: 0 Sample: 44230000 / 53735682 Loss: 1.4658122291008273\n",
      "Epoch: 0 Sample: 44240000 / 53735682 Loss: 1.449173125636956\n",
      "Epoch: 0 Sample: 44250000 / 53735682 Loss: 1.368359629419901\n",
      "Epoch: 0 Sample: 44260000 / 53735682 Loss: 1.54869551317466\n",
      "Epoch: 0 Sample: 44270000 / 53735682 Loss: 1.5138671312050782\n",
      "Epoch: 0 Sample: 44280000 / 53735682 Loss: 1.4384005245173048\n",
      "Epoch: 0 Sample: 44290000 / 53735682 Loss: 1.4913404478340153\n",
      "Epoch: 0 Sample: 44300000 / 53735682 Loss: 1.53072103205441\n",
      "Epoch: 0 Sample: 44310000 / 53735682 Loss: 1.4778223874510137\n",
      "Epoch: 0 Sample: 44320000 / 53735682 Loss: 1.4400402842212057\n",
      "Epoch: 0 Sample: 44330000 / 53735682 Loss: 1.4802975725541612\n",
      "Epoch: 0 Sample: 44340000 / 53735682 Loss: 1.4533155771436088\n",
      "Epoch: 0 Sample: 44350000 / 53735682 Loss: 1.550832310208101\n",
      "Epoch: 0 Sample: 44360000 / 53735682 Loss: 1.4975354754064814\n",
      "Epoch: 0 Sample: 44370000 / 53735682 Loss: 1.508209336744314\n",
      "Epoch: 0 Sample: 44380000 / 53735682 Loss: 1.5174139048707906\n",
      "Epoch: 0 Sample: 44390000 / 53735682 Loss: 1.4295200908584695\n",
      "Epoch: 0 Sample: 44400000 / 53735682 Loss: 1.4290257050117992\n",
      "Epoch: 0 Sample: 44410000 / 53735682 Loss: 1.4768280662370277\n",
      "Epoch: 0 Sample: 44420000 / 53735682 Loss: 1.3930603918272335\n",
      "Epoch: 0 Sample: 44430000 / 53735682 Loss: 1.4861966871617\n",
      "Epoch: 0 Sample: 44440000 / 53735682 Loss: 1.4540751428042802\n",
      "Epoch: 0 Sample: 44450000 / 53735682 Loss: 1.4918951525272734\n",
      "Epoch: 0 Sample: 44460000 / 53735682 Loss: 1.4584608648571717\n",
      "Epoch: 0 Sample: 44470000 / 53735682 Loss: 1.4959194968071965\n",
      "Epoch: 0 Sample: 44480000 / 53735682 Loss: 1.4650705031362918\n",
      "Epoch: 0 Sample: 44490000 / 53735682 Loss: 1.533991849748428\n",
      "Epoch: 0 Sample: 44500000 / 53735682 Loss: 1.5196111713352307\n",
      "Epoch: 0 Sample: 44510000 / 53735682 Loss: 1.4006757206958707\n",
      "Epoch: 0 Sample: 44520000 / 53735682 Loss: 1.4897364403724151\n",
      "Epoch: 0 Sample: 44530000 / 53735682 Loss: 1.5220327729193728\n",
      "Epoch: 0 Sample: 44540000 / 53735682 Loss: 1.5112555549995568\n",
      "Epoch: 0 Sample: 44550000 / 53735682 Loss: 1.4894526404816575\n",
      "Epoch: 0 Sample: 44560000 / 53735682 Loss: 1.4883347723028884\n",
      "Epoch: 0 Sample: 44570000 / 53735682 Loss: 1.4226666961408552\n",
      "Epoch: 0 Sample: 44580000 / 53735682 Loss: 1.4254320208036888\n",
      "Epoch: 0 Sample: 44590000 / 53735682 Loss: 1.5529403660696817\n",
      "Epoch: 0 Sample: 44600000 / 53735682 Loss: 1.5479106460941898\n",
      "Epoch: 0 Sample: 44610000 / 53735682 Loss: 1.4710882524255962\n",
      "Epoch: 0 Sample: 44620000 / 53735682 Loss: 1.3977102229624974\n",
      "Epoch: 0 Sample: 44630000 / 53735682 Loss: 1.4777852660157471\n",
      "Epoch: 0 Sample: 44640000 / 53735682 Loss: 1.4813485402217175\n",
      "Epoch: 0 Sample: 44650000 / 53735682 Loss: 1.4466098719070664\n",
      "Epoch: 0 Sample: 44660000 / 53735682 Loss: 1.5509226713225224\n",
      "Epoch: 0 Sample: 44670000 / 53735682 Loss: 1.480008279130422\n",
      "Epoch: 0 Sample: 44680000 / 53735682 Loss: 1.4589969894143953\n",
      "Epoch: 0 Sample: 44690000 / 53735682 Loss: 1.3513611230203195\n",
      "Epoch: 0 Sample: 44700000 / 53735682 Loss: 1.4748392708005371\n",
      "Epoch: 0 Sample: 44710000 / 53735682 Loss: 1.4534048244659252\n",
      "Epoch: 0 Sample: 44720000 / 53735682 Loss: 1.4430345704968262\n",
      "Epoch: 0 Sample: 44730000 / 53735682 Loss: 1.490570173401703\n",
      "Epoch: 0 Sample: 44740000 / 53735682 Loss: 1.39529527705922\n",
      "Epoch: 0 Sample: 44750000 / 53735682 Loss: 1.4915722577560353\n",
      "Epoch: 0 Sample: 44760000 / 53735682 Loss: 1.48415521011294\n",
      "Epoch: 0 Sample: 44770000 / 53735682 Loss: 1.53868464756758\n",
      "Epoch: 0 Sample: 44780000 / 53735682 Loss: 1.5001269819443448\n",
      "Epoch: 0 Sample: 44790000 / 53735682 Loss: 1.527189307549592\n",
      "Epoch: 0 Sample: 44800000 / 53735682 Loss: 1.4967582804492947\n",
      "Epoch: 0 Sample: 44810000 / 53735682 Loss: 1.4902712910861955\n",
      "Epoch: 0 Sample: 44820000 / 53735682 Loss: 1.5205823235778229\n",
      "Epoch: 0 Sample: 44830000 / 53735682 Loss: 1.5408584060842125\n",
      "Epoch: 0 Sample: 44840000 / 53735682 Loss: 1.4776139486760438\n",
      "Epoch: 0 Sample: 44850000 / 53735682 Loss: 1.4396706359481637\n",
      "Epoch: 0 Sample: 44860000 / 53735682 Loss: 1.5724682178013598\n",
      "Epoch: 0 Sample: 44870000 / 53735682 Loss: 1.5030662626158044\n",
      "Epoch: 0 Sample: 44880000 / 53735682 Loss: 1.4668699250680048\n",
      "Epoch: 0 Sample: 44890000 / 53735682 Loss: 1.5212326517288735\n",
      "Epoch: 0 Sample: 44900000 / 53735682 Loss: 1.4960784781748067\n",
      "Epoch: 0 Sample: 44910000 / 53735682 Loss: 1.4864314492083335\n",
      "Epoch: 0 Sample: 44920000 / 53735682 Loss: 1.51917495578255\n",
      "Epoch: 0 Sample: 44930000 / 53735682 Loss: 1.4820351975512585\n",
      "Epoch: 0 Sample: 44940000 / 53735682 Loss: 1.511657235737119\n",
      "Epoch: 0 Sample: 44950000 / 53735682 Loss: 1.403224495490338\n",
      "Epoch: 0 Sample: 44960000 / 53735682 Loss: 1.5437510766851208\n",
      "Epoch: 0 Sample: 44970000 / 53735682 Loss: 1.4903275920120103\n",
      "Epoch: 0 Sample: 44980000 / 53735682 Loss: 1.464734538031938\n",
      "Epoch: 0 Sample: 44990000 / 53735682 Loss: 1.4874830329799167\n",
      "Epoch: 0 Sample: 45000000 / 53735682 Loss: 1.5425523862376838\n",
      "Epoch: 0 Sample: 45010000 / 53735682 Loss: 1.477886484758443\n",
      "Epoch: 0 Sample: 45020000 / 53735682 Loss: 1.4832653080300031\n",
      "Epoch: 0 Sample: 45030000 / 53735682 Loss: 1.4947426664325791\n",
      "Epoch: 0 Sample: 45040000 / 53735682 Loss: 1.4997145556158347\n",
      "Epoch: 0 Sample: 45050000 / 53735682 Loss: 1.4550075678925039\n",
      "Epoch: 0 Sample: 45060000 / 53735682 Loss: 1.5079063884476334\n",
      "Epoch: 0 Sample: 45070000 / 53735682 Loss: 1.446469401610909\n",
      "Epoch: 0 Sample: 45080000 / 53735682 Loss: 1.475170720312132\n",
      "Epoch: 0 Sample: 45090000 / 53735682 Loss: 1.4652688688239566\n",
      "Epoch: 0 Sample: 45100000 / 53735682 Loss: 1.4811171406425707\n",
      "Epoch: 0 Sample: 45110000 / 53735682 Loss: 1.4927913458005815\n",
      "Epoch: 0 Sample: 45120000 / 53735682 Loss: 1.4366818261254872\n",
      "Epoch: 0 Sample: 45130000 / 53735682 Loss: 1.4088377399745573\n",
      "Epoch: 0 Sample: 45140000 / 53735682 Loss: 1.5202227851813697\n",
      "Epoch: 0 Sample: 45150000 / 53735682 Loss: 1.5399756668064275\n",
      "Epoch: 0 Sample: 45160000 / 53735682 Loss: 1.5505147475065988\n",
      "Epoch: 0 Sample: 45170000 / 53735682 Loss: 1.6092513484601958\n",
      "Epoch: 0 Sample: 45180000 / 53735682 Loss: 1.5023572754630297\n",
      "Epoch: 0 Sample: 45190000 / 53735682 Loss: 1.4846936033467246\n",
      "Epoch: 0 Sample: 45200000 / 53735682 Loss: 1.5649732830667342\n",
      "Epoch: 0 Sample: 45210000 / 53735682 Loss: 1.4654253769836703\n",
      "Epoch: 0 Sample: 45220000 / 53735682 Loss: 1.4994610330809075\n",
      "Epoch: 0 Sample: 45230000 / 53735682 Loss: 1.4849100933385724\n",
      "Epoch: 0 Sample: 45240000 / 53735682 Loss: 1.4021105498900064\n",
      "Epoch: 0 Sample: 45250000 / 53735682 Loss: 1.5396667733139733\n",
      "Epoch: 0 Sample: 45260000 / 53735682 Loss: 1.505637882692734\n",
      "Epoch: 0 Sample: 45270000 / 53735682 Loss: 1.5073514235233496\n",
      "Epoch: 0 Sample: 45280000 / 53735682 Loss: 1.4327868066531178\n",
      "Epoch: 0 Sample: 45290000 / 53735682 Loss: 1.4831428813561356\n",
      "Epoch: 0 Sample: 45300000 / 53735682 Loss: 1.4903583954479205\n",
      "Epoch: 0 Sample: 45310000 / 53735682 Loss: 1.420403719182751\n",
      "Epoch: 0 Sample: 45320000 / 53735682 Loss: 1.4199578669495185\n",
      "Epoch: 0 Sample: 45330000 / 53735682 Loss: 1.3990357848177308\n",
      "Epoch: 0 Sample: 45340000 / 53735682 Loss: 1.4607969458761618\n",
      "Epoch: 0 Sample: 45350000 / 53735682 Loss: 1.4384792695294535\n",
      "Epoch: 0 Sample: 45360000 / 53735682 Loss: 1.4467719800263872\n",
      "Epoch: 0 Sample: 45370000 / 53735682 Loss: 1.4556066604006883\n",
      "Epoch: 0 Sample: 45380000 / 53735682 Loss: 1.5126580436483057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 45390000 / 53735682 Loss: 1.4924391118778741\n",
      "Epoch: 0 Sample: 45400000 / 53735682 Loss: 1.464599992519907\n",
      "Epoch: 0 Sample: 45410000 / 53735682 Loss: 1.502396458645379\n",
      "Epoch: 0 Sample: 45420000 / 53735682 Loss: 1.4590825273116046\n",
      "Epoch: 0 Sample: 45430000 / 53735682 Loss: 1.5019357819394807\n",
      "Epoch: 0 Sample: 45440000 / 53735682 Loss: 1.5243403859668745\n",
      "Epoch: 0 Sample: 45450000 / 53735682 Loss: 1.4989598920705616\n",
      "Epoch: 0 Sample: 45460000 / 53735682 Loss: 1.503532017688869\n",
      "Epoch: 0 Sample: 45470000 / 53735682 Loss: 1.516217755854035\n",
      "Epoch: 0 Sample: 45480000 / 53735682 Loss: 1.5038060371936681\n",
      "Epoch: 0 Sample: 45490000 / 53735682 Loss: 1.4538417900011378\n",
      "Epoch: 0 Sample: 45500000 / 53735682 Loss: 1.5245715543178293\n",
      "Epoch: 0 Sample: 45510000 / 53735682 Loss: 1.475651294071693\n",
      "Epoch: 0 Sample: 45520000 / 53735682 Loss: 1.3897263081891587\n",
      "Epoch: 0 Sample: 45530000 / 53735682 Loss: 1.4819164054596143\n",
      "Epoch: 0 Sample: 45540000 / 53735682 Loss: 1.5091249065727972\n",
      "Epoch: 0 Sample: 45550000 / 53735682 Loss: 1.5168532358651219\n",
      "Epoch: 0 Sample: 45560000 / 53735682 Loss: 1.508038622206823\n",
      "Epoch: 0 Sample: 45570000 / 53735682 Loss: 1.4458066895514605\n",
      "Epoch: 0 Sample: 45580000 / 53735682 Loss: 1.5398425357360546\n",
      "Epoch: 0 Sample: 45590000 / 53735682 Loss: 1.4248828881914277\n",
      "Epoch: 0 Sample: 45600000 / 53735682 Loss: 1.5111227297867318\n",
      "Epoch: 0 Sample: 45610000 / 53735682 Loss: 1.4991130748893688\n",
      "Epoch: 0 Sample: 45620000 / 53735682 Loss: 1.4389036219384903\n",
      "Epoch: 0 Sample: 45630000 / 53735682 Loss: 1.549453959990642\n",
      "Epoch: 0 Sample: 45640000 / 53735682 Loss: 1.505218286385881\n",
      "Epoch: 0 Sample: 45650000 / 53735682 Loss: 1.4334491736067285\n",
      "Epoch: 0 Sample: 45660000 / 53735682 Loss: 1.4333837833969896\n",
      "Epoch: 0 Sample: 45670000 / 53735682 Loss: 1.4952003506845168\n",
      "Epoch: 0 Sample: 45680000 / 53735682 Loss: 1.4592185612120812\n",
      "Epoch: 0 Sample: 45690000 / 53735682 Loss: 1.5080974205500952\n",
      "Epoch: 0 Sample: 45700000 / 53735682 Loss: 1.5451816508603882\n",
      "Epoch: 0 Sample: 45710000 / 53735682 Loss: 1.4183387912360035\n",
      "Epoch: 0 Sample: 45720000 / 53735682 Loss: 1.5406628753997986\n",
      "Epoch: 0 Sample: 45730000 / 53735682 Loss: 1.537090770626329\n",
      "Epoch: 0 Sample: 45740000 / 53735682 Loss: 1.4838733695080029\n",
      "Epoch: 0 Sample: 45750000 / 53735682 Loss: 1.46030021919286\n",
      "Epoch: 0 Sample: 45760000 / 53735682 Loss: 1.4688524833677077\n",
      "Epoch: 0 Sample: 45770000 / 53735682 Loss: 1.5210696734283675\n",
      "Epoch: 0 Sample: 45780000 / 53735682 Loss: 1.5576512193553365\n",
      "Epoch: 0 Sample: 45790000 / 53735682 Loss: 1.46229044387059\n",
      "Epoch: 0 Sample: 45800000 / 53735682 Loss: 1.3849506376954368\n",
      "Epoch: 0 Sample: 45810000 / 53735682 Loss: 1.459059644764229\n",
      "Epoch: 0 Sample: 45820000 / 53735682 Loss: 1.3900903894964347\n",
      "Epoch: 0 Sample: 45830000 / 53735682 Loss: 1.417374107565023\n",
      "Epoch: 0 Sample: 45840000 / 53735682 Loss: 1.40898200910271\n",
      "Epoch: 0 Sample: 45850000 / 53735682 Loss: 1.4593563746341396\n",
      "Epoch: 0 Sample: 45860000 / 53735682 Loss: 1.546310345187798\n",
      "Epoch: 0 Sample: 45870000 / 53735682 Loss: 1.3964722496594293\n",
      "Epoch: 0 Sample: 45880000 / 53735682 Loss: 1.4867001938999937\n",
      "Epoch: 0 Sample: 45890000 / 53735682 Loss: 1.4910723617020898\n",
      "Epoch: 0 Sample: 45900000 / 53735682 Loss: 1.486478515221454\n",
      "Epoch: 0 Sample: 45910000 / 53735682 Loss: 1.4803270199753509\n",
      "Epoch: 0 Sample: 45920000 / 53735682 Loss: 1.5017261116996632\n",
      "Epoch: 0 Sample: 45930000 / 53735682 Loss: 1.4690885614734102\n",
      "Epoch: 0 Sample: 45940000 / 53735682 Loss: 1.512830915015145\n",
      "Epoch: 0 Sample: 45950000 / 53735682 Loss: 1.431946379323962\n",
      "Epoch: 0 Sample: 45960000 / 53735682 Loss: 1.4555938471217775\n",
      "Epoch: 0 Sample: 45970000 / 53735682 Loss: 1.5055471678845094\n",
      "Epoch: 0 Sample: 45980000 / 53735682 Loss: 1.4920576902173612\n",
      "Epoch: 0 Sample: 45990000 / 53735682 Loss: 1.556055124159034\n",
      "Epoch: 0 Sample: 46000000 / 53735682 Loss: 1.482302027490582\n",
      "Epoch: 0 Sample: 46010000 / 53735682 Loss: 1.5198141272805399\n",
      "Epoch: 0 Sample: 46020000 / 53735682 Loss: 1.5090598268881363\n",
      "Epoch: 0 Sample: 46030000 / 53735682 Loss: 1.4283018724587628\n",
      "Epoch: 0 Sample: 46040000 / 53735682 Loss: 1.4318299940090708\n",
      "Epoch: 0 Sample: 46050000 / 53735682 Loss: 1.4596703699971032\n",
      "Epoch: 0 Sample: 46060000 / 53735682 Loss: 1.4359974672762759\n",
      "Epoch: 0 Sample: 46070000 / 53735682 Loss: 1.4538060195704983\n",
      "Epoch: 0 Sample: 46080000 / 53735682 Loss: 1.5074140586747329\n",
      "Epoch: 0 Sample: 46090000 / 53735682 Loss: 1.4454118274583059\n",
      "Epoch: 0 Sample: 46100000 / 53735682 Loss: 1.4900022480083095\n",
      "Epoch: 0 Sample: 46110000 / 53735682 Loss: 1.3738356559932599\n",
      "Epoch: 0 Sample: 46120000 / 53735682 Loss: 1.421067483633986\n",
      "Epoch: 0 Sample: 46130000 / 53735682 Loss: 1.4274383840168126\n",
      "Epoch: 0 Sample: 46140000 / 53735682 Loss: 1.5535898018297498\n",
      "Epoch: 0 Sample: 46150000 / 53735682 Loss: 1.453952882827999\n",
      "Epoch: 0 Sample: 46160000 / 53735682 Loss: 1.4299259925868242\n",
      "Epoch: 0 Sample: 46170000 / 53735682 Loss: 1.4420983979825897\n",
      "Epoch: 0 Sample: 46180000 / 53735682 Loss: 1.408867506695743\n",
      "Epoch: 0 Sample: 46190000 / 53735682 Loss: 1.464983889311319\n",
      "Epoch: 0 Sample: 46200000 / 53735682 Loss: 1.5144747119875106\n",
      "Epoch: 0 Sample: 46210000 / 53735682 Loss: 1.5390398890022898\n",
      "Epoch: 0 Sample: 46220000 / 53735682 Loss: 1.534034166547235\n",
      "Epoch: 0 Sample: 46230000 / 53735682 Loss: 1.496335865673256\n",
      "Epoch: 0 Sample: 46240000 / 53735682 Loss: 1.4763620864150653\n",
      "Epoch: 0 Sample: 46250000 / 53735682 Loss: 1.451148313588761\n",
      "Epoch: 0 Sample: 46260000 / 53735682 Loss: 1.4841100989706475\n",
      "Epoch: 0 Sample: 46270000 / 53735682 Loss: 1.4517329143920414\n",
      "Epoch: 0 Sample: 46280000 / 53735682 Loss: 1.455933029463443\n",
      "Epoch: 0 Sample: 46290000 / 53735682 Loss: 1.5226963510952678\n",
      "Epoch: 0 Sample: 46300000 / 53735682 Loss: 1.4458524440010008\n",
      "Epoch: 0 Sample: 46310000 / 53735682 Loss: 1.4157815067406496\n",
      "Epoch: 0 Sample: 46320000 / 53735682 Loss: 1.4898294400117305\n",
      "Epoch: 0 Sample: 46330000 / 53735682 Loss: 1.4300613363493384\n",
      "Epoch: 0 Sample: 46340000 / 53735682 Loss: 1.4901348992946661\n",
      "Epoch: 0 Sample: 46350000 / 53735682 Loss: 1.4665317457012543\n",
      "Epoch: 0 Sample: 46360000 / 53735682 Loss: 1.4680278854630258\n",
      "Epoch: 0 Sample: 46370000 / 53735682 Loss: 1.4053637407008914\n",
      "Epoch: 0 Sample: 46380000 / 53735682 Loss: 1.5205406492448452\n",
      "Epoch: 0 Sample: 46390000 / 53735682 Loss: 1.5230013846217423\n",
      "Epoch: 0 Sample: 46400000 / 53735682 Loss: 1.496157613092441\n",
      "Epoch: 0 Sample: 46410000 / 53735682 Loss: 1.47770133862844\n",
      "Epoch: 0 Sample: 46420000 / 53735682 Loss: 1.4645579820423686\n",
      "Epoch: 0 Sample: 46430000 / 53735682 Loss: 1.457315311416543\n",
      "Epoch: 0 Sample: 46440000 / 53735682 Loss: 1.520148382959356\n",
      "Epoch: 0 Sample: 46450000 / 53735682 Loss: 1.474605358601373\n",
      "Epoch: 0 Sample: 46460000 / 53735682 Loss: 1.5420293879288052\n",
      "Epoch: 0 Sample: 46470000 / 53735682 Loss: 1.623173947807904\n",
      "Epoch: 0 Sample: 46480000 / 53735682 Loss: 1.4663236002762368\n",
      "Epoch: 0 Sample: 46490000 / 53735682 Loss: 1.5514793544762955\n",
      "Epoch: 0 Sample: 46500000 / 53735682 Loss: 1.4718710959534844\n",
      "Epoch: 0 Sample: 46510000 / 53735682 Loss: 1.4026163049513434\n",
      "Epoch: 0 Sample: 46520000 / 53735682 Loss: 1.4738376481626911\n",
      "Epoch: 0 Sample: 46530000 / 53735682 Loss: 1.5140133980039567\n",
      "Epoch: 0 Sample: 46540000 / 53735682 Loss: 1.5253163125365632\n",
      "Epoch: 0 Sample: 46550000 / 53735682 Loss: 1.431467551840293\n",
      "Epoch: 0 Sample: 46560000 / 53735682 Loss: 1.411815946258077\n",
      "Epoch: 0 Sample: 46570000 / 53735682 Loss: 1.5390947978277512\n",
      "Epoch: 0 Sample: 46580000 / 53735682 Loss: 1.5864813036511929\n",
      "Epoch: 0 Sample: 46590000 / 53735682 Loss: 1.480864739238407\n",
      "Epoch: 0 Sample: 46600000 / 53735682 Loss: 1.46181850797287\n",
      "Epoch: 0 Sample: 46610000 / 53735682 Loss: 1.4696043524753368\n",
      "Epoch: 0 Sample: 46620000 / 53735682 Loss: 1.3715995051446463\n",
      "Epoch: 0 Sample: 46630000 / 53735682 Loss: 1.4733918629194078\n",
      "Epoch: 0 Sample: 46640000 / 53735682 Loss: 1.5116814636877187\n",
      "Epoch: 0 Sample: 46650000 / 53735682 Loss: 1.4492444118645735\n",
      "Epoch: 0 Sample: 46660000 / 53735682 Loss: 1.4890205400537195\n",
      "Epoch: 0 Sample: 46670000 / 53735682 Loss: 1.4888717995625629\n",
      "Epoch: 0 Sample: 46680000 / 53735682 Loss: 1.4177176205019046\n",
      "Epoch: 0 Sample: 46690000 / 53735682 Loss: 1.5138861258226715\n",
      "Epoch: 0 Sample: 46700000 / 53735682 Loss: 1.517190298179588\n",
      "Epoch: 0 Sample: 46710000 / 53735682 Loss: 1.4670964165187625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 46720000 / 53735682 Loss: 1.5516485226453396\n",
      "Epoch: 0 Sample: 46730000 / 53735682 Loss: 1.528129921770366\n",
      "Epoch: 0 Sample: 46740000 / 53735682 Loss: 1.4619309051830176\n",
      "Epoch: 0 Sample: 46750000 / 53735682 Loss: 1.4531061678302364\n",
      "Epoch: 0 Sample: 46760000 / 53735682 Loss: 1.551958000076215\n",
      "Epoch: 0 Sample: 46770000 / 53735682 Loss: 1.44832096534933\n",
      "Epoch: 0 Sample: 46780000 / 53735682 Loss: 1.4453547403653397\n",
      "Epoch: 0 Sample: 46790000 / 53735682 Loss: 1.4247475814739692\n",
      "Epoch: 0 Sample: 46800000 / 53735682 Loss: 1.4342890540827247\n",
      "Epoch: 0 Sample: 46810000 / 53735682 Loss: 1.4540540085100537\n",
      "Epoch: 0 Sample: 46820000 / 53735682 Loss: 1.4127526904535195\n",
      "Epoch: 0 Sample: 46830000 / 53735682 Loss: 1.5335346503298575\n",
      "Epoch: 0 Sample: 46840000 / 53735682 Loss: 1.5568032189865528\n",
      "Epoch: 0 Sample: 46850000 / 53735682 Loss: 1.4675546497175356\n",
      "Epoch: 0 Sample: 46860000 / 53735682 Loss: 1.430303316751739\n",
      "Epoch: 0 Sample: 46870000 / 53735682 Loss: 1.5092562069386277\n",
      "Epoch: 0 Sample: 46880000 / 53735682 Loss: 1.480113108425365\n",
      "Epoch: 0 Sample: 46890000 / 53735682 Loss: 1.5739118307215856\n",
      "Epoch: 0 Sample: 46900000 / 53735682 Loss: 1.453736262533536\n",
      "Epoch: 0 Sample: 46910000 / 53735682 Loss: 1.510978649070771\n",
      "Epoch: 0 Sample: 46920000 / 53735682 Loss: 1.3661680778641827\n",
      "Epoch: 0 Sample: 46930000 / 53735682 Loss: 1.560223476049937\n",
      "Epoch: 0 Sample: 46940000 / 53735682 Loss: 1.4320339215569269\n",
      "Epoch: 0 Sample: 46950000 / 53735682 Loss: 1.4532430278609574\n",
      "Epoch: 0 Sample: 46960000 / 53735682 Loss: 1.4637173763399154\n",
      "Epoch: 0 Sample: 46970000 / 53735682 Loss: 1.483304238023727\n",
      "Epoch: 0 Sample: 46980000 / 53735682 Loss: 1.4644764225197795\n",
      "Epoch: 0 Sample: 46990000 / 53735682 Loss: 1.5358763121776147\n",
      "Epoch: 0 Sample: 47000000 / 53735682 Loss: 1.4525258257847597\n",
      "Epoch: 0 Sample: 47010000 / 53735682 Loss: 1.45396602613808\n",
      "Epoch: 0 Sample: 47020000 / 53735682 Loss: 1.5160250192901952\n",
      "Epoch: 0 Sample: 47030000 / 53735682 Loss: 1.4315036111419956\n",
      "Epoch: 0 Sample: 47040000 / 53735682 Loss: 1.3873004217483866\n",
      "Epoch: 0 Sample: 47050000 / 53735682 Loss: 1.530882444552469\n",
      "Epoch: 0 Sample: 47060000 / 53735682 Loss: 1.422981568937491\n",
      "Epoch: 0 Sample: 47070000 / 53735682 Loss: 1.353704521940604\n",
      "Epoch: 0 Sample: 47080000 / 53735682 Loss: 1.435874584687126\n",
      "Epoch: 0 Sample: 47090000 / 53735682 Loss: 1.4371650988122404\n",
      "Epoch: 0 Sample: 47100000 / 53735682 Loss: 1.5001639124791877\n",
      "Epoch: 0 Sample: 47110000 / 53735682 Loss: 1.4952922031901328\n",
      "Epoch: 0 Sample: 47120000 / 53735682 Loss: 1.4392643354091104\n",
      "Epoch: 0 Sample: 47130000 / 53735682 Loss: 1.4480261960880858\n",
      "Epoch: 0 Sample: 47140000 / 53735682 Loss: 1.5535839259495179\n",
      "Epoch: 0 Sample: 47150000 / 53735682 Loss: 1.482431465968146\n",
      "Epoch: 0 Sample: 47160000 / 53735682 Loss: 1.5149677278852829\n",
      "Epoch: 0 Sample: 47170000 / 53735682 Loss: 1.4900499770616502\n",
      "Epoch: 0 Sample: 47180000 / 53735682 Loss: 1.5023088794833428\n",
      "Epoch: 0 Sample: 47190000 / 53735682 Loss: 1.387037492767979\n",
      "Epoch: 0 Sample: 47200000 / 53735682 Loss: 1.4935100871633291\n",
      "Epoch: 0 Sample: 47210000 / 53735682 Loss: 1.3967312483821943\n",
      "Epoch: 0 Sample: 47220000 / 53735682 Loss: 1.4300863814663498\n",
      "Epoch: 0 Sample: 47230000 / 53735682 Loss: 1.4920524922802605\n",
      "Epoch: 0 Sample: 47240000 / 53735682 Loss: 1.5027219059686927\n",
      "Epoch: 0 Sample: 47250000 / 53735682 Loss: 1.4999186277417191\n",
      "Epoch: 0 Sample: 47260000 / 53735682 Loss: 1.435126358594415\n",
      "Epoch: 0 Sample: 47270000 / 53735682 Loss: 1.4598074090384823\n",
      "Epoch: 0 Sample: 47280000 / 53735682 Loss: 1.4387526625834801\n",
      "Epoch: 0 Sample: 47290000 / 53735682 Loss: 1.5197345856289899\n",
      "Epoch: 0 Sample: 47300000 / 53735682 Loss: 1.4785114866661393\n",
      "Epoch: 0 Sample: 47310000 / 53735682 Loss: 1.495813601582279\n",
      "Epoch: 0 Sample: 47320000 / 53735682 Loss: 1.5263488677626946\n",
      "Epoch: 0 Sample: 47330000 / 53735682 Loss: 1.4074682503112275\n",
      "Epoch: 0 Sample: 47340000 / 53735682 Loss: 1.4428397946147131\n",
      "Epoch: 0 Sample: 47350000 / 53735682 Loss: 1.4940950339265546\n",
      "Epoch: 0 Sample: 47360000 / 53735682 Loss: 1.5023940273498542\n",
      "Epoch: 0 Sample: 47370000 / 53735682 Loss: 1.4745402038767972\n",
      "Epoch: 0 Sample: 47380000 / 53735682 Loss: 1.4926403430371173\n",
      "Epoch: 0 Sample: 47390000 / 53735682 Loss: 1.4846484368460973\n",
      "Epoch: 0 Sample: 47400000 / 53735682 Loss: 1.4423281142872943\n",
      "Epoch: 0 Sample: 47410000 / 53735682 Loss: 1.5367477436705488\n",
      "Epoch: 0 Sample: 47420000 / 53735682 Loss: 1.4558125960821668\n",
      "Epoch: 0 Sample: 47430000 / 53735682 Loss: 1.3517530800283029\n",
      "Epoch: 0 Sample: 47440000 / 53735682 Loss: 1.5199851284405954\n",
      "Epoch: 0 Sample: 47450000 / 53735682 Loss: 1.4702559093987766\n",
      "Epoch: 0 Sample: 47460000 / 53735682 Loss: 1.4582401949875359\n",
      "Epoch: 0 Sample: 47470000 / 53735682 Loss: 1.4374388527175312\n",
      "Epoch: 0 Sample: 47480000 / 53735682 Loss: 1.4669985979523346\n",
      "Epoch: 0 Sample: 47490000 / 53735682 Loss: 1.43957384088817\n",
      "Epoch: 0 Sample: 47500000 / 53735682 Loss: 1.4963339031597722\n",
      "Epoch: 0 Sample: 47510000 / 53735682 Loss: 1.503135910455843\n",
      "Epoch: 0 Sample: 47520000 / 53735682 Loss: 1.389292696852872\n",
      "Epoch: 0 Sample: 47530000 / 53735682 Loss: 1.534517548666475\n",
      "Epoch: 0 Sample: 47540000 / 53735682 Loss: 1.4631137675702626\n",
      "Epoch: 0 Sample: 47550000 / 53735682 Loss: 1.416134061946724\n",
      "Epoch: 0 Sample: 47560000 / 53735682 Loss: 1.486442960289402\n",
      "Epoch: 0 Sample: 47570000 / 53735682 Loss: 1.434917887982495\n",
      "Epoch: 0 Sample: 47580000 / 53735682 Loss: 1.5556033502157935\n",
      "Epoch: 0 Sample: 47590000 / 53735682 Loss: 1.476484988513144\n",
      "Epoch: 0 Sample: 47600000 / 53735682 Loss: 1.4739699386879161\n",
      "Epoch: 0 Sample: 47610000 / 53735682 Loss: 1.5133689889453932\n",
      "Epoch: 0 Sample: 47620000 / 53735682 Loss: 1.4393046678077877\n",
      "Epoch: 0 Sample: 47630000 / 53735682 Loss: 1.4780643750815252\n",
      "Epoch: 0 Sample: 47640000 / 53735682 Loss: 1.4888893937424683\n",
      "Epoch: 0 Sample: 47650000 / 53735682 Loss: 1.5135796053575596\n",
      "Epoch: 0 Sample: 47660000 / 53735682 Loss: 1.4237056966592485\n",
      "Epoch: 0 Sample: 47670000 / 53735682 Loss: 1.4539067364241658\n",
      "Epoch: 0 Sample: 47680000 / 53735682 Loss: 1.478323586758059\n",
      "Epoch: 0 Sample: 47690000 / 53735682 Loss: 1.428322481821298\n",
      "Epoch: 0 Sample: 47700000 / 53735682 Loss: 1.4906716945873533\n",
      "Epoch: 0 Sample: 47710000 / 53735682 Loss: 1.4363114891776538\n",
      "Epoch: 0 Sample: 47720000 / 53735682 Loss: 1.4710825015501618\n",
      "Epoch: 0 Sample: 47730000 / 53735682 Loss: 1.5006962331126823\n",
      "Epoch: 0 Sample: 47740000 / 53735682 Loss: 1.4876232591709904\n",
      "Epoch: 0 Sample: 47750000 / 53735682 Loss: 1.4526500797062278\n",
      "Epoch: 0 Sample: 47760000 / 53735682 Loss: 1.4263275285958712\n",
      "Epoch: 0 Sample: 47770000 / 53735682 Loss: 1.4373076653520895\n",
      "Epoch: 0 Sample: 47780000 / 53735682 Loss: 1.6028740255451814\n",
      "Epoch: 0 Sample: 47790000 / 53735682 Loss: 1.5542520997980924\n",
      "Epoch: 0 Sample: 47800000 / 53735682 Loss: 1.5049555471629557\n",
      "Epoch: 0 Sample: 47810000 / 53735682 Loss: 1.4247727409356772\n",
      "Epoch: 0 Sample: 47820000 / 53735682 Loss: 1.538636776126113\n",
      "Epoch: 0 Sample: 47830000 / 53735682 Loss: 1.4835689444577318\n",
      "Epoch: 0 Sample: 47840000 / 53735682 Loss: 1.5209150414821813\n",
      "Epoch: 0 Sample: 47850000 / 53735682 Loss: 1.5080650766740822\n",
      "Epoch: 0 Sample: 47860000 / 53735682 Loss: 1.5135115571805846\n",
      "Epoch: 0 Sample: 47870000 / 53735682 Loss: 1.4499378513013472\n",
      "Epoch: 0 Sample: 47880000 / 53735682 Loss: 1.475597060716979\n",
      "Epoch: 0 Sample: 47890000 / 53735682 Loss: 1.5479392196653414\n",
      "Epoch: 0 Sample: 47900000 / 53735682 Loss: 1.4809293727419826\n",
      "Epoch: 0 Sample: 47910000 / 53735682 Loss: 1.4253750499397004\n",
      "Epoch: 0 Sample: 47920000 / 53735682 Loss: 1.4982825196120846\n",
      "Epoch: 0 Sample: 47930000 / 53735682 Loss: 1.5255347876743015\n",
      "Epoch: 0 Sample: 47940000 / 53735682 Loss: 1.4227032286866406\n",
      "Epoch: 0 Sample: 47950000 / 53735682 Loss: 1.479841658438819\n",
      "Epoch: 0 Sample: 47960000 / 53735682 Loss: 1.4409929212198471\n",
      "Epoch: 0 Sample: 47970000 / 53735682 Loss: 1.5448129692813608\n",
      "Epoch: 0 Sample: 47980000 / 53735682 Loss: 1.4866627277310687\n",
      "Epoch: 0 Sample: 47990000 / 53735682 Loss: 1.480734990686822\n",
      "Epoch: 0 Sample: 48000000 / 53735682 Loss: 1.412854147938304\n",
      "Epoch: 0 Sample: 48010000 / 53735682 Loss: 1.4697751060503286\n",
      "Epoch: 0 Sample: 48020000 / 53735682 Loss: 1.4518081645846634\n",
      "Epoch: 0 Sample: 48030000 / 53735682 Loss: 1.4610263651820512\n",
      "Epoch: 0 Sample: 48040000 / 53735682 Loss: 1.4597781353126655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 48050000 / 53735682 Loss: 1.3876740767012028\n",
      "Epoch: 0 Sample: 48060000 / 53735682 Loss: 1.4680710183503183\n",
      "Epoch: 0 Sample: 48070000 / 53735682 Loss: 1.4755599984631074\n",
      "Epoch: 0 Sample: 48080000 / 53735682 Loss: 1.5523004338245938\n",
      "Epoch: 0 Sample: 48090000 / 53735682 Loss: 1.5994316018987542\n",
      "Epoch: 0 Sample: 48100000 / 53735682 Loss: 1.52515554982922\n",
      "Epoch: 0 Sample: 48110000 / 53735682 Loss: 1.5266621642268832\n",
      "Epoch: 0 Sample: 48120000 / 53735682 Loss: 1.4358994570135173\n",
      "Epoch: 0 Sample: 48130000 / 53735682 Loss: 1.4844516723660708\n",
      "Epoch: 0 Sample: 48140000 / 53735682 Loss: 1.5313081516283429\n",
      "Epoch: 0 Sample: 48150000 / 53735682 Loss: 1.5139678307875837\n",
      "Epoch: 0 Sample: 48160000 / 53735682 Loss: 1.4691548566033583\n",
      "Epoch: 0 Sample: 48170000 / 53735682 Loss: 1.500691942265698\n",
      "Epoch: 0 Sample: 48180000 / 53735682 Loss: 1.50482167323261\n",
      "Epoch: 0 Sample: 48190000 / 53735682 Loss: 1.4198772669283068\n",
      "Epoch: 0 Sample: 48200000 / 53735682 Loss: 1.4838124089354432\n",
      "Epoch: 0 Sample: 48210000 / 53735682 Loss: 1.5050710077788825\n",
      "Epoch: 0 Sample: 48220000 / 53735682 Loss: 1.3805775187201508\n",
      "Epoch: 0 Sample: 48230000 / 53735682 Loss: 1.526554827186278\n",
      "Epoch: 0 Sample: 48240000 / 53735682 Loss: 1.4084657610185611\n",
      "Epoch: 0 Sample: 48250000 / 53735682 Loss: 1.5066205316598977\n",
      "Epoch: 0 Sample: 48260000 / 53735682 Loss: 1.415792928615391\n",
      "Epoch: 0 Sample: 48270000 / 53735682 Loss: 1.5108656060302406\n",
      "Epoch: 0 Sample: 48280000 / 53735682 Loss: 1.5024558543202957\n",
      "Epoch: 0 Sample: 48290000 / 53735682 Loss: 1.4351931462831622\n",
      "Epoch: 0 Sample: 48300000 / 53735682 Loss: 1.437732574354986\n",
      "Epoch: 0 Sample: 48310000 / 53735682 Loss: 1.4617745643226567\n",
      "Epoch: 0 Sample: 48320000 / 53735682 Loss: 1.3951867842740846\n",
      "Epoch: 0 Sample: 48330000 / 53735682 Loss: 1.4438914559073914\n",
      "Epoch: 0 Sample: 48340000 / 53735682 Loss: 1.5008336390144326\n",
      "Epoch: 0 Sample: 48350000 / 53735682 Loss: 1.5128016237822213\n",
      "Epoch: 0 Sample: 48360000 / 53735682 Loss: 1.422802662318479\n",
      "Epoch: 0 Sample: 48370000 / 53735682 Loss: 1.4166826077129937\n",
      "Epoch: 0 Sample: 48380000 / 53735682 Loss: 1.485198012474538\n",
      "Epoch: 0 Sample: 48390000 / 53735682 Loss: 1.5193217796791727\n",
      "Epoch: 0 Sample: 48400000 / 53735682 Loss: 1.4212202136342138\n",
      "Epoch: 0 Sample: 48410000 / 53735682 Loss: 1.41034740431171\n",
      "Epoch: 0 Sample: 48420000 / 53735682 Loss: 1.552052439620618\n",
      "Epoch: 0 Sample: 48430000 / 53735682 Loss: 1.4252395904433222\n",
      "Epoch: 0 Sample: 48440000 / 53735682 Loss: 1.3539932391596996\n",
      "Epoch: 0 Sample: 48450000 / 53735682 Loss: 1.4717609786487227\n",
      "Epoch: 0 Sample: 48460000 / 53735682 Loss: 1.5098798736352688\n",
      "Epoch: 0 Sample: 48470000 / 53735682 Loss: 1.6061277143162374\n",
      "Epoch: 0 Sample: 48480000 / 53735682 Loss: 1.5387782373625676\n",
      "Epoch: 0 Sample: 48490000 / 53735682 Loss: 1.4711230364367767\n",
      "Epoch: 0 Sample: 48500000 / 53735682 Loss: 1.5010248591706286\n",
      "Epoch: 0 Sample: 48510000 / 53735682 Loss: 1.537291598936819\n",
      "Epoch: 0 Sample: 48520000 / 53735682 Loss: 1.515410083348086\n",
      "Epoch: 0 Sample: 48530000 / 53735682 Loss: 1.5301745154085347\n",
      "Epoch: 0 Sample: 48540000 / 53735682 Loss: 1.4687143294954619\n",
      "Epoch: 0 Sample: 48550000 / 53735682 Loss: 1.3699499901648724\n",
      "Epoch: 0 Sample: 48560000 / 53735682 Loss: 1.5466692046072716\n",
      "Epoch: 0 Sample: 48570000 / 53735682 Loss: 1.5008658220297468\n",
      "Epoch: 0 Sample: 48580000 / 53735682 Loss: 1.4349864780103716\n",
      "Epoch: 0 Sample: 48590000 / 53735682 Loss: 1.531739965076472\n",
      "Epoch: 0 Sample: 48600000 / 53735682 Loss: 1.5093904452166615\n",
      "Epoch: 0 Sample: 48610000 / 53735682 Loss: 1.5224925002601868\n",
      "Epoch: 0 Sample: 48620000 / 53735682 Loss: 1.5201862048450516\n",
      "Epoch: 0 Sample: 48630000 / 53735682 Loss: 1.5505755087060746\n",
      "Epoch: 0 Sample: 48640000 / 53735682 Loss: 1.5104072913127755\n",
      "Epoch: 0 Sample: 48650000 / 53735682 Loss: 1.5366859276990374\n",
      "Epoch: 0 Sample: 48660000 / 53735682 Loss: 1.5212167007294082\n",
      "Epoch: 0 Sample: 48670000 / 53735682 Loss: 1.506567760308064\n",
      "Epoch: 0 Sample: 48680000 / 53735682 Loss: 1.532657901668418\n",
      "Epoch: 0 Sample: 48690000 / 53735682 Loss: 1.4325553012569583\n",
      "Epoch: 0 Sample: 48700000 / 53735682 Loss: 1.425859426771416\n",
      "Epoch: 0 Sample: 48710000 / 53735682 Loss: 1.5157726809505565\n",
      "Epoch: 0 Sample: 48720000 / 53735682 Loss: 1.4753276682041254\n",
      "Epoch: 0 Sample: 48730000 / 53735682 Loss: 1.470948244631979\n",
      "Epoch: 0 Sample: 48740000 / 53735682 Loss: 1.453194515031487\n",
      "Epoch: 0 Sample: 48750000 / 53735682 Loss: 1.4352346181539901\n",
      "Epoch: 0 Sample: 48760000 / 53735682 Loss: 1.5206834163431493\n",
      "Epoch: 0 Sample: 48770000 / 53735682 Loss: 1.4795846256059362\n",
      "Epoch: 0 Sample: 48780000 / 53735682 Loss: 1.350483989019045\n",
      "Epoch: 0 Sample: 48790000 / 53735682 Loss: 1.4277663606203872\n",
      "Epoch: 0 Sample: 48800000 / 53735682 Loss: 1.5664467068908041\n",
      "Epoch: 0 Sample: 48810000 / 53735682 Loss: 1.535511532579344\n",
      "Epoch: 0 Sample: 48820000 / 53735682 Loss: 1.4709134143667055\n",
      "Epoch: 0 Sample: 48830000 / 53735682 Loss: 1.4626258551577032\n",
      "Epoch: 0 Sample: 48840000 / 53735682 Loss: 1.4881878909606037\n",
      "Epoch: 0 Sample: 48850000 / 53735682 Loss: 1.4514116013823757\n",
      "Epoch: 0 Sample: 48860000 / 53735682 Loss: 1.4152672682070924\n",
      "Epoch: 0 Sample: 48870000 / 53735682 Loss: 1.570379149437453\n",
      "Epoch: 0 Sample: 48880000 / 53735682 Loss: 1.5233280631980521\n",
      "Epoch: 0 Sample: 48890000 / 53735682 Loss: 1.4604022058319543\n",
      "Epoch: 0 Sample: 48900000 / 53735682 Loss: 1.467438527829103\n",
      "Epoch: 0 Sample: 48910000 / 53735682 Loss: 1.5177441093289028\n",
      "Epoch: 0 Sample: 48920000 / 53735682 Loss: 1.5154468778189432\n",
      "Epoch: 0 Sample: 48930000 / 53735682 Loss: 1.4288592066793186\n",
      "Epoch: 0 Sample: 48940000 / 53735682 Loss: 1.46947337988599\n",
      "Epoch: 0 Sample: 48950000 / 53735682 Loss: 1.531412576881734\n",
      "Epoch: 0 Sample: 48960000 / 53735682 Loss: 1.4477471811229288\n",
      "Epoch: 0 Sample: 48970000 / 53735682 Loss: 1.4858605910251803\n",
      "Epoch: 0 Sample: 48980000 / 53735682 Loss: 1.541662219484461\n",
      "Epoch: 0 Sample: 48990000 / 53735682 Loss: 1.521814655249161\n",
      "Epoch: 0 Sample: 49000000 / 53735682 Loss: 1.52716181934204\n",
      "Epoch: 0 Sample: 49010000 / 53735682 Loss: 1.4564628119187706\n",
      "Epoch: 0 Sample: 49020000 / 53735682 Loss: 1.506613000046772\n",
      "Epoch: 0 Sample: 49030000 / 53735682 Loss: 1.4751024268254431\n",
      "Epoch: 0 Sample: 49040000 / 53735682 Loss: 1.467222926740292\n",
      "Epoch: 0 Sample: 49050000 / 53735682 Loss: 1.431642904245939\n",
      "Epoch: 0 Sample: 49060000 / 53735682 Loss: 1.4406577428756688\n",
      "Epoch: 0 Sample: 49070000 / 53735682 Loss: 1.4476202346748275\n",
      "Epoch: 0 Sample: 49080000 / 53735682 Loss: 1.4669224110560313\n",
      "Epoch: 0 Sample: 49090000 / 53735682 Loss: 1.487712197209295\n",
      "Epoch: 0 Sample: 49100000 / 53735682 Loss: 1.5501728669032908\n",
      "Epoch: 0 Sample: 49110000 / 53735682 Loss: 1.4999958917183145\n",
      "Epoch: 0 Sample: 49120000 / 53735682 Loss: 1.5007649741360827\n",
      "Epoch: 0 Sample: 49130000 / 53735682 Loss: 1.4216724752675924\n",
      "Epoch: 0 Sample: 49140000 / 53735682 Loss: 1.548047400279845\n",
      "Epoch: 0 Sample: 49150000 / 53735682 Loss: 1.550762053053311\n",
      "Epoch: 0 Sample: 49160000 / 53735682 Loss: 1.4463491425991126\n",
      "Epoch: 0 Sample: 49170000 / 53735682 Loss: 1.4547723601825324\n",
      "Epoch: 0 Sample: 49180000 / 53735682 Loss: 1.3832416797851594\n",
      "Epoch: 0 Sample: 49190000 / 53735682 Loss: 1.4635546417062058\n",
      "Epoch: 0 Sample: 49200000 / 53735682 Loss: 1.499059400091967\n",
      "Epoch: 0 Sample: 49210000 / 53735682 Loss: 1.442408781493431\n",
      "Epoch: 0 Sample: 49220000 / 53735682 Loss: 1.4835194167292836\n",
      "Epoch: 0 Sample: 49230000 / 53735682 Loss: 1.407998245476856\n",
      "Epoch: 0 Sample: 49240000 / 53735682 Loss: 1.4865361728346596\n",
      "Epoch: 0 Sample: 49250000 / 53735682 Loss: 1.512010605707499\n",
      "Epoch: 0 Sample: 49260000 / 53735682 Loss: 1.4269610279767546\n",
      "Epoch: 0 Sample: 49270000 / 53735682 Loss: 1.5166894151254986\n",
      "Epoch: 0 Sample: 49280000 / 53735682 Loss: 1.535386896583066\n",
      "Epoch: 0 Sample: 49290000 / 53735682 Loss: 1.5436225763425413\n",
      "Epoch: 0 Sample: 49300000 / 53735682 Loss: 1.4809219922967998\n",
      "Epoch: 0 Sample: 49310000 / 53735682 Loss: 1.45408528468541\n",
      "Epoch: 0 Sample: 49320000 / 53735682 Loss: 1.4219784926253287\n",
      "Epoch: 0 Sample: 49330000 / 53735682 Loss: 1.4601478937033043\n",
      "Epoch: 0 Sample: 49340000 / 53735682 Loss: 1.4532403186235328\n",
      "Epoch: 0 Sample: 49350000 / 53735682 Loss: 1.4134921195644579\n",
      "Epoch: 0 Sample: 49360000 / 53735682 Loss: 1.4212232588683062\n",
      "Epoch: 0 Sample: 49370000 / 53735682 Loss: 1.481161043528168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 49380000 / 53735682 Loss: 1.464441046431958\n",
      "Epoch: 0 Sample: 49390000 / 53735682 Loss: 1.4091263937085754\n",
      "Epoch: 0 Sample: 49400000 / 53735682 Loss: 1.465059511108839\n",
      "Epoch: 0 Sample: 49410000 / 53735682 Loss: 1.4936085088535607\n",
      "Epoch: 0 Sample: 49420000 / 53735682 Loss: 1.5621703231523503\n",
      "Epoch: 0 Sample: 49430000 / 53735682 Loss: 1.4175523015437883\n",
      "Epoch: 0 Sample: 49440000 / 53735682 Loss: 1.5041165762622688\n",
      "Epoch: 0 Sample: 49450000 / 53735682 Loss: 1.4438163560582535\n",
      "Epoch: 0 Sample: 49460000 / 53735682 Loss: 1.4572254527203508\n",
      "Epoch: 0 Sample: 49470000 / 53735682 Loss: 1.4482245755914276\n",
      "Epoch: 0 Sample: 49480000 / 53735682 Loss: 1.516397130489902\n",
      "Epoch: 0 Sample: 49490000 / 53735682 Loss: 1.4617794961255426\n",
      "Epoch: 0 Sample: 49500000 / 53735682 Loss: 1.477743127675121\n",
      "Epoch: 0 Sample: 49510000 / 53735682 Loss: 1.4960103320820304\n",
      "Epoch: 0 Sample: 49520000 / 53735682 Loss: 1.4840861779366898\n",
      "Epoch: 0 Sample: 49530000 / 53735682 Loss: 1.5300615405263183\n",
      "Epoch: 0 Sample: 49540000 / 53735682 Loss: 1.5046069870214724\n",
      "Epoch: 0 Sample: 49550000 / 53735682 Loss: 1.4867839316587816\n",
      "Epoch: 0 Sample: 49560000 / 53735682 Loss: 1.4133312114262457\n",
      "Epoch: 0 Sample: 49570000 / 53735682 Loss: 1.5059042712021267\n",
      "Epoch: 0 Sample: 49580000 / 53735682 Loss: 1.5256379795481603\n",
      "Epoch: 0 Sample: 49590000 / 53735682 Loss: 1.5134774034593383\n",
      "Epoch: 0 Sample: 49600000 / 53735682 Loss: 1.502197762724975\n",
      "Epoch: 0 Sample: 49610000 / 53735682 Loss: 1.4517038790323245\n",
      "Epoch: 0 Sample: 49620000 / 53735682 Loss: 1.5601014717143493\n",
      "Epoch: 0 Sample: 49630000 / 53735682 Loss: 1.3819025893226977\n",
      "Epoch: 0 Sample: 49640000 / 53735682 Loss: 1.5370473916391332\n",
      "Epoch: 0 Sample: 49650000 / 53735682 Loss: 1.4631527293694417\n",
      "Epoch: 0 Sample: 49660000 / 53735682 Loss: 1.4094606209531735\n",
      "Epoch: 0 Sample: 49670000 / 53735682 Loss: 1.418150689150884\n",
      "Epoch: 0 Sample: 49680000 / 53735682 Loss: 1.5352991475346436\n",
      "Epoch: 0 Sample: 49690000 / 53735682 Loss: 1.5117704516718917\n",
      "Epoch: 0 Sample: 49700000 / 53735682 Loss: 1.4318105629228737\n",
      "Epoch: 0 Sample: 49710000 / 53735682 Loss: 1.447504267025026\n",
      "Epoch: 0 Sample: 49720000 / 53735682 Loss: 1.4643973495758953\n",
      "Epoch: 0 Sample: 49730000 / 53735682 Loss: 1.5203961994659203\n",
      "Epoch: 0 Sample: 49740000 / 53735682 Loss: 1.4330688493763688\n",
      "Epoch: 0 Sample: 49750000 / 53735682 Loss: 1.3890164064221868\n",
      "Epoch: 0 Sample: 49760000 / 53735682 Loss: 1.46636773347871\n",
      "Epoch: 0 Sample: 49770000 / 53735682 Loss: 1.4815951006985637\n",
      "Epoch: 0 Sample: 49780000 / 53735682 Loss: 1.4331703140209195\n",
      "Epoch: 0 Sample: 49790000 / 53735682 Loss: 1.445809291010307\n",
      "Epoch: 0 Sample: 49800000 / 53735682 Loss: 1.4234442695384142\n",
      "Epoch: 0 Sample: 49810000 / 53735682 Loss: 1.553713151395455\n",
      "Epoch: 0 Sample: 49820000 / 53735682 Loss: 1.5634621086725409\n",
      "Epoch: 0 Sample: 49830000 / 53735682 Loss: 1.4514262670708908\n",
      "Epoch: 0 Sample: 49840000 / 53735682 Loss: 1.4526254347626142\n",
      "Epoch: 0 Sample: 49850000 / 53735682 Loss: 1.4007185515290583\n",
      "Epoch: 0 Sample: 49860000 / 53735682 Loss: 1.4173900559106758\n",
      "Epoch: 0 Sample: 49870000 / 53735682 Loss: 1.4778592372036639\n",
      "Epoch: 0 Sample: 49880000 / 53735682 Loss: 1.4328939391696731\n",
      "Epoch: 0 Sample: 49890000 / 53735682 Loss: 1.5366658288064095\n",
      "Epoch: 0 Sample: 49900000 / 53735682 Loss: 1.5624161078979073\n",
      "Epoch: 0 Sample: 49910000 / 53735682 Loss: 1.499117927638095\n",
      "Epoch: 0 Sample: 49920000 / 53735682 Loss: 1.5236681738381739\n",
      "Epoch: 0 Sample: 49930000 / 53735682 Loss: 1.489502870593294\n",
      "Epoch: 0 Sample: 49940000 / 53735682 Loss: 1.5343194047096798\n",
      "Epoch: 0 Sample: 49950000 / 53735682 Loss: 1.4526211064599823\n",
      "Epoch: 0 Sample: 49960000 / 53735682 Loss: 1.5233281474511484\n",
      "Epoch: 0 Sample: 49970000 / 53735682 Loss: 1.4500854041752003\n",
      "Epoch: 0 Sample: 49980000 / 53735682 Loss: 1.5041461212515377\n",
      "Epoch: 0 Sample: 49990000 / 53735682 Loss: 1.5270211462390209\n",
      "Epoch: 0 Sample: 50000000 / 53735682 Loss: 1.4982513312484373\n",
      "Epoch: 0 Sample: 50010000 / 53735682 Loss: 1.4630832384394956\n",
      "Epoch: 0 Sample: 50020000 / 53735682 Loss: 1.4536826242718766\n",
      "Epoch: 0 Sample: 50030000 / 53735682 Loss: 1.470455856571855\n",
      "Epoch: 0 Sample: 50040000 / 53735682 Loss: 1.5329516262401448\n",
      "Epoch: 0 Sample: 50050000 / 53735682 Loss: 1.3987017196428422\n",
      "Epoch: 0 Sample: 50060000 / 53735682 Loss: 1.4408733618364902\n",
      "Epoch: 0 Sample: 50070000 / 53735682 Loss: 1.3928684886925158\n",
      "Epoch: 0 Sample: 50080000 / 53735682 Loss: 1.4224105993722604\n",
      "Epoch: 0 Sample: 50090000 / 53735682 Loss: 1.4262103793631502\n",
      "Epoch: 0 Sample: 50100000 / 53735682 Loss: 1.503484991185742\n",
      "Epoch: 0 Sample: 50110000 / 53735682 Loss: 1.4815724234187948\n",
      "Epoch: 0 Sample: 50120000 / 53735682 Loss: 1.4344722106989944\n",
      "Epoch: 0 Sample: 50130000 / 53735682 Loss: 1.5196048933599808\n",
      "Epoch: 0 Sample: 50140000 / 53735682 Loss: 1.4834728469612417\n",
      "Epoch: 0 Sample: 50150000 / 53735682 Loss: 1.4284660257724144\n",
      "Epoch: 0 Sample: 50160000 / 53735682 Loss: 1.4053032926540676\n",
      "Epoch: 0 Sample: 50170000 / 53735682 Loss: 1.4597782084721185\n",
      "Epoch: 0 Sample: 50180000 / 53735682 Loss: 1.5033810139924006\n",
      "Epoch: 0 Sample: 50190000 / 53735682 Loss: 1.569456293558992\n",
      "Epoch: 0 Sample: 50200000 / 53735682 Loss: 1.391580526244812\n",
      "Epoch: 0 Sample: 50210000 / 53735682 Loss: 1.4315750511487573\n",
      "Epoch: 0 Sample: 50220000 / 53735682 Loss: 1.4788476185617756\n",
      "Epoch: 0 Sample: 50230000 / 53735682 Loss: 1.501126122159252\n",
      "Epoch: 0 Sample: 50240000 / 53735682 Loss: 1.468509567893458\n",
      "Epoch: 0 Sample: 50250000 / 53735682 Loss: 1.4940756087763423\n",
      "Epoch: 0 Sample: 50260000 / 53735682 Loss: 1.4505339599641207\n",
      "Epoch: 0 Sample: 50270000 / 53735682 Loss: 1.490080567002726\n",
      "Epoch: 0 Sample: 50280000 / 53735682 Loss: 1.4975762169577744\n",
      "Epoch: 0 Sample: 50290000 / 53735682 Loss: 1.5507712443586388\n",
      "Epoch: 0 Sample: 50300000 / 53735682 Loss: 1.5670173709645345\n",
      "Epoch: 0 Sample: 50310000 / 53735682 Loss: 1.4431235594004561\n",
      "Epoch: 0 Sample: 50320000 / 53735682 Loss: 1.4868888153124384\n",
      "Epoch: 0 Sample: 50330000 / 53735682 Loss: 1.5128685919928566\n",
      "Epoch: 0 Sample: 50340000 / 53735682 Loss: 1.4418742037985486\n",
      "Epoch: 0 Sample: 50350000 / 53735682 Loss: 1.4883414032952664\n",
      "Epoch: 0 Sample: 50360000 / 53735682 Loss: 1.4685558301537989\n",
      "Epoch: 0 Sample: 50370000 / 53735682 Loss: 1.4784962056952284\n",
      "Epoch: 0 Sample: 50380000 / 53735682 Loss: 1.4313136571236653\n",
      "Epoch: 0 Sample: 50390000 / 53735682 Loss: 1.469347144012481\n",
      "Epoch: 0 Sample: 50400000 / 53735682 Loss: 1.4892872269839685\n",
      "Epoch: 0 Sample: 50410000 / 53735682 Loss: 1.5224457026102751\n",
      "Epoch: 0 Sample: 50420000 / 53735682 Loss: 1.4937480218033405\n",
      "Epoch: 0 Sample: 50430000 / 53735682 Loss: 1.4809092712812144\n",
      "Epoch: 0 Sample: 50440000 / 53735682 Loss: 1.4716487778447056\n",
      "Epoch: 0 Sample: 50450000 / 53735682 Loss: 1.4440413243888892\n",
      "Epoch: 0 Sample: 50460000 / 53735682 Loss: 1.4892498605523903\n",
      "Epoch: 0 Sample: 50470000 / 53735682 Loss: 1.4888491936294486\n",
      "Epoch: 0 Sample: 50480000 / 53735682 Loss: 1.4844086562484393\n",
      "Epoch: 0 Sample: 50490000 / 53735682 Loss: 1.466897977309708\n",
      "Epoch: 0 Sample: 50500000 / 53735682 Loss: 1.43312810395109\n",
      "Epoch: 0 Sample: 50510000 / 53735682 Loss: 1.4148363552682894\n",
      "Epoch: 0 Sample: 50520000 / 53735682 Loss: 1.4897472998473524\n",
      "Epoch: 0 Sample: 50530000 / 53735682 Loss: 1.4271784304854847\n",
      "Epoch: 0 Sample: 50540000 / 53735682 Loss: 1.4708448873212392\n",
      "Epoch: 0 Sample: 50550000 / 53735682 Loss: 1.4909087072269298\n",
      "Epoch: 0 Sample: 50560000 / 53735682 Loss: 1.452153599682298\n",
      "Epoch: 0 Sample: 50570000 / 53735682 Loss: 1.4516775749051418\n",
      "Epoch: 0 Sample: 50580000 / 53735682 Loss: 1.455618923766941\n",
      "Epoch: 0 Sample: 50590000 / 53735682 Loss: 1.4168151849292745\n",
      "Epoch: 0 Sample: 50600000 / 53735682 Loss: 1.4071252147199296\n",
      "Epoch: 0 Sample: 50610000 / 53735682 Loss: 1.4762978582161672\n",
      "Epoch: 0 Sample: 50620000 / 53735682 Loss: 1.5328781402666571\n",
      "Epoch: 0 Sample: 50630000 / 53735682 Loss: 1.4673363350970003\n",
      "Epoch: 0 Sample: 50640000 / 53735682 Loss: 1.461166801608634\n",
      "Epoch: 0 Sample: 50650000 / 53735682 Loss: 1.5089829498200968\n",
      "Epoch: 0 Sample: 50660000 / 53735682 Loss: 1.4598685168412189\n",
      "Epoch: 0 Sample: 50670000 / 53735682 Loss: 1.4177490556045504\n",
      "Epoch: 0 Sample: 50680000 / 53735682 Loss: 1.503376252532368\n",
      "Epoch: 0 Sample: 50690000 / 53735682 Loss: 1.4501603979457411\n",
      "Epoch: 0 Sample: 50700000 / 53735682 Loss: 1.4595060746175257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 50710000 / 53735682 Loss: 1.5447151047287242\n",
      "Epoch: 0 Sample: 50720000 / 53735682 Loss: 1.4427394430457405\n",
      "Epoch: 0 Sample: 50730000 / 53735682 Loss: 1.481798853582609\n",
      "Epoch: 0 Sample: 50740000 / 53735682 Loss: 1.4525451008793364\n",
      "Epoch: 0 Sample: 50750000 / 53735682 Loss: 1.5166837221278628\n",
      "Epoch: 0 Sample: 50760000 / 53735682 Loss: 1.4570891295583666\n",
      "Epoch: 0 Sample: 50770000 / 53735682 Loss: 1.426333300679593\n",
      "Epoch: 0 Sample: 50780000 / 53735682 Loss: 1.4491633608004466\n",
      "Epoch: 0 Sample: 50790000 / 53735682 Loss: 1.399467373382109\n",
      "Epoch: 0 Sample: 50800000 / 53735682 Loss: 1.4359824442761888\n",
      "Epoch: 0 Sample: 50810000 / 53735682 Loss: 1.4967943685079643\n",
      "Epoch: 0 Sample: 50820000 / 53735682 Loss: 1.4293520433184335\n",
      "Epoch: 0 Sample: 50830000 / 53735682 Loss: 1.506159776722358\n",
      "Epoch: 0 Sample: 50840000 / 53735682 Loss: 1.4272007844709058\n",
      "Epoch: 0 Sample: 50850000 / 53735682 Loss: 1.537016667764381\n",
      "Epoch: 0 Sample: 50860000 / 53735682 Loss: 1.4321196119676671\n",
      "Epoch: 0 Sample: 50870000 / 53735682 Loss: 1.4734980177498498\n",
      "Epoch: 0 Sample: 50880000 / 53735682 Loss: 1.5570374682825467\n",
      "Epoch: 0 Sample: 50890000 / 53735682 Loss: 1.459887957036901\n",
      "Epoch: 0 Sample: 50900000 / 53735682 Loss: 1.4774391333512686\n",
      "Epoch: 0 Sample: 50910000 / 53735682 Loss: 1.5119613268329577\n",
      "Epoch: 0 Sample: 50920000 / 53735682 Loss: 1.511399679535382\n",
      "Epoch: 0 Sample: 50930000 / 53735682 Loss: 1.4991931834970278\n",
      "Epoch: 0 Sample: 50940000 / 53735682 Loss: 1.4817225749950274\n",
      "Epoch: 0 Sample: 50950000 / 53735682 Loss: 1.50315545901345\n",
      "Epoch: 0 Sample: 50960000 / 53735682 Loss: 1.5185488007495018\n",
      "Epoch: 0 Sample: 50970000 / 53735682 Loss: 1.3990877435313414\n",
      "Epoch: 0 Sample: 50980000 / 53735682 Loss: 1.4454140193946263\n",
      "Epoch: 0 Sample: 50990000 / 53735682 Loss: 1.4189502161510086\n",
      "Epoch: 0 Sample: 51000000 / 53735682 Loss: 1.4416660530236904\n",
      "Epoch: 0 Sample: 51010000 / 53735682 Loss: 1.4033693610035152\n",
      "Epoch: 0 Sample: 51020000 / 53735682 Loss: 1.4524584722344827\n",
      "Epoch: 0 Sample: 51030000 / 53735682 Loss: 1.4668319871115971\n",
      "Epoch: 0 Sample: 51040000 / 53735682 Loss: 1.5138224954191724\n",
      "Epoch: 0 Sample: 51050000 / 53735682 Loss: 1.5127148566786226\n",
      "Epoch: 0 Sample: 51060000 / 53735682 Loss: 1.4199922958534075\n",
      "Epoch: 0 Sample: 51070000 / 53735682 Loss: 1.4145570912640477\n",
      "Epoch: 0 Sample: 51080000 / 53735682 Loss: 1.497401709731136\n",
      "Epoch: 0 Sample: 51090000 / 53735682 Loss: 1.4898221158564766\n",
      "Epoch: 0 Sample: 51100000 / 53735682 Loss: 1.4613590027203989\n",
      "Epoch: 0 Sample: 51110000 / 53735682 Loss: 1.4432529847698465\n",
      "Epoch: 0 Sample: 51120000 / 53735682 Loss: 1.4852853343887964\n",
      "Epoch: 0 Sample: 51130000 / 53735682 Loss: 1.4766167537948327\n",
      "Epoch: 0 Sample: 51140000 / 53735682 Loss: 1.5152256193891425\n",
      "Epoch: 0 Sample: 51150000 / 53735682 Loss: 1.4598071746684311\n",
      "Epoch: 0 Sample: 51160000 / 53735682 Loss: 1.445275710954562\n",
      "Epoch: 0 Sample: 51170000 / 53735682 Loss: 1.5343309116605077\n",
      "Epoch: 0 Sample: 51180000 / 53735682 Loss: 1.6198944087583946\n",
      "Epoch: 0 Sample: 51190000 / 53735682 Loss: 1.5317016813616222\n",
      "Epoch: 0 Sample: 51200000 / 53735682 Loss: 1.446966144301245\n",
      "Epoch: 0 Sample: 51210000 / 53735682 Loss: 1.419575364251687\n",
      "Epoch: 0 Sample: 51220000 / 53735682 Loss: 1.4825386104200777\n",
      "Epoch: 0 Sample: 51230000 / 53735682 Loss: 1.4500394008832789\n",
      "Epoch: 0 Sample: 51240000 / 53735682 Loss: 1.4554837038041333\n",
      "Epoch: 0 Sample: 51250000 / 53735682 Loss: 1.4056143973918718\n",
      "Epoch: 0 Sample: 51260000 / 53735682 Loss: 1.4595884997285242\n",
      "Epoch: 0 Sample: 51270000 / 53735682 Loss: 1.455235143367196\n",
      "Epoch: 0 Sample: 51280000 / 53735682 Loss: 1.3984620380581907\n",
      "Epoch: 0 Sample: 51290000 / 53735682 Loss: 1.540699126403527\n",
      "Epoch: 0 Sample: 51300000 / 53735682 Loss: 1.4042435180616604\n",
      "Epoch: 0 Sample: 51310000 / 53735682 Loss: 1.3921371307934427\n",
      "Epoch: 0 Sample: 51320000 / 53735682 Loss: 1.4999772638286606\n",
      "Epoch: 0 Sample: 51330000 / 53735682 Loss: 1.462336639711169\n",
      "Epoch: 0 Sample: 51340000 / 53735682 Loss: 1.487689135254322\n",
      "Epoch: 0 Sample: 51350000 / 53735682 Loss: 1.4475426816366908\n",
      "Epoch: 0 Sample: 51360000 / 53735682 Loss: 1.5728653856246546\n",
      "Epoch: 0 Sample: 51370000 / 53735682 Loss: 1.4901882829460686\n",
      "Epoch: 0 Sample: 51380000 / 53735682 Loss: 1.4923522202295993\n",
      "Epoch: 0 Sample: 51390000 / 53735682 Loss: 1.3897613243066806\n",
      "Epoch: 0 Sample: 51400000 / 53735682 Loss: 1.524709181585373\n",
      "Epoch: 0 Sample: 51410000 / 53735682 Loss: 1.4322228986102878\n",
      "Epoch: 0 Sample: 51420000 / 53735682 Loss: 1.432950399158743\n",
      "Epoch: 0 Sample: 51430000 / 53735682 Loss: 1.5548939364390146\n",
      "Epoch: 0 Sample: 51440000 / 53735682 Loss: 1.3499858229625215\n",
      "Epoch: 0 Sample: 51450000 / 53735682 Loss: 1.4825993587841988\n",
      "Epoch: 0 Sample: 51460000 / 53735682 Loss: 1.4372211433127466\n",
      "Epoch: 0 Sample: 51470000 / 53735682 Loss: 1.4453197695878919\n",
      "Epoch: 0 Sample: 51480000 / 53735682 Loss: 1.5584657266592878\n",
      "Epoch: 0 Sample: 51490000 / 53735682 Loss: 1.4980508474973853\n",
      "Epoch: 0 Sample: 51500000 / 53735682 Loss: 1.460847766858957\n",
      "Epoch: 0 Sample: 51510000 / 53735682 Loss: 1.4264241657732564\n",
      "Epoch: 0 Sample: 51520000 / 53735682 Loss: 1.512675758229821\n",
      "Epoch: 0 Sample: 51530000 / 53735682 Loss: 1.5638737547607033\n",
      "Epoch: 0 Sample: 51540000 / 53735682 Loss: 1.5140626139770013\n",
      "Epoch: 0 Sample: 51550000 / 53735682 Loss: 1.512764374571863\n",
      "Epoch: 0 Sample: 51560000 / 53735682 Loss: 1.6115857344746196\n",
      "Epoch: 0 Sample: 51570000 / 53735682 Loss: 1.5162000743355994\n",
      "Epoch: 0 Sample: 51580000 / 53735682 Loss: 1.4069695230472399\n",
      "Epoch: 0 Sample: 51590000 / 53735682 Loss: 1.3986901758276309\n",
      "Epoch: 0 Sample: 51600000 / 53735682 Loss: 1.4371133906384286\n",
      "Epoch: 0 Sample: 51610000 / 53735682 Loss: 1.5056973598339596\n",
      "Epoch: 0 Sample: 51620000 / 53735682 Loss: 1.4992290043580367\n",
      "Epoch: 0 Sample: 51630000 / 53735682 Loss: 1.5149805776074332\n",
      "Epoch: 0 Sample: 51640000 / 53735682 Loss: 1.4244558040451172\n",
      "Epoch: 0 Sample: 51650000 / 53735682 Loss: 1.4341143569079564\n",
      "Epoch: 0 Sample: 51660000 / 53735682 Loss: 1.4191906994453285\n",
      "Epoch: 0 Sample: 51670000 / 53735682 Loss: 1.5214812632938988\n",
      "Epoch: 0 Sample: 51680000 / 53735682 Loss: 1.4567422588243102\n",
      "Epoch: 0 Sample: 51690000 / 53735682 Loss: 1.4935109760791394\n",
      "Epoch: 0 Sample: 51700000 / 53735682 Loss: 1.4351470653042693\n",
      "Epoch: 0 Sample: 51710000 / 53735682 Loss: 1.5425789252150897\n",
      "Epoch: 0 Sample: 51720000 / 53735682 Loss: 1.4722497784596569\n",
      "Epoch: 0 Sample: 51730000 / 53735682 Loss: 1.4493321300260114\n",
      "Epoch: 0 Sample: 51740000 / 53735682 Loss: 1.4859681090299603\n",
      "Epoch: 0 Sample: 51750000 / 53735682 Loss: 1.5359555543716454\n",
      "Epoch: 0 Sample: 51760000 / 53735682 Loss: 1.5179131793549967\n",
      "Epoch: 0 Sample: 51770000 / 53735682 Loss: 1.4603058577253816\n",
      "Epoch: 0 Sample: 51780000 / 53735682 Loss: 1.4861837391777768\n",
      "Epoch: 0 Sample: 51790000 / 53735682 Loss: 1.4236842843089854\n",
      "Epoch: 0 Sample: 51800000 / 53735682 Loss: 1.4649816424005615\n",
      "Epoch: 0 Sample: 51810000 / 53735682 Loss: 1.4552417040844465\n",
      "Epoch: 0 Sample: 51820000 / 53735682 Loss: 1.4227817090615473\n",
      "Epoch: 0 Sample: 51830000 / 53735682 Loss: 1.514742701754714\n",
      "Epoch: 0 Sample: 51840000 / 53735682 Loss: 1.4576033949951972\n",
      "Epoch: 0 Sample: 51850000 / 53735682 Loss: 1.4768763412689823\n",
      "Epoch: 0 Sample: 51860000 / 53735682 Loss: 1.4886443231076885\n",
      "Epoch: 0 Sample: 51870000 / 53735682 Loss: 1.5260744812567153\n",
      "Epoch: 0 Sample: 51880000 / 53735682 Loss: 1.4773037783383716\n",
      "Epoch: 0 Sample: 51890000 / 53735682 Loss: 1.5096312435449315\n",
      "Epoch: 0 Sample: 51900000 / 53735682 Loss: 1.5651417878629006\n",
      "Epoch: 0 Sample: 51910000 / 53735682 Loss: 1.5556560004556133\n",
      "Epoch: 0 Sample: 51920000 / 53735682 Loss: 1.5312454646415508\n",
      "Epoch: 0 Sample: 51930000 / 53735682 Loss: 1.5124539061847977\n",
      "Epoch: 0 Sample: 51940000 / 53735682 Loss: 1.478520079386211\n",
      "Epoch: 0 Sample: 51950000 / 53735682 Loss: 1.4581612438087381\n",
      "Epoch: 0 Sample: 51960000 / 53735682 Loss: 1.438677298350041\n",
      "Epoch: 0 Sample: 51970000 / 53735682 Loss: 1.5543027749201186\n",
      "Epoch: 0 Sample: 51980000 / 53735682 Loss: 1.5643330740447332\n",
      "Epoch: 0 Sample: 51990000 / 53735682 Loss: 1.4597032517934219\n",
      "Epoch: 0 Sample: 52000000 / 53735682 Loss: 1.408571859760407\n",
      "Epoch: 0 Sample: 52010000 / 53735682 Loss: 1.4819485322343269\n",
      "Epoch: 0 Sample: 52020000 / 53735682 Loss: 1.4486506987280752\n",
      "Epoch: 0 Sample: 52030000 / 53735682 Loss: 1.4902461728148995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 52040000 / 53735682 Loss: 1.4860425120306235\n",
      "Epoch: 0 Sample: 52050000 / 53735682 Loss: 1.4960863623470135\n",
      "Epoch: 0 Sample: 52060000 / 53735682 Loss: 1.4804264523950112\n",
      "Epoch: 0 Sample: 52070000 / 53735682 Loss: 1.5685031132286995\n",
      "Epoch: 0 Sample: 52080000 / 53735682 Loss: 1.485066962097438\n",
      "Epoch: 0 Sample: 52090000 / 53735682 Loss: 1.4915075745003952\n",
      "Epoch: 0 Sample: 52100000 / 53735682 Loss: 1.5388886315339014\n",
      "Epoch: 0 Sample: 52110000 / 53735682 Loss: 1.4628458759569807\n",
      "Epoch: 0 Sample: 52120000 / 53735682 Loss: 1.5015821809172412\n",
      "Epoch: 0 Sample: 52130000 / 53735682 Loss: 1.456978956607733\n",
      "Epoch: 0 Sample: 52140000 / 53735682 Loss: 1.4361259746179915\n",
      "Epoch: 0 Sample: 52150000 / 53735682 Loss: 1.4646136419903901\n",
      "Epoch: 0 Sample: 52160000 / 53735682 Loss: 1.4205618311221708\n",
      "Epoch: 0 Sample: 52170000 / 53735682 Loss: 1.467242387005294\n",
      "Epoch: 0 Sample: 52180000 / 53735682 Loss: 1.4858714313451737\n",
      "Epoch: 0 Sample: 52190000 / 53735682 Loss: 1.4682727780690208\n",
      "Epoch: 0 Sample: 52200000 / 53735682 Loss: 1.4352110752623644\n",
      "Epoch: 0 Sample: 52210000 / 53735682 Loss: 1.5417411626237458\n",
      "Epoch: 0 Sample: 52220000 / 53735682 Loss: 1.565718549784438\n",
      "Epoch: 0 Sample: 52230000 / 53735682 Loss: 1.4184115581288521\n",
      "Epoch: 0 Sample: 52240000 / 53735682 Loss: 1.4421871163620046\n",
      "Epoch: 0 Sample: 52250000 / 53735682 Loss: 1.4941642264145998\n",
      "Epoch: 0 Sample: 52260000 / 53735682 Loss: 1.4966677014951197\n",
      "Epoch: 0 Sample: 52270000 / 53735682 Loss: 1.3928667201634601\n",
      "Epoch: 0 Sample: 52280000 / 53735682 Loss: 1.469338040345876\n",
      "Epoch: 0 Sample: 52290000 / 53735682 Loss: 1.4381938544858315\n",
      "Epoch: 0 Sample: 52300000 / 53735682 Loss: 1.4596646726042612\n",
      "Epoch: 0 Sample: 52310000 / 53735682 Loss: 1.4138962607140204\n",
      "Epoch: 0 Sample: 52320000 / 53735682 Loss: 1.4381063438816484\n",
      "Epoch: 0 Sample: 52330000 / 53735682 Loss: 1.4774784824037281\n",
      "Epoch: 0 Sample: 52340000 / 53735682 Loss: 1.525579520882069\n",
      "Epoch: 0 Sample: 52350000 / 53735682 Loss: 1.5030527038582773\n",
      "Epoch: 0 Sample: 52360000 / 53735682 Loss: 1.4446656775654783\n",
      "Epoch: 0 Sample: 52370000 / 53735682 Loss: 1.4909896092036057\n",
      "Epoch: 0 Sample: 52380000 / 53735682 Loss: 1.5331543753109558\n",
      "Epoch: 0 Sample: 52390000 / 53735682 Loss: 1.4043261799502735\n",
      "Epoch: 0 Sample: 52400000 / 53735682 Loss: 1.5284639828370312\n",
      "Epoch: 0 Sample: 52410000 / 53735682 Loss: 1.4244033604315327\n",
      "Epoch: 0 Sample: 52420000 / 53735682 Loss: 1.472858088149894\n",
      "Epoch: 0 Sample: 52430000 / 53735682 Loss: 1.4395684142875391\n",
      "Epoch: 0 Sample: 52440000 / 53735682 Loss: 1.4118423550748416\n",
      "Epoch: 0 Sample: 52450000 / 53735682 Loss: 1.4429228878186109\n",
      "Epoch: 0 Sample: 52460000 / 53735682 Loss: 1.4981531247692574\n",
      "Epoch: 0 Sample: 52470000 / 53735682 Loss: 1.4566135901851973\n",
      "Epoch: 0 Sample: 52480000 / 53735682 Loss: 1.3988244205520308\n",
      "Epoch: 0 Sample: 52490000 / 53735682 Loss: 1.4636520015366927\n",
      "Epoch: 0 Sample: 52500000 / 53735682 Loss: 1.4601479179365293\n",
      "Epoch: 0 Sample: 52510000 / 53735682 Loss: 1.3865116094440093\n",
      "Epoch: 0 Sample: 52520000 / 53735682 Loss: 1.4480079630962115\n",
      "Epoch: 0 Sample: 52530000 / 53735682 Loss: 1.555900741446649\n",
      "Epoch: 0 Sample: 52540000 / 53735682 Loss: 1.4814495717737284\n",
      "Epoch: 0 Sample: 52550000 / 53735682 Loss: 1.5109045469671312\n",
      "Epoch: 0 Sample: 52560000 / 53735682 Loss: 1.4463282093158738\n",
      "Epoch: 0 Sample: 52570000 / 53735682 Loss: 1.4085514917198432\n",
      "Epoch: 0 Sample: 52580000 / 53735682 Loss: 1.4281032081548632\n",
      "Epoch: 0 Sample: 52590000 / 53735682 Loss: 1.5470929981391026\n",
      "Epoch: 0 Sample: 52600000 / 53735682 Loss: 1.3697392370661703\n",
      "Epoch: 0 Sample: 52610000 / 53735682 Loss: 1.431482734083089\n",
      "Epoch: 0 Sample: 52620000 / 53735682 Loss: 1.5317477797598316\n",
      "Epoch: 0 Sample: 52630000 / 53735682 Loss: 1.5025975072135362\n",
      "Epoch: 0 Sample: 52640000 / 53735682 Loss: 1.5491271343445114\n",
      "Epoch: 0 Sample: 52650000 / 53735682 Loss: 1.5103316682544938\n",
      "Epoch: 0 Sample: 52660000 / 53735682 Loss: 1.4081568102986046\n",
      "Epoch: 0 Sample: 52670000 / 53735682 Loss: 1.4531963566800556\n",
      "Epoch: 0 Sample: 52680000 / 53735682 Loss: 1.4417236692945838\n",
      "Epoch: 0 Sample: 52690000 / 53735682 Loss: 1.5130966302261326\n",
      "Epoch: 0 Sample: 52700000 / 53735682 Loss: 1.5049737563401955\n",
      "Epoch: 0 Sample: 52710000 / 53735682 Loss: 1.4464253714092068\n",
      "Epoch: 0 Sample: 52720000 / 53735682 Loss: 1.489446149320483\n",
      "Epoch: 0 Sample: 52730000 / 53735682 Loss: 1.4714434421922804\n",
      "Epoch: 0 Sample: 52740000 / 53735682 Loss: 1.4550659296347277\n",
      "Epoch: 0 Sample: 52750000 / 53735682 Loss: 1.4939282102022209\n",
      "Epoch: 0 Sample: 52760000 / 53735682 Loss: 1.4021777568480311\n",
      "Epoch: 0 Sample: 52770000 / 53735682 Loss: 1.4354439132556065\n",
      "Epoch: 0 Sample: 52780000 / 53735682 Loss: 1.5190875554573116\n",
      "Epoch: 0 Sample: 52790000 / 53735682 Loss: 1.4661127625679446\n",
      "Epoch: 0 Sample: 52800000 / 53735682 Loss: 1.5557305121527456\n",
      "Epoch: 0 Sample: 52810000 / 53735682 Loss: 1.4410549026234962\n",
      "Epoch: 0 Sample: 52820000 / 53735682 Loss: 1.436583102044537\n",
      "Epoch: 0 Sample: 52830000 / 53735682 Loss: 1.4449469648132949\n",
      "Epoch: 0 Sample: 52840000 / 53735682 Loss: 1.491155928636493\n",
      "Epoch: 0 Sample: 52850000 / 53735682 Loss: 1.4681047211521179\n",
      "Epoch: 0 Sample: 52860000 / 53735682 Loss: 1.5255892445662478\n",
      "Epoch: 0 Sample: 52870000 / 53735682 Loss: 1.5749908962577308\n",
      "Epoch: 0 Sample: 52880000 / 53735682 Loss: 1.5181986589661747\n",
      "Epoch: 0 Sample: 52890000 / 53735682 Loss: 1.4559029377596264\n",
      "Epoch: 0 Sample: 52900000 / 53735682 Loss: 1.5632042959708126\n",
      "Epoch: 0 Sample: 52910000 / 53735682 Loss: 1.5420671216504434\n",
      "Epoch: 0 Sample: 52920000 / 53735682 Loss: 1.5481766062560536\n",
      "Epoch: 0 Sample: 52930000 / 53735682 Loss: 1.481972032174331\n",
      "Epoch: 0 Sample: 52940000 / 53735682 Loss: 1.446943647919296\n",
      "Epoch: 0 Sample: 52950000 / 53735682 Loss: 1.5260721678347715\n",
      "Epoch: 0 Sample: 52960000 / 53735682 Loss: 1.4478037842582019\n",
      "Epoch: 0 Sample: 52970000 / 53735682 Loss: 1.5018331625460135\n",
      "Epoch: 0 Sample: 52980000 / 53735682 Loss: 1.4844871207088743\n",
      "Epoch: 0 Sample: 52990000 / 53735682 Loss: 1.4963352739664066\n",
      "Epoch: 0 Sample: 53000000 / 53735682 Loss: 1.5085668446369973\n",
      "Epoch: 0 Sample: 53010000 / 53735682 Loss: 1.3912796271220467\n",
      "Epoch: 0 Sample: 53020000 / 53735682 Loss: 1.458243364591608\n",
      "Epoch: 0 Sample: 53030000 / 53735682 Loss: 1.4726710322360796\n",
      "Epoch: 0 Sample: 53040000 / 53735682 Loss: 1.3678607594946182\n",
      "Epoch: 0 Sample: 53050000 / 53735682 Loss: 1.4799560689590394\n",
      "Epoch: 0 Sample: 53060000 / 53735682 Loss: 1.534023775669298\n",
      "Epoch: 0 Sample: 53070000 / 53735682 Loss: 1.4244299335809232\n",
      "Epoch: 0 Sample: 53080000 / 53735682 Loss: 1.5087937119171266\n",
      "Epoch: 0 Sample: 53090000 / 53735682 Loss: 1.573831623462411\n",
      "Epoch: 0 Sample: 53100000 / 53735682 Loss: 1.4781957070123823\n",
      "Epoch: 0 Sample: 53110000 / 53735682 Loss: 1.3953872193872776\n",
      "Epoch: 0 Sample: 53120000 / 53735682 Loss: 1.606214919765367\n",
      "Epoch: 0 Sample: 53130000 / 53735682 Loss: 1.4871639666761594\n",
      "Epoch: 0 Sample: 53140000 / 53735682 Loss: 1.418459204065624\n",
      "Epoch: 0 Sample: 53150000 / 53735682 Loss: 1.4919131292275034\n",
      "Epoch: 0 Sample: 53160000 / 53735682 Loss: 1.436839709001203\n",
      "Epoch: 0 Sample: 53170000 / 53735682 Loss: 1.4943589256244372\n",
      "Epoch: 0 Sample: 53180000 / 53735682 Loss: 1.5287196185424647\n",
      "Epoch: 0 Sample: 53190000 / 53735682 Loss: 1.3940426734138978\n",
      "Epoch: 0 Sample: 53200000 / 53735682 Loss: 1.5705509150300703\n",
      "Epoch: 0 Sample: 53210000 / 53735682 Loss: 1.5400365684636994\n",
      "Epoch: 0 Sample: 53220000 / 53735682 Loss: 1.4289889949222125\n",
      "Epoch: 0 Sample: 53230000 / 53735682 Loss: 1.4973147397488864\n",
      "Epoch: 0 Sample: 53240000 / 53735682 Loss: 1.4869396073464154\n",
      "Epoch: 0 Sample: 53250000 / 53735682 Loss: 1.4829531144181405\n",
      "Epoch: 0 Sample: 53260000 / 53735682 Loss: 1.4909558519623947\n",
      "Epoch: 0 Sample: 53270000 / 53735682 Loss: 1.4272154112937994\n",
      "Epoch: 0 Sample: 53280000 / 53735682 Loss: 1.491053922716183\n",
      "Epoch: 0 Sample: 53290000 / 53735682 Loss: 1.3840753758983833\n",
      "Epoch: 0 Sample: 53300000 / 53735682 Loss: 1.463019569022404\n",
      "Epoch: 0 Sample: 53310000 / 53735682 Loss: 1.5009595460148586\n",
      "Epoch: 0 Sample: 53320000 / 53735682 Loss: 1.4474754335276174\n",
      "Epoch: 0 Sample: 53330000 / 53735682 Loss: 1.5050296423338854\n",
      "Epoch: 0 Sample: 53340000 / 53735682 Loss: 1.4851644504922321\n",
      "Epoch: 0 Sample: 53350000 / 53735682 Loss: 1.4954333976809882\n",
      "Epoch: 0 Sample: 53360000 / 53735682 Loss: 1.4306777329653122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Sample: 53370000 / 53735682 Loss: 1.492429364223669\n",
      "Epoch: 0 Sample: 53380000 / 53735682 Loss: 1.534498426750148\n",
      "Epoch: 0 Sample: 53390000 / 53735682 Loss: 1.3992495056170706\n",
      "Epoch: 0 Sample: 53400000 / 53735682 Loss: 1.4315951117222405\n",
      "Epoch: 0 Sample: 53410000 / 53735682 Loss: 1.4216226023583451\n",
      "Epoch: 0 Sample: 53420000 / 53735682 Loss: 1.5297226892812505\n",
      "Epoch: 0 Sample: 53430000 / 53735682 Loss: 1.4597649694705932\n",
      "Epoch: 0 Sample: 53440000 / 53735682 Loss: 1.4248060046158222\n",
      "Epoch: 0 Sample: 53450000 / 53735682 Loss: 1.4962728735137225\n",
      "Epoch: 0 Sample: 53460000 / 53735682 Loss: 1.4092403993318392\n",
      "Epoch: 0 Sample: 53470000 / 53735682 Loss: 1.587569907138227\n",
      "Epoch: 0 Sample: 53480000 / 53735682 Loss: 1.408660864448011\n",
      "Epoch: 0 Sample: 53490000 / 53735682 Loss: 1.472817367747251\n",
      "Epoch: 0 Sample: 53500000 / 53735682 Loss: 1.416116925686125\n",
      "Epoch: 0 Sample: 53510000 / 53735682 Loss: 1.4942346577576702\n",
      "Epoch: 0 Sample: 53520000 / 53735682 Loss: 1.4805710228065736\n",
      "Epoch: 0 Sample: 53530000 / 53735682 Loss: 1.4185978497646776\n",
      "Epoch: 0 Sample: 53540000 / 53735682 Loss: 1.4291067978278384\n",
      "Epoch: 0 Sample: 53550000 / 53735682 Loss: 1.5212768997865846\n",
      "Epoch: 0 Sample: 53560000 / 53735682 Loss: 1.4139722832754464\n",
      "Epoch: 0 Sample: 53570000 / 53735682 Loss: 1.4627341807752319\n",
      "Epoch: 0 Sample: 53580000 / 53735682 Loss: 1.4339097807548706\n",
      "Epoch: 0 Sample: 53590000 / 53735682 Loss: 1.4168861647021793\n",
      "Epoch: 0 Sample: 53600000 / 53735682 Loss: 1.4158891850193789\n",
      "Epoch: 0 Sample: 53610000 / 53735682 Loss: 1.5301625744687088\n",
      "Epoch: 0 Sample: 53620000 / 53735682 Loss: 1.4757588610129684\n",
      "Epoch: 0 Sample: 53630000 / 53735682 Loss: 1.476413568674043\n",
      "Epoch: 0 Sample: 53640000 / 53735682 Loss: 1.4720903586908765\n",
      "Epoch: 0 Sample: 53650000 / 53735682 Loss: 1.4536919676843096\n",
      "Epoch: 0 Sample: 53660000 / 53735682 Loss: 1.5022278949238435\n",
      "Epoch: 0 Sample: 53670000 / 53735682 Loss: 1.4517541633817186\n",
      "Epoch: 0 Sample: 53680000 / 53735682 Loss: 1.4983649437738147\n",
      "Epoch: 0 Sample: 53690000 / 53735682 Loss: 1.4771417465394865\n",
      "Epoch: 0 Sample: 53700000 / 53735682 Loss: 1.4473500898074856\n",
      "Epoch: 0 Sample: 53710000 / 53735682 Loss: 1.47361497424432\n",
      "Epoch: 0 Sample: 53720000 / 53735682 Loss: 1.4094117093929035\n",
      "Epoch: 0 Sample: 53730000 / 53735682 Loss: 1.4926954377473651\n"
     ]
    }
   ],
   "source": [
    "U0 = (np.random.rand(len(words), embDim) - 0.5) / embDim\n",
    "V0 = (np.random.rand(len(words), embDim) - 0.5) / embDim\n",
    "v0 = (np.random.rand(embDim) - 0.5) / embDim\n",
    "\n",
    "seq = sampling.createSamplingSequence(freqs)\n",
    "contextFunction = lambda c: sampling.sampleContext(c, seq, negativesCount)\n",
    "\n",
    "if len(sys.argv)>1 and sys.argv[1] == 'cumulative':\n",
    "    U,V,v = w2v_sgd.stochasticGradientDescend(data,np.copy(U0),np.copy(V0),np.copy(v0),contextFunction,grads.lossAndGradientCumulative)\n",
    "else:\n",
    "    U,V,v = w2v_sgd.stochasticGradientDescend(data,np.copy(U0),np.copy(V0),np.copy(v0),contextFunction,grads.lossAndGradientBatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa516d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('w2v-U',U)\n",
    "np.save('w2v-V',V)\n",
    "np.save('w2v-vv',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a77ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 20000 words...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#U = np.load('w2v-U')\n",
    "#V = np.load('w2v-V')\n",
    "\n",
    "E = np.concatenate([U,V],axis=1)\n",
    "\n",
    "E_reduced =utils.SVD_k_dim(E,k=2)\n",
    "E_normalized_2d = E_reduced /np.linalg.norm(E_reduced, axis=1)[:, np.newaxis]\n",
    "\n",
    "sampleWords = 'януари октомври седмица година медии пазар стоки бизнес фирма бюджет петрол нефт'.split()\n",
    "\n",
    "utils.plot_embeddings(E_normalized_2d, word2ind, sampleWords, 'embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d751e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
