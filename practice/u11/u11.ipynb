{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "> ### Стоян Михов\n",
    "> #### Зимен семестър 2021/2022\n",
    "\n",
    "### Упражнение 11\n",
    "\n",
    " За да работи програмата трябва корпуса от публицистични текстове за Югоизточна Европа,\n",
    " да се намира разархивиран в директорията, в която е програмата (виж упражнение 2).\n",
    "\n",
    " Преди да се стартира програмата е необходимо да се активира съответното обкръжение с командата: `conda activate tii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/psarlov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2000, 2.0000, 3.0000],\n",
       "        [4.0000, 5.0000, 6.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1.2,2,3],[4,5,6]]);X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 2.0000, 1.0000],\n",
       "        [2.0000, 3.0000, 4.1000]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.tensor([[3,2,1],[2,3,4.1]], requires_grad=True);Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8554, 0.9563, 0.1901, 0.0984],\n",
       "        [0.2970, 0.6576, 0.7569, 0.2961],\n",
       "        [0.2996, 0.8576, 0.0432, 0.2611]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3,4, requires_grad=True);A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9788, 10.0771,  3.9991,  2.6420],\n",
       "        [10.5339, 19.6603,  7.6325,  5.5964]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.matmul(X+Y,A);B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-132.2402, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.sum(-2 * B);C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.4000, -20.4000, -20.4000, -20.4000],\n",
       "        [-24.0000, -24.0000, -24.0000, -24.0000],\n",
       "        [-28.2000, -28.2000, -28.2000, -28.2000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-20.4000, -20.4000, -20.4000, -20.4000],\n",
      "        [-24.0000, -24.0000, -24.0000, -24.0000],\n",
      "        [-28.2000, -28.2000, -28.2000, -28.2000]])\n",
      "tensor([[-4.2002, -4.0153, -2.9230],\n",
      "        [-4.2002, -4.0153, -2.9230]])\n"
     ]
    }
   ],
   "source": [
    "print(A.grad)\n",
    "print(Y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8554, 0.9563, 0.1901, 0.0984],\n",
       "        [0.2970, 0.6576, 0.7569, 0.2961],\n",
       "        [0.2996, 0.8576, 0.0432, 0.2611]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.mean(A);S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.grad)\n",
    "print(Y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.grad = None\n",
    "Y.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.mean(torch.matmul(Y,A));S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(A.grad)\n",
    "print(Y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[25.3354, 25.4363, 24.6701, 24.5784],\n",
       "         [29.0970, 29.4576, 29.5569, 29.0961],\n",
       "         [34.1396, 34.6976, 33.8832, 34.1011]], requires_grad=True),\n",
       " tensor([[8.0403, 6.8183, 4.5076],\n",
       "         [7.0403, 7.8183, 7.6076]], requires_grad=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.0403, 6.8183, 4.5076],\n",
      "        [7.0403, 7.8183, 7.6076]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    A -= 1.2 * A.grad\n",
    "    Y -= 1.2 * Y.grad\n",
    "    A.grad = None\n",
    "    Y.grad = None\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Визуализация на прогреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class progressBar:\n",
    "    def __init__(self ,barWidth = 50):\n",
    "        self.barWidth = barWidth\n",
    "        self.period = None\n",
    "    def start(self, count):\n",
    "        self.item=0\n",
    "        self.period = int(count / self.barWidth)\n",
    "        sys.stdout.write(\"[\"+(\" \" * self.barWidth)+\"]\")\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\b\" * (self.barWidth+1))\n",
    "    def tick(self):\n",
    "        if self.item>0 and self.item % self.period == 0:\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "        self.item += 1\n",
    "    def stop(self):\n",
    "        sys.stdout.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDictionary(corpus, limit=20000):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    dictionary = {}\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for w in doc:\n",
    "            if w not in dictionary: dictionary[w] = 0\n",
    "        dictionary[w] += 1\n",
    "    L = sorted([(w,dictionary[w]) for w in dictionary], key = lambda x: x[1] , reverse=True)\n",
    "    if limit > len(L): limit = len(L)\n",
    "    words = [ w for w,_ in L[:limit] ] + [unkToken]\n",
    "    word2ind = { w:i for i,w in enumerate(words)}\n",
    "    pb.stop()\n",
    "    return words, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(corpus, order, word2ind):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    unk = word2ind[unkToken]\n",
    "    start = word2ind[startToken]\n",
    "\n",
    "    points = sum(len(s)-1 for s in corpus)\n",
    "    \n",
    "    target = np.empty(points, dtype='int32')\n",
    "    context = np.empty((points,order-1), dtype='int32')\n",
    "    p = 0\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for wi in range(1,len(doc)):\n",
    "            i = word2ind.get(doc[wi], unk)\n",
    "            target[p] = i\n",
    "            sample = []\n",
    "            for k in range(1,order):\n",
    "                if wi-k < 0:\n",
    "                    j = start\n",
    "                else:\n",
    "                    j = word2ind.get(doc[wi-k], unk)\n",
    "                context[p,k-1] = j\n",
    "            p += 1\n",
    "    pb.stop()\n",
    "    return target, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Зареждане на корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n"
     ]
    }
   ],
   "source": [
    "corpus_root = '../JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "startToken = '<START>'\n",
    "endToken = '<END>'\n",
    "unkToken = '<UNK>'\n",
    "\n",
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]\n",
    "\n",
    "words, word2ind = extractDictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n"
     ]
    }
   ],
   "source": [
    "order = 4\n",
    "target, context = extractData(corpus, order, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 50\n",
    "hid_size = 100\n",
    "\n",
    "L = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 1000\n",
    "idx = np.arange(len(target), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "learning_rate = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Първи вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = torch.empty(L, emb_size, requires_grad = True)\n",
    "W1 = torch.empty((order-1)*emb_size, hid_size, requires_grad = True)\n",
    "b1 = torch.empty(hid_size, requires_grad = True)\n",
    "W2 = torch.empty(hid_size, L, requires_grad = True)\n",
    "b2 = torch.empty(L, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6055, -1.7630,  0.2008,  ..., -0.9813,  0.6026, -0.4261],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(E)\n",
    "torch.nn.init.normal_(W1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(W2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_fn = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6167/3056281611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mE\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mW1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mW2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    E -= learning_rate * E.grad\n",
    "    W1 -= learning_rate * W1.grad\n",
    "    b1 -= learning_rate * b1.grad\n",
    "    W2 -= learning_rate * W2.grad\n",
    "    b2 -= learning_rate * b2.grad\n",
    "    # Manually zero the gradients\n",
    "    E.grad = None\n",
    "    W1.grad = None\n",
    "    b1.grad = None\n",
    "    W2.grad = None\n",
    "    b2.grad = None\n",
    "\n",
    "if b % 10000 == 0:\n",
    "    print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 9992433 9.774436950683594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6167/608327347.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mE\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mW1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mb1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "\n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    S = len(batchIdx)\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long)\n",
    "    batchContext = context[batchIdx]\n",
    "\n",
    "    X = E[batchContext].view(S,(order-1) * emb_size)\n",
    "    h = sigmoid_fn(torch.matmul(X,W1) + b1)\n",
    "    z = torch.matmul(h,W2) + b2\n",
    "    \n",
    "    t = torch.exp(z)\n",
    "    s = torch.sum(t,axis=1)\n",
    "    z = t/s.unsqueeze(1)\n",
    "    p = z[torch.arange(S),batchTarget]\n",
    "    H = -torch.mean(torch.log(p))\n",
    "\n",
    "    H.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        E -= learning_rate * E.grad\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "        # Manually zero the gradients\n",
    "        E.grad = None\n",
    "        W1.grad = None\n",
    "        b1.grad = None\n",
    "        W2.grad = None\n",
    "        b2.grad = None\n",
    "\n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Втори вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8930, -0.5340, -0.6765,  ...,  1.3285, -0.3465,  1.5441],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(E)\n",
    "torch.nn.init.normal_(W1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(W2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 9992433 29.535554885864258\n",
      "10000 / 9992433 21.66497802734375\n",
      "20000 / 9992433 18.567216873168945\n",
      "30000 / 9992433 16.70700454711914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6167/3745840083.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tii/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tii/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    S = len(batchIdx)\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long)\n",
    "    batchContext = context[batchIdx]\n",
    "    \n",
    "    X = E[batchContext].view(S,(order-1) * emb_size)\n",
    "    h = sigmoid_fn(torch.matmul(X,W1) + b1)\n",
    "    z = torch.matmul(h,W2) + b2\n",
    "    H = loss_fn(z,batchTarget)\n",
    "    \n",
    "    H.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        E -= learning_rate * E.grad\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "        # Manually zero the gradients\n",
    "        E.grad = None\n",
    "        W1.grad = None\n",
    "        b1.grad = None\n",
    "        W2.grad = None\n",
    "        b2.grad = None\n",
    "    \n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Трети вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6167/2065967185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "torch.version.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6167/3892558280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tii/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/anaconda3/envs/tii/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "E = torch.empty(L, emb_size, requires_grad = True, device = device)\n",
    "W1 = torch.empty((order-1)*emb_size, hid_size, requires_grad = True, device = device)\n",
    "b1 = torch.empty(hid_size, requires_grad = True, device = device)\n",
    "W2 = torch.empty(hid_size, L, requires_grad = True, device = device)\n",
    "b2 = torch.empty(L, requires_grad = True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.normal_(E)\n",
    "torch.nn.init.normal_(W1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(W2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    S = len(batchIdx)\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long, device = device)\n",
    "    batchContext = context[batchIdx]\n",
    "    \n",
    "    X = E[batchContext].view(S,(order-1) * emb_size)\n",
    "    h = sigmoid_fn(torch.matmul(X,W1) + b1)\n",
    "    z = torch.matmul(h,W2) + b2\n",
    "    H = loss_fn(z,batchTarget)\n",
    "    \n",
    "    H.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        E -= learning_rate * E.grad\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "        # Manually zero the gradients\n",
    "        E.grad = None\n",
    "        W1.grad = None\n",
    "        b1.grad = None\n",
    "        W2.grad = None\n",
    "        b2.grad = None\n",
    "    \n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
