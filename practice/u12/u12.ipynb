{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "> ### Стоян Михов\n",
    "> #### Зимен семестър 2021/2022\n",
    "\n",
    "### Упражнение 12\n",
    "\n",
    " За да работи програмата трябва корпуса от публицистични текстове за Югоизточна Европа,\n",
    " да се намира разархивиран в директорията, в която е програмата (виж упражнение 2).\n",
    "\n",
    " Преди да се стартира програмата е необходимо да се активира съответното обкръжение с командата: `conda activate tii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Визуализация на прогреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class progressBar:\n",
    "    def __init__(self ,barWidth = 50):\n",
    "        self.barWidth = barWidth\n",
    "        self.period = None\n",
    "    def start(self, count):\n",
    "        self.item=0\n",
    "        self.period = int(count / self.barWidth)\n",
    "        sys.stdout.write(\"[\"+(\" \" * self.barWidth)+\"]\")\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\b\" * (self.barWidth+1))\n",
    "    def tick(self):\n",
    "        if self.item>0 and self.item % self.period == 0:\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "        self.item += 1\n",
    "    def stop(self):\n",
    "        sys.stdout.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDictionary(corpus, limit=20000):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    dictionary = {}\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for w in doc:\n",
    "            if w not in dictionary: dictionary[w] = 0\n",
    "        dictionary[w] += 1\n",
    "    L = sorted([(w,dictionary[w]) for w in dictionary], key = lambda x: x[1] , reverse=True)\n",
    "    if limit > len(L): limit = len(L)\n",
    "    words = [ w for w,_ in L[:limit] ] + [unkToken]\n",
    "    word2ind = { w:i for i,w in enumerate(words)}\n",
    "    pb.stop()\n",
    "    return words, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentCorpus(fullSentCorpus, testFraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(fullSentCorpus)\n",
    "    testCount = int(len(fullSentCorpus) * testFraction)\n",
    "    testSentCorpus = fullSentCorpus[:testCount]\n",
    "    trainSentCorpus = fullSentCorpus[testCount:]\n",
    "    return testSentCorpus, trainSentCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(corpus, order, word2ind):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    unk = word2ind[unkToken]\n",
    "    start = word2ind[startToken]\n",
    "\n",
    "    points = sum(len(s)-1 for s in corpus)\n",
    "    \n",
    "    target = np.empty(points, dtype='int32')\n",
    "    context = np.empty((points,order-1), dtype='int32')\n",
    "    p = 0\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for wi in range(1,len(doc)):\n",
    "            i = word2ind.get(doc[wi], unk)\n",
    "            target[p] = i\n",
    "            for k in range(1,order):\n",
    "                if wi-k < 0:\n",
    "                    j = start\n",
    "                else:\n",
    "                    j = word2ind.get(doc[wi-k], unk)\n",
    "                context[p,k-1] = j\n",
    "            p += 1\n",
    "    pb.stop()\n",
    "    return target, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Зареждане на корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "startToken = '<START>'\n",
    "endToken = '<END>'\n",
    "unkToken = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word2ind = extractDictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus, trainCorpus  = splitSentCorpus(corpus, testFraction = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 4\n",
    "target, context = extractData(trainCorpus, order, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 50\n",
    "hid_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 1000\n",
    "idx = np.arange(len(target), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "learning_rate = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Параметри на модела"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = torch.empty(L, emb_size, requires_grad = True)\n",
    "W1 = torch.empty((order-1)*emb_size, hid_size, requires_grad = True)\n",
    "b1 = torch.empty(hid_size, requires_grad = True)\n",
    "W2 = torch.empty(hid_size, L, requires_grad = True)\n",
    "b2 = torch.empty(L, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Стар вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.normal_(E)\n",
    "torch.nn.init.normal_(W1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(W2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    S = len(batchIdx)\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long)\n",
    "    batchContext = context[batchIdx]\n",
    "    \n",
    "    X = E[batchContext].view(S,(order-1) * emb_size)\n",
    "    h = torch.sigmoid(torch.matmul(X,W1) + b1)\n",
    "    z = torch.matmul(h,W2) + b2\n",
    "    H = torch.nn.functional.cross_entropy(z,batchTarget)\n",
    "    \n",
    "    H.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        E -= learning_rate * E.grad\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "        # Manually zero the gradients\n",
    "        E.grad = None\n",
    "        W1.grad = None\n",
    "        b1.grad = None\n",
    "        W2.grad = None\n",
    "        b2.grad = None\n",
    "    \n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Дефиниране на нова функция за афинна трансформация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineFunction(torch.autograd.Function):\n",
    "    \n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # This function implements output = input @ weight + bias\n",
    "    def forward(ctx, input, weight, bias):\n",
    "        ctx.save_for_backward(input, weight, bias)\n",
    "        output = torch.mm(input,weight)\n",
    "        output += bias.unsqueeze(0)\n",
    "        return output\n",
    "    \n",
    "    # This function gets the gradient for its output\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight, bias = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = torch.mm(grad_output, weight.t())\n",
    "        grad_weight = torch.mm(input.t(), grad_output)\n",
    "        grad_bias = grad_output.sum(0)\n",
    "        \n",
    "        return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######    вариант използващ афинната функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.normal_(E)\n",
    "torch.nn.init.normal_(W1)\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(W2)\n",
    "torch.nn.init.normal_(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long)\n",
    "    batchContext = context[batchIdx]\n",
    "    \n",
    "    X = E[batchContext].flatten(1,2)\n",
    "    h = torch.sigmoid(AffineFunction.apply(X,W1,b1))\n",
    "    z = AffineFunction.apply(h,W2,b2)\n",
    "    H = torch.nn.functional.cross_entropy(z,batchTarget)\n",
    "    \n",
    "    H.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        E -= learning_rate * E.grad\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "        # Manually zero the gradients\n",
    "        E.grad = None\n",
    "        W1.grad = None\n",
    "        b1.grad = None\n",
    "        W2.grad = None\n",
    "        b2.grad = None\n",
    "    \n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Вариант с използване на модул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LModel(torch.nn.Module):\n",
    "    def __init__(self, L, emb_size, hid_size, order):\n",
    "        super(LModel, self).__init__()\n",
    "        \n",
    "        self.E = torch.nn.Parameter(torch.rand(L, emb_size)-0.5)\n",
    "        self.W1 = torch.nn.Parameter(torch.rand((order-1)*emb_size, hid_size)-0.5)\n",
    "        self.b1 = torch.nn.Parameter(torch.rand(hid_size)-0.5)\n",
    "        self.W2 = torch.nn.Parameter(torch.rand(hid_size, L)-0.5)\n",
    "        self.b2 = torch.nn.Parameter(torch.rand(L)-0.5)\n",
    "    \n",
    "    def forward(self, context, target):\n",
    "        device = next(model.parameters()).device\n",
    "        contextTensor = torch.tensor(context, dtype=torch.long, device = device)\n",
    "        targetTensor = torch.tensor(target, dtype=torch.long, device = device)\n",
    "        \n",
    "        X = self.E[contextTensor].flatten(1,2)\n",
    "        h = torch.sigmoid(torch.matmul(X,self.W1) + self.b1)\n",
    "        z = torch.matmul(h,self.W2) + self.b2\n",
    "        H = torch.nn.functional.cross_entropy(z,targetTensor)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(i,torch.cuda.get_device_name(i)) for i in range(torch.cuda.device_count())];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LModel(L, emb_size, hid_size, order).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.named_parameters(): print(p[0],'\\t',p[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    H = model(context[batchIdx],target[batchIdx])\n",
    "    \n",
    "    model.zero_grad()\n",
    "    H.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Вариант с модул, в който са вложени други модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LModel(torch.nn.Module):\n",
    "    def __init__(self, L, emb_size, hid_size, order):\n",
    "        super(LModel, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(L, emb_size)\n",
    "        self.layer1 = torch.nn.Linear((order-1) * emb_size, hid_size)\n",
    "        self.layer2 = torch.nn.Linear(hid_size, L)\n",
    "    \n",
    "    def forward(self, context, target):\n",
    "        device = next(model.parameters()).device\n",
    "        targetTensor = torch.tensor(target, dtype=torch.long, device = device)\n",
    "        contextTensor = torch.tensor(context, dtype=torch.long, device = device)\n",
    "\n",
    "        X = self.embedding(contextTensor).flatten(1,2)\n",
    "        h = torch.sigmoid(self.layer1(X))\n",
    "        z = self.layer2(h)\n",
    "        return torch.nn.functional.cross_entropy(z,targetTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LModel(L, emb_size, hid_size, order).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    H = model(context[batchIdx],target[batchIdx])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Вариант с използване на последователност от модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "                            torch.nn.Embedding(L, emb_size),\n",
    "                            torch.nn.Flatten(1,2),\n",
    "                            torch.nn.Linear((order-1) * emb_size, hid_size),\n",
    "                            torch.nn.Sigmoid(),\n",
    "                            torch.nn.Linear(hid_size, L)\n",
    "                            ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0,len(idx),batchSize):\n",
    "    \n",
    "    batchIdx = idx[b:min(b+batchSize,len(idx))]\n",
    "    batchTarget = torch.tensor(target[batchIdx], dtype=torch.long, device = device)\n",
    "    batchContext = torch.tensor(context[batchIdx], dtype=torch.long, device = device)\n",
    "    \n",
    "    z = model(batchContext)\n",
    "    H = torch.nn.functional.cross_entropy(z,batchTarget)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if b % 10000 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, testCorpus, word2ind, order, device, batchSize):\n",
    "    target, context = extractData(testCorpus, order, word2ind)\n",
    "\n",
    "    H = 0.\n",
    "    for b in range(0,len(target),batchSize):\n",
    "        batchTarget = torch.tensor(target[b:min(b+batchSize,len(target))], dtype=torch.long, device = device)\n",
    "        batchContext = torch.tensor(context[b:min(b+batchSize,len(target))], dtype=torch.long, device = device)\n",
    "        l = len(batchTarget)\n",
    "        \n",
    "        z = model(batchContext)\n",
    "        H += l * torch.nn.functional.cross_entropy(z,batchTarget)\n",
    "\n",
    "    return math.exp(H/len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perplexity(model, testCorpus, word2ind, order, device, batchSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разбиване на корпуса на партиди с изречения с еднаква дължина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitCorpusInBatches(corpus, batchSize):\n",
    "    minLen = min(len(s) for s in corpus)\n",
    "    maxLen = max(len(s) for s in corpus)\n",
    "    \n",
    "    corpusBins = [ []  for _ in range(maxLen - minLen + 1) ]\n",
    "    for s in corpus:\n",
    "        l = len(s) - minLen\n",
    "        corpusBins[l].append(s)\n",
    "    \n",
    "    batchCorpus = []\n",
    "    for l in range(maxLen - minLen + 1):\n",
    "        bin = corpusBins[l]\n",
    "        idx = np.arange(len(bin), dtype='int32')\n",
    "        np.random.shuffle(idx)\n",
    "        for b in range(0, len(bin), batchSize):\n",
    "            batch = []\n",
    "            for si in range(b, min(b + batchSize, len(bin))):\n",
    "                batch.append(bin[idx[si]])\n",
    "            batchCorpus.append(batch)\n",
    "    return batchCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCellModel(torch.nn.Module): # 33\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super(LSTMCellModel, self).__init__()\n",
    "        self.ii = torch.nn.Linear(embed_size, hidden_size)\n",
    "        self.fi = torch.nn.Linear(embed_size, hidden_size)\n",
    "        self.oi = torch.nn.Linear(embed_size, hidden_size)\n",
    "        self.gi = torch.nn.Linear(embed_size, hidden_size)\n",
    "        self.ih = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.fh = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.oh = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.gh = torch.nn.Linear(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hc_0):\n",
    "        (h_0, c_0) = hc_0\n",
    "        i = torch.sigmoid(self.ii(input) + self.ih(h_0))\n",
    "        f = torch.sigmoid(self.fi(input) + self.fh(h_0))\n",
    "        o = torch.sigmoid(self.oi(input) + self.oh(h_0))\n",
    "        g = torch.tanh(self.gi(input) + self.gh(h_0))\n",
    "        c_1 = f * c_0 + i * g\n",
    "        h_1 = o * torch.tanh(c_1)\n",
    "        return (h_1, c_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = LSTMCellModel(embed_size, hidden_size)\n",
    "        #self.cell = torch.nn.LSTMCell(embed_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        seq_len = input.shape[0]\n",
    "        batch_size = input.shape[1]\n",
    "        device = next(self.parameters()).device\n",
    "        h = torch.zeros(batch_size,self.hidden_size, device = device)\n",
    "        c = torch.zeros(batch_size,self.hidden_size, device = device)\n",
    "        output = []\n",
    "        for i in range(seq_len):\n",
    "            h, c = self.cell(input[i], (h, c))\n",
    "            output.append(h)\n",
    "        return torch.stack(output), (h,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModel(torch.nn.Module): # 23\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken):\n",
    "        super(LSTMLanguageModel, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        #self.lstm = LSTMModel(embed_size, hidden_size)\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
    "    \n",
    "    def forward(self, source):\n",
    "        ### source e списък от изречения. Всяко изречение е списък от думи\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = len(source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        X = torch.t(torch.tensor(sents, dtype=torch.long, device=device))\n",
    "        E = self.embed(X[:-1])\n",
    "        output, _ = self.lstm(E)\n",
    "        Z = self.projection(output.flatten(0,1))\n",
    "        Y_bar = X[1:].flatten(0,1)\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Зареждане на корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "batchCorpus = splitCorpusInBatches(trainCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LSTMLanguageModel(emb_size, hid_size, word2ind, unkToken).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(batchCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(len(idx)):\n",
    "    H = lm(batchCorpus[idx[b]])\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, testCorpus, batchSize):\n",
    "    batchCorpus = splitCorpusInBatches(testCorpus, batchSize)\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(len(batchCorpus)):\n",
    "        l = len(batchCorpus[b])*(len(batchCorpus[b][0])-1)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batchCorpus[b])\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perplexity(lm, testCorpus, batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p[0] for p in lm.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lm.state_dict(), 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in lm.state_dict():\n",
    "    print(p,lm.state_dict()[p].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 = LSTMLanguageModel(emb_size, hid_size, word2ind, unkToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1.load_state_dict(torch.load('lstm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perplexity(lm1, testCorpus, batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
