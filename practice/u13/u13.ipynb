{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "> ### Стоян Михов\n",
    "> #### Зимен семестър 2021/2022\n",
    "\n",
    "### Упражнение 13\n",
    "\n",
    " За да работи програмата трябва корпуса от публицистични текстове за Югоизточна Европа,\n",
    " да се намира разархивиран в директорията, в която е програмата (виж упражнение 2).\n",
    "\n",
    " Преди да се стартира програмата е необходимо да се активира съответното обкръжение с командата: `conda activate tii`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Визуализация на прогреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class progressBar:\n",
    "    def __init__(self ,barWidth = 50):\n",
    "        self.barWidth = barWidth\n",
    "        self.period = None\n",
    "    def start(self, count):\n",
    "        self.item=0\n",
    "        self.period = int(count / self.barWidth)\n",
    "        sys.stdout.write(\"[\"+(\" \" * self.barWidth)+\"]\")\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\b\" * (self.barWidth+1))\n",
    "    def tick(self):\n",
    "        if self.item>0 and self.item % self.period == 0:\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "        self.item += 1\n",
    "    def stop(self):\n",
    "        sys.stdout.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDictionary(corpus, limit=20000):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    dictionary = {}\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for w in doc:\n",
    "            if w not in dictionary: dictionary[w] = 0\n",
    "        dictionary[w] += 1\n",
    "    L = sorted([(w,dictionary[w]) for w in dictionary], key = lambda x: x[1] , reverse=True)\n",
    "    if limit > len(L): limit = len(L)\n",
    "    words = [ w for w,_ in L[:limit] ] + [unkToken] + [padToken]\n",
    "    word2ind = { w:i for i,w in enumerate(words)}\n",
    "    pb.stop()\n",
    "    return words, word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentCorpus(fullSentCorpus, testFraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(fullSentCorpus)\n",
    "    testCount = int(len(fullSentCorpus) * testFraction)\n",
    "    testSentCorpus = fullSentCorpus[:testCount]\n",
    "    trainSentCorpus = fullSentCorpus[testCount:]\n",
    "    return testSentCorpus, trainSentCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Зареждане на корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "startToken = '<s>'\n",
    "endToken = '</s>'\n",
    "unkToken = '<unk>'\n",
    "padToken = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n"
     ]
    }
   ],
   "source": [
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]\n",
    "words, word2ind = extractDictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus, trainCorpus  = splitSentCorpus(corpus, testFraction = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "emb_size = 50\n",
    "hid_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM с пакетиране на партида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken):\n",
    "        super(LSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device)) # (w,s)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source) # (w,s)\n",
    "        E = self.embed(X[:-1]) # (w,s,e) # cntg\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked) # (w,s,h)\n",
    "\n",
    "        Z = self.projection(output.flatten(0,1)) # (w*s,h)\n",
    "        Y_bar = X[1:].flatten(0,1) # (w*s)\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LSTMLanguageModelPack(emb_size, hid_size, word2ind, unkToken, padToken).to(device) # i n\n",
    "optimizer = torch.optim.Adam(lm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = lm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, testCorpus, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(testCorpus),batchSize):\n",
    "        batch = testCorpus[b:min(b+batchSize, len(testCorpus))]\n",
    "        l = sum(len(s)-1 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * lm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.608086011322"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(lm, testCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Двупосочен LSTM с пакетиране на партида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken, endToken):\n",
    "        super(BiLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.endTokenIdx = word2ind[endToken]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(embed_size, hidden_size, bidirectional=True)\n",
    "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(word2ind))\n",
    "\n",
    "    def preparePaddedBatch(self, source): #\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source) # (w,s)\n",
    "        E = self.embed(X) # (w,s,e)\n",
    "        \n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False)) #bd\n",
    "        \n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked) # (w,s,2h) # d\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size) # (w,s,2,h) # d\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2) # (w,s,2h) # d\n",
    "        Z = self.projection(t.flatten(0,1)) # (w*s,2h)\n",
    "\n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.endTokenIdx] = self.padTokenIdx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm = BiLSTMLanguageModelPack(emb_size, hid_size, word2ind, unkToken, padToken, endToken).to(device)\n",
    "optimizer = torch.optim.Adam(blm.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = blm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(blm, testCorpus, batchSize):\n",
    "    H = 0.\n",
    "    c = 0\n",
    "    for b in range(0,len(testCorpus),batchSize):\n",
    "        batch = testCorpus[b:min(b+batchSize, len(testCorpus))]\n",
    "        l = sum(len(s)-2 for s in batch)\n",
    "        c += l\n",
    "        with torch.no_grad():\n",
    "            H += l * blm(batch)\n",
    "    return math.exp(H/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.285752269193237"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(blm, testCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LSTM класификатор на документи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel, classesCount):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(langModel.lstm.hidden_size,classesCount)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X[:-1])\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        _, (h,_) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        \n",
    "        Z = self.classProjection(torch.squeeze(h,dim=0)) # (s,h) -> (s,c)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = myCorpus.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('E-Economy'+'/')==0 ]\n",
    "milCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('S-Military'+'/')==0 ]\n",
    "polCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('J-Politics'+'/')==0 ]\n",
    "culCorpus = [ [startToken] + [w.lower() for w in myCorpus.words(f)] + [endToken] for f in fileNames if f.find('C-Culture'+'/')==0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEcoCorpus, trainEcoCorpus = splitSentCorpus(ecoCorpus)\n",
    "testMilCorpus, trainMilCorpus = splitSentCorpus(milCorpus)\n",
    "testPolCorpus, trainPolCorpus = splitSentCorpus(polCorpus)\n",
    "testCulCorpus, trainCulCorpus = splitSentCorpus(culCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainClassCorpus = trainEcoCorpus + trainMilCorpus + trainPolCorpus + trainCulCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = np.concatenate((\n",
    "                         np.ones(len(trainEcoCorpus),dtype='int32')*0,\n",
    "                         np.ones(len(trainMilCorpus),dtype='int32')*1,\n",
    "                         np.ones(len(trainPolCorpus),dtype='int32')*2,\n",
    "                         np.ones(len(trainCulCorpus),dtype='int32')*3\n",
    "                         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = np.concatenate((\n",
    "                        np.ones(len(testEcoCorpus),dtype='int32')*0,\n",
    "                        np.ones(len(testMilCorpus),dtype='int32')*1,\n",
    "                        np.ones(len(testPolCorpus),dtype='int32')*2,\n",
    "                        np.ones(len(testCulCorpus),dtype='int32')*3\n",
    "                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModel = LSTMClassifier(lm,4).to(device)\n",
    "optimizer = torch.optim.Adam(classModel.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(idx)\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "\n",
    "    Z = classModel(batch)\n",
    "    H = torch.nn.functional.cross_entropy(Z,target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testClassCorpus = [ testEcoCorpus, testMilCorpus, testPolCorpus, testCulCorpus ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(s):\n",
    "    with torch.no_grad():\n",
    "        Z = classModel([s])\n",
    "        return torch.argmax(Z[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifier(testClassCorpus, gamma):\n",
    "    L = [ len(c) for c in testClassCorpus ]\n",
    "    pb = progressBar(50)\n",
    "    pb.start(sum(L))\n",
    "    classesCount = len(testClassCorpus)\n",
    "    confusionMatrix = [ [0] * classesCount for _ in range(classesCount) ]\n",
    "    for c in range(classesCount):\n",
    "        for text in testClassCorpus[c]:\n",
    "            pb.tick()\n",
    "            c_MAP = gamma(text)\n",
    "            confusionMatrix[c][c_MAP] += 1\n",
    "    pb.stop()\n",
    "    precision = []\n",
    "    recall = []\n",
    "    Fscore = []\n",
    "    for c in range(classesCount):\n",
    "        extracted = sum(confusionMatrix[x][c] for x in range(classesCount))\n",
    "        if confusionMatrix[c][c] == 0:\n",
    "            precision.append(0.0)\n",
    "            recall.append(0.0)\n",
    "            Fscore.append(0.0)\n",
    "        else:\n",
    "            precision.append( confusionMatrix[c][c] / extracted )\n",
    "            recall.append( confusionMatrix[c][c] / L[c] )\n",
    "            Fscore.append((2.0 * precision[c] * recall[c]) / (precision[c] + recall[c]))\n",
    "    P = sum( L[c] * precision[c] / sum(L) for c in range(classesCount) )\n",
    "    R = sum( L[c] * recall[c] / sum(L) for c in range(classesCount) )\n",
    "    F1 = (2*P*R) / (P + R)\n",
    "    print('=================================================================')\n",
    "    print('Матрица на обърквания: ')\n",
    "    for row in confusionMatrix:\n",
    "        for val in row:\n",
    "            print('{:4}'.format(val), end = '')\n",
    "        print()\n",
    "    print('Прецизност: '+str(precision))\n",
    "    print('Обхват: '+str(recall))\n",
    "    print('F-оценка: '+str(Fscore))\n",
    "    print('Обща презизност: '+str(P))\n",
    "    print('Общ обхват: '+str(R))\n",
    "    print('Обща F-оценка: '+str(F1))\n",
    "    print('=================================================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n",
      "=================================================================\n",
      "Матрица на обърквания: \n",
      "   1  18  46   0\n",
      "   1 144  11   2\n",
      "   0  29 705   1\n",
      "   0   1   2  42\n",
      "Прецизност: [0.5, 0.75, 0.9227748691099477, 0.9333333333333333]\n",
      "Обхват: [0.015384615384615385, 0.9113924050632911, 0.9591836734693877, 0.9333333333333333]\n",
      "F-оценка: [0.029850746268656723, 0.8228571428571428, 0.9406270847231488, 0.9333333333333333]\n",
      "Обща презизност: 0.8686336279120754\n",
      "Общ обхват: 0.8893320039880359\n",
      "Обща F-оценка: 0.8788609640877645\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testClassifier(testClassCorpus, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Двупосочен LSTM класификатор на документи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, langModel, classesCount):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.langModel = langModel\n",
    "        self.classProjection = torch.nn.Linear(2*langModel.hidden_size,classesCount)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.langModel.preparePaddedBatch(source)\n",
    "        E = self.langModel.embed(X)\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        _, (h,c) = self.langModel.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        h = h.view(2,batch_size,self.langModel.hidden_size)\n",
    "        \n",
    "        Z = self.classProjection(torch.cat([h[0],h[1]],1)) # (batch_size,2*self.langModel.hidden_size) -> (batch_size,4=|C|)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModelB = BiLSTMClassifier(blm,4).to(device)\n",
    "optimizer = torch.optim.Adam(classModelB.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "    \n",
    "    Z = classModelB(batch)\n",
    "    H = torch.nn.functional.cross_entropy(Z,target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(s):\n",
    "    with torch.no_grad():\n",
    "        Z = classModelB([s])\n",
    "        return torch.argmax(Z[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n",
      "=================================================================\n",
      "Матрица на обърквания: \n",
      "  40   3  21   1\n",
      "  15 135   8   0\n",
      "   5   5 725   0\n",
      "   5   0   0  40\n",
      "Прецизност: [0.6153846153846154, 0.9440559440559441, 0.9615384615384616, 0.975609756097561]\n",
      "Обхват: [0.6153846153846154, 0.8544303797468354, 0.9863945578231292, 0.8888888888888888]\n",
      "F-оценка: [0.6153846153846154, 0.8970099667774087, 0.9738079247817326, 0.9302325581395349]\n",
      "Обща презизност: 0.9369830981216337\n",
      "Общ обхват: 0.9371884346959122\n",
      "Обща F-оценка: 0.9370857551603071\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testClassifier(testClassCorpus, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Конволюционен класификатор на документи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionClassifier(torch.nn.Module):\n",
    "    def __init__(self, embed, filterSize, filterCount, classesCount, word2ind, unkToken, padToken):\n",
    "        super(ConvolutionClassifier, self).__init__()\n",
    "        self.embed = embed\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.convolution = torch.nn.Conv1d(in_channels=embed.embedding_dim, out_channels=filterCount, kernel_size=filterSize)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.classProjection = torch.nn.Linear(filterCount,classesCount)\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.tensor(sents_padded, dtype=torch.long, device=device) # (batch_size,max_sent_len,embed_size)\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        \n",
    "        E = torch.transpose(self.embed(X),1,2) # (s,e,w)\n",
    "        ### Очаква се Е да е тензор с размер (batch_size, embed_size, max_sent_len)\n",
    "\n",
    "        U,_ = torch.max(torch.relu(self.convolution(E)), dim=2) # (s,oc,w) # d -> (s,oc)\n",
    "        Z = self.classProjection(self.dropout(U))\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB = lm.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classModelE = ConvolutionClassifier(EMB, 7, 400, 4, word2ind, unkToken, padToken).to(device)\n",
    "optimizer = torch.optim.Adam(classModelE.parameters(), lr=0.01, weight_decay=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainClassCorpus), dtype='int32')\n",
    "classModelE.train() # d\n",
    "for epoch in range(10):\n",
    "    np.random.shuffle(idx)\n",
    "    for b in range(0, len(idx), batchSize):\n",
    "        batch = [ trainClassCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "        target = torch.tensor(trainY[idx[b:min(b+batchSize, len(idx))]], dtype = torch.long, device = device)\n",
    "    \n",
    "        Z = classModelE(batch)\n",
    "        H = torch.nn.functional.cross_entropy(Z,target)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        H.backward()\n",
    "        optimizer.step()\n",
    "        if b % 10 == 0:\n",
    "            print(b, '/', len(idx), H.item())\n",
    "classModelE.eval()\n",
    "testClassifier(testClassCorpus, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(s):\n",
    "    with torch.no_grad():\n",
    "        Z = classModelE([s])\n",
    "        return torch.argmax(Z[0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  --------------------------------------------------]\n",
      "=================================================================\n",
      "Матрица на обърквания: \n",
      "  45   0  20   0\n",
      "   0 146  12   0\n",
      "   0   3 732   0\n",
      "   0   0   2  43\n",
      "Прецизност: [1.0, 0.9798657718120806, 0.9556135770234987, 1.0]\n",
      "Обхват: [0.6923076923076923, 0.9240506329113924, 0.9959183673469387, 0.9555555555555556]\n",
      "F-оценка: [0.8181818181818181, 0.9511400651465798, 0.9753497668221185, 0.9772727272727273]\n",
      "Обща презизност: 0.9643018654621938\n",
      "Общ обхват: 0.9631106679960121\n",
      "Обща F-оценка: 0.9637058986316202\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testClassifier(testClassCorpus, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LSTM с посимволово влагане с КНН и пакетиране на партида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharEmbedding(torch.nn.Module):\n",
    "    def __init__(self, word2ind, char_embed_size, word_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharEmbedding, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.char_embed_size = char_embed_size\n",
    "        self.word_embed_size = word_embed_size\n",
    "        self.filter_size = filter_size\n",
    "        self.dropoutrate = dropoutrate\n",
    "        self.padding = padding\n",
    "\n",
    "        alphabetSet = {c for w in word2ind for c in w}\n",
    "        alphabet = ['§','`','~','№']+list(alphabetSet)\n",
    "        self.char2id = {c:i for i, c in enumerate(alphabet) }\n",
    "        self.char_pad = self.char2id['§']\n",
    "        self.start_of_word = self.char2id['`']\n",
    "        self.end_of_word = self.char2id['~']\n",
    "        self.char_unk = self.char2id['№']\n",
    "\n",
    "        self.CharEmbedding = torch.nn.Embedding(len(self.char2id),self.char_embed_size, padding_idx = self.char_pad)\n",
    "        self.conv = torch.nn.Conv1d(char_embed_size, word_embed_size, filter_size, padding=padding)\n",
    "        self.highway_proj = torch.nn.Linear(word_embed_size,word_embed_size)\n",
    "        self.highway_gate = torch.nn.Linear(word_embed_size,word_embed_size)\n",
    "\n",
    "        self.Dropout = torch.nn.Dropout(dropoutrate)\n",
    "\n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        source_ids = [[ [self.start_of_word] + [self.char2id.get(c, self.char_unk) for c in w ] + [self.end_of_word] for w in s] for s in source]\n",
    "\n",
    "        max_word_length = max(len(w) for s in source_ids for w in s )\n",
    "        max_sent_len = max(len(s) for s in source_ids)\n",
    "    \n",
    "        sents_padded = []\n",
    "        for sentence in source_ids:\n",
    "            sent_padded = [ w + [self.char_pad]*(max_word_length-len(w)) for w in sentence ] + [[self.char_pad]*max_word_length] * (max_sent_len - len(sentence))\n",
    "            sents_padded.append(sent_padded)\n",
    "\n",
    "        return torch.transpose(torch.tensor(sents_padded, dtype=torch.long, device=device),0,1).contiguous()\n",
    "\n",
    "    def forward(self, source):\n",
    "        batch_size = len(source) # (s,w,c)\n",
    "        X = self.preparePaddedBatch(source) # (w,s,c)\n",
    "        X_emb = self.CharEmbedding(X).transpose(2,3) # (w,s,ce,c)\n",
    "\n",
    "        x_conv = self.conv(X_emb.flatten(0,1)) # (w*s,we,c)\n",
    "        x_conv_out0,_ = torch.max(torch.nn.functional.relu(x_conv),dim=2) # (w*s,we)\n",
    "        x_conv_out = x_conv_out0.view((-1,batch_size,self.word_embed_size)) # (w,s,we)\n",
    "\n",
    "        x_proj = torch.nn.functional.relu(self.highway_proj(x_conv_out)) # (w,s,we)\n",
    "        x_gate = torch.sigmoid(self.highway_gate(x_conv_out)) # (w,s,we)\n",
    "        x_highway = x_gate * x_proj + (1 - x_gate) * x_conv_out # (w,s,we)\n",
    "\n",
    "        output = self.Dropout(x_highway)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, word_embed_size, hidden_size, word2ind, unkToken, padToken, char_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharCNNLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "\n",
    "        self.charEmbedding = CharEmbedding(word2ind, char_embed_size, word_embed_size, filter_size, dropoutrate, padding)\n",
    "        self.lstm = torch.nn.LSTM(word_embed_size, hidden_size)\n",
    "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    \n",
    "    def forward(self, source):\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.charEmbedding(source)\n",
    "        source_lengths = [len(s)-1 for s in source]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        \n",
    "        Z = self.projection(output.flatten(0,1))\n",
    "        Y_bar = X[1:].flatten(0,1)\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm = CharCNNLSTMLanguageModelPack(256, 256, word2ind, unkToken, padToken, 32).to(device)\n",
    "optimizer = torch.optim.Adam(clm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm.train()\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = clm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())\n",
    "clm.eval()\n",
    "perplexity(clm, testCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Двупосочен LSTM с пакетиране на партида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNNBiLSTMLanguageModelPack(torch.nn.Module):\n",
    "    def __init__(self, word_embed_size, hidden_size, word2ind, unkToken, padToken, endToken, char_embed_size, filter_size=5, dropoutrate=0.3, padding=1):\n",
    "        super(CharCNNBiLSTMLanguageModelPack, self).__init__()\n",
    "        self.word2ind = word2ind\n",
    "        self.unkTokenIdx = word2ind[unkToken]\n",
    "        self.padTokenIdx = word2ind[padToken]\n",
    "        self.endTokenIdx = word2ind[endToken]\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.charEmbedding = CharEmbedding(word2ind, char_embed_size, word_embed_size, filter_size, dropoutrate, padding)\n",
    "        self.lstm = torch.nn.LSTM(word_embed_size, hidden_size, bidirectional=True)\n",
    "        self.projection = torch.nn.Linear(2*hidden_size,len(word2ind))\n",
    "    \n",
    "    def preparePaddedBatch(self, source):\n",
    "        device = next(self.parameters()).device\n",
    "        m = max(len(s) for s in source)\n",
    "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
    "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
    "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
    "    \n",
    "    def forward(self, source):\n",
    "        batch_size = len(source)\n",
    "        X = self.preparePaddedBatch(source)\n",
    "        E = self.charEmbedding(source)\n",
    "\n",
    "        source_lengths = [len(s) for s in source]\n",
    "        m = X.shape[0]\n",
    "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
    "        \n",
    "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
    "        output = output.view(m, batch_size, 2, self.hidden_size)\n",
    "        t = torch.cat((output[:-2,:,0,:], output[2:,:,1,:]),2)\n",
    "        Z = self.projection(t.flatten(0,1))\n",
    "        \n",
    "        Y_bar = X[1:-1].flatten(0,1)\n",
    "        Y_bar[Y_bar==self.endTokenIdx] = self.padTokenIdx\n",
    "        H = torch.nn.functional.cross_entropy(Z,Y_bar,ignore_index=self.padTokenIdx)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cblm = CharCNNBiLSTMLanguageModelPack(256, 256, word2ind, unkToken, padToken, endToken, 32).to(device)\n",
    "optimizer = torch.optim.Adam(cblm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(trainCorpus), dtype='int32')\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cblm.train()\n",
    "for b in range(0, len(idx), batchSize):\n",
    "    batch = [ trainCorpus[i] for i in idx[b:min(b+batchSize, len(idx))] ]\n",
    "    H = cblm(batch)\n",
    "    optimizer.zero_grad()\n",
    "    H.backward()\n",
    "    optimizer.step()\n",
    "    if b % 10 == 0:\n",
    "        print(b, '/', len(idx), H.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.162559473913722"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(cblm, testCorpus, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
