{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcf59ce",
   "metadata": {},
   "source": [
    "## Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
    "> ### Стоян Михов\n",
    "> #### Зимен семестър 2021/2022\n",
    "\n",
    "### Упражнение 10\n",
    "\n",
    " За да работи програмата трябва корпуса от публицистични текстове за Югоизточна Европа,\n",
    " да се намира разархивиран в директорията, в която е програмата (виж упражнение 2).\n",
    "\n",
    " Преди да се стартира програмата е необходимо да се активира съответното обкръжение с командата: `conda activate tii`\n",
    " \n",
    " Настоящата програма използва библиотеката sklearn.\n",
    " За да я инсталирате, след активиране на обкръжението трябва да изпълните командата: `conda install scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import sys\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e35895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class progressBar:\n",
    "    def __init__(self ,barWidth = 50):\n",
    "        self.barWidth = barWidth\n",
    "        self.period = None\n",
    "    def start(self, count):\n",
    "        self.item=0\n",
    "        self.period = int(count / self.barWidth)\n",
    "        sys.stdout.write(\"[\"+(\" \" * self.barWidth)+\"]\")\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\b\" * (self.barWidth+1))\n",
    "    def tick(self):\n",
    "        if self.item>0 and self.item % self.period == 0:\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "        self.item += 1\n",
    "    def stop(self):\n",
    "        sys.stdout.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d54c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentCorpus(fullSentCorpus, testFraction = 0.1):\n",
    "    random.seed(42)\n",
    "    random.shuffle(fullSentCorpus)\n",
    "    testCount = int(len(fullSentCorpus) * testFraction)\n",
    "    testSentCorpus = fullSentCorpus[:testCount]\n",
    "    trainSentCorpus = fullSentCorpus[testCount:]\n",
    "    return testSentCorpus, trainSentCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "startToken = '<START>'\n",
    "endToken = '<END>'\n",
    "unkToken = '<UNK>'\n",
    "\n",
    "def extractDictionary(corpus, limit=20000):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    dictionary = {}\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for w in doc:\n",
    "            if w not in dictionary: dictionary[w] = 0\n",
    "        dictionary[w] += 1\n",
    "    L = sorted([(w,dictionary[w]) for w in dictionary], key = lambda x: x[1] , reverse=True)\n",
    "    if limit > len(L): limit = len(L)\n",
    "    words = [ w for w,_ in L[:limit] ] + [unkToken]\n",
    "    word2ind = { w:i for i,w in enumerate(words)}\n",
    "    pb.stop()\n",
    "    return words, word2ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ebce1",
   "metadata": {},
   "source": [
    "#### Обектна имплементация на Backpropagation с Numpy операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d784a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class compNode:\n",
    "    def __init__(self, predecessors, trainable = True):\n",
    "        self.predecessors = predecessors\n",
    "        self.trainable = trainable\n",
    "        self.value = None\n",
    "        self.grad = None\n",
    "    \n",
    "    def calcValue(self): ## трябва да се дефинира за конкретния връх\n",
    "        return\n",
    "    \n",
    "    def propagateGrad(self, grad):\n",
    "        if not self.grad:\n",
    "            self.grad = grad\n",
    "        else:\n",
    "            self.grad += grad\n",
    "\n",
    "    def derivativeMult(self,i): ## трябва да се дефинира за конкретния връх\n",
    "        return\n",
    "    \n",
    "    def propagateBack(self):\n",
    "        if not self.predecessors: return\n",
    "        for i,p in enumerate(self.predecessors):\n",
    "            if p.trainable:\n",
    "                partialGrad = self.derivativeMult(i)\n",
    "                p.propagateGrad(partialGrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a852df4f",
   "metadata": {},
   "source": [
    "#### Топологично сортиране на върховете на изчислителен граф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedNodes(t,L):\n",
    "    if t in L: return L\n",
    "    if t.predecessors:\n",
    "        for p in t.predecessors:\n",
    "            L = getSortedNodes(p,L)\n",
    "    L.append(t)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b23565",
   "metadata": {},
   "source": [
    "#### Базов обект за модел на невронна мрежа. Съдържа имплементация на Backpropagation и стохастично спускане по градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bafc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, topNode):\n",
    "        self.topNode = topNode\n",
    "        self.sortedNodes = getSortedNodes(topNode,[])\n",
    "        self.paramNodes = [ v for v in self.sortedNodes if v.trainable and not v.predecessors ]\n",
    "        self.dataNodes = [ v for v in self.sortedNodes if not v.trainable and not v.predecessors ]\n",
    "    \n",
    "    def setParameters(self, params):\n",
    "        for i, p in enumerate(params):\n",
    "            self.paramNodes[i].value = p\n",
    "\n",
    "    def setData(self, data):\n",
    "        for i, d in enumerate(data):\n",
    "            self.dataNodes[i].value = d\n",
    "\n",
    "    def saveModelParams(self, fileName):\n",
    "        with open(fileName, 'wb') as f:\n",
    "            for p in self.paramNodes:\n",
    "                np.save(f, p.value)\n",
    "\n",
    "    def loadModelParams(self, fileName):\n",
    "        with open(fileName, 'rb') as f:\n",
    "            for p in self.paramNodes:\n",
    "                p.value = np.load(f, allow_pickle=True)\n",
    "\n",
    "    def forward(self):\n",
    "        for v in self.sortedNodes:\n",
    "            v.calcValue()\n",
    "\n",
    "    def backwards(self):\n",
    "        for v in self.sortedNodes:\n",
    "            v.grad = None\n",
    "        self.topNode.propagateGrad(1)\n",
    "        for v in reversed(self.sortedNodes):\n",
    "            v.propagateBack()\n",
    "                \n",
    "    def updateModel(self,alpha):\n",
    "        for p in self.paramNodes:\n",
    "            p.value -= alpha * p.grad\n",
    "    \n",
    "    def calcLoss(self,testData,batchSize):\n",
    "        loss = 0.\n",
    "        samples = len(testData[0])\n",
    "        for i in range(0,samples,batchSize):\n",
    "            li = min(i+batchSize, samples)\n",
    "            batchData = [d[i:li] for d in testData ]\n",
    "            self.setData(batchData)\n",
    "            self.forward()\n",
    "            loss += (li-i) * self.topNode.value\n",
    "        return loss / samples\n",
    "    \n",
    "    def batchedStochasticGradient(self, trainData, testData, batchSize, alpha = 1., maxEpoch = 100000, printInterval = 100, saveInterval = 10000, fileToSave = None):\n",
    "        ceList = []\n",
    "        tceList = []\n",
    "        epoch = 0\n",
    "        batch = 0\n",
    "        samples = np.arange(len(trainData[0]), dtype='int32')\n",
    "        batchesInEpoch = len(samples) // batchSize\n",
    "        while epoch<maxEpoch:\n",
    "            np.random.shuffle(samples)\n",
    "            for i in range(0,len(samples),batchSize):\n",
    "                if fileToSave and batch > 0 and batch % saveInterval == 0:\n",
    "                    self.saveModelParams(fileToSave)\n",
    "                if batch % printInterval == 0:\n",
    "                    ce = self.topNode.value\n",
    "                    tce = self.calcLoss(testData,batchSize)\n",
    "                    ceList.append(ce)\n",
    "                    tceList.append(tce)\n",
    "                    print('Epoch: '+str(epoch) + ', Batch: '+str(batch % batchesInEpoch)+'/'+str(batchesInEpoch)+', Train loss: '+str(ce)+', Test loss: '+str(tce))\n",
    "                idx = samples[i:min(i+batchSize, len(samples))]\n",
    "                batchData = [d[idx] for d in trainData ]\n",
    "                self.setData(batchData)\n",
    "                self.forward()\n",
    "                self.backwards()\n",
    "                self.updateModel(alpha)\n",
    "                batch += 1\n",
    "            epoch += 1\n",
    "        return ceList, tceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f056dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class termFrequencyNode(compNode):\n",
    "    def setDictionarySize(self,size):\n",
    "        self.dictionarySize = size\n",
    "    def calcValue(self):\n",
    "        ### c следва да бъде списък от контексти с индекси\n",
    "        c = self.predecessors[0].value\n",
    "        S = len(c)\n",
    "        self.value = np.zeros((S,self.dictionarySize), dtype = 'int32')\n",
    "        for i in range(S):\n",
    "            for j in c[i]:\n",
    "                self.value[i,j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9868502",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mulMatrixMatrixNode(compNode):\n",
    "    def calcValue(self):\n",
    "        x = self.predecessors[0].value\n",
    "        y = self.predecessors[1].value\n",
    "        self.value = np.dot(x,y)\n",
    "    def derivativeMult(self,i):\n",
    "        if i == 0:\n",
    "            y = self.predecessors[1].value\n",
    "            return np.dot(self.grad,y.transpose()) \n",
    "        else:\n",
    "            x = self.predecessors[0].value\n",
    "            return np.dot(x.transpose(),self.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxM(U):\n",
    "    ### U следва да бъде матрица с размерност: (S,M)\n",
    "    U = np.exp(U)\n",
    "    tmp = np.sum(U,axis=1)[:,np.newaxis]\n",
    "    U /= tmp\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class crossEntropySoftmaxNode(compNode):\n",
    "    def calcValue(self):\n",
    "        ### z следва да бъде матрица с размерност: (S,L)\n",
    "        ### w следва да бъде вектор с размерност S от индекси на думи\n",
    "        z = self.predecessors[0].value\n",
    "        w = self.predecessors[1].value\n",
    "        self.S = z.shape[0]\n",
    "        self.v = softmaxM(z)\n",
    "        p = self.v[np.arange(self.S, dtype='int32'),w]\n",
    "        self.value = -np.mean(np.log(p))\n",
    "    def derivativeMult(self,i): # 18\n",
    "        w = self.predecessors[1].value\n",
    "        d = -self.v\n",
    "        d[np.arange(self.S, dtype='int32'),w] += 1.\n",
    "        return self.grad * (-d/self.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractContexts(corpus, window_size, words, word2ind):\n",
    "    pb = progressBar()\n",
    "    pb.start(len(corpus))\n",
    "    unk = word2ind[unkToken]\n",
    "\n",
    "    centers = []\n",
    "    contexts = []\n",
    "    for doc in corpus:\n",
    "        pb.tick()\n",
    "        for wi in range(len(doc)):\n",
    "            i = word2ind.get(doc[wi], unk)\n",
    "            context = []\n",
    "            for k in range(1,window_size+1):\n",
    "                if wi-k>=0:\n",
    "                    j = word2ind.get(doc[wi-k], unk)\n",
    "                    context.append(j)\n",
    "                if wi+k<len(doc) and doc[wi+k] in word2ind:\n",
    "                    j = word2ind.get(doc[wi+k], unk)\n",
    "                    context.append(j)\n",
    "            if len(context)==0: continue\n",
    "            centers.append(i)\n",
    "            contexts.append(context)\n",
    "    pb.stop()\n",
    "    return np.array(centers, dtype = 'int32'),np.array(contexts, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d519647",
   "metadata": {},
   "source": [
    "######   Зареждане на корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = 'JOURNALISM.BG/C-MassMedia'\n",
    "myCorpus = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "\n",
    "corpus = [ [startToken] + [w.lower() for w in sent] + [endToken] for sent in myCorpus.sents()]\n",
    "\n",
    "words, word2ind = extractDictionary(corpus)\n",
    "\n",
    "testCorpus, trainCorpus = splitSentCorpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4\n",
    "trainW, trainC = extractContexts(trainCorpus, window_size, words, word2ind)\n",
    "testW, testC = extractContexts(testCorpus, window_size, words, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = compNode(None,trainable=False)\n",
    "C = compNode(None,trainable=False)\n",
    "U = compNode(None)\n",
    "V = compNode(None)\n",
    "chi = termFrequencyNode([C],trainable=False)\n",
    "chi.setDictionarySize(len(words))\n",
    "VC = mulMatrixMatrixNode([chi,V])\n",
    "Z = mulMatrixMatrixNode([VC,U])\n",
    "h = crossEntropySoftmaxNode([Z,w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cacf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embDim = 50\n",
    "U0 = (np.random.rand(embDim, len(words)) - 0.5) / embDim\n",
    "V0 = (np.random.rand(len(words), embDim) - 0.5) / embDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = model(h)\n",
    "word2vec.setParameters([np.copy(V0),np.copy(U0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7395739",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cefList, tcefList = word2vec.batchedStochasticGradient([trainC,trainW], [testC[:1000],testW[:1000]], 100, maxEpoch = 1, printInterval = 10, saveInterval = 100, fileToSave = 'test.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ако имаме вече натрениран модел може директно да го заредим\n",
    "#   word2vec.loadModelParams('w2v.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa36a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.loadModelParams('test.load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b12ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.concatenate([U.value.transpose(),V.value],axis=1) # center & context emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a777bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_k_dim(X, k=100, n_iters = 10):\n",
    "    # Документация на метода има на https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "    \n",
    "    print(\"Running Truncated SVD over %i words...\" % (X.shape[0]))\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=n_iters)\n",
    "    svd.fit(X)\n",
    "    X_reduced = svd.transform(X)\n",
    "    print(\"Done.\")\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings_3d(M, word2ind, words):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    xs = M[:,0]\n",
    "    ys = M[:,1]\n",
    "    zs = M[:,2]\n",
    "    for w in words:\n",
    "        i=word2ind[w]\n",
    "        ax.scatter(xs[i], ys[i], zs[i], marker='x', color= 'red')\n",
    "        ax.text(xs[i]+0.001, ys[i]+0.001, zs[i]+0.001, w)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db158254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings_pairs_3d(M, word2ind, wordPairs):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    xs = M[:,0]\n",
    "    ys = M[:,1]\n",
    "    zs = M[:,2]\n",
    "    for u,v in wordPairs:\n",
    "        i=word2ind[u]\n",
    "        j=word2ind[v]\n",
    "        ax.plot(xs[[i,j]], ys[[i,j]], zs[[i,j]], color= 'red')\n",
    "        ax.text(xs[i]+0.001, ys[i]+0.001, zs[i]+0.001, u)\n",
    "        ax.text(xs[j]+0.001, ys[j]+0.001, zs[j]+0.001, v)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_reduced =SVD_k_dim(E,k=3)\n",
    "E_normalized_3d = E_reduced /np.linalg.norm(E_reduced, axis=1)[:, np.newaxis]\n",
    "sampleWords = ['кола', 'автомобил', 'румъния', 'министър', 'президент', 'гърция', 'футбол', 'спорт', 'баскетбол', 'българия', 'театър', 'кино', 'опера']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d66e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b59e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_3d(E_normalized_3d, word2ind, sampleWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e77710",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleWordPairs = [('румъния', 'букурещ'), ('италия', 'рим'), ('франция', 'париж'), ('унгария', 'будапеща'), ('българия', 'софия'), ('германия', 'берлин')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_pairs_3d(E_normalized_3d, word2ind, sampleWordPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb811900",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_normalized = E /np.linalg.norm(E, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(w,word2ind,words,C,limit=10):\n",
    "    i = word2ind[w]\n",
    "    L = np.dot(C,C[i]).tolist()\n",
    "    L = sorted([(words[i],s) for i,s in enumerate(L)], key = lambda x: x[1] , reverse=True)\n",
    "    return L[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(most_similar('гърция',word2ind,words,E_normalized,limit=5))\n",
    "pprint.pprint(most_similar('футбол',word2ind,words,E_normalized,limit=5))\n",
    "pprint.pprint(most_similar('град',word2ind,words,E_normalized,limit=5))\n",
    "pprint.pprint(most_similar('съд',word2ind,words,E_normalized,limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Перплексията на Word2Vec CBOW модела е: ', np.exp(word2vec.calcLoss([testC[:100000],testW[:100000]],100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac6594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
